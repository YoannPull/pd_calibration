# PD Calibration — End-to-End Pipeline

A clean, reproducible pipeline to:
- build **default labels** per quarter (Freddie-Mac–style),
- **impute** with a persisted imputer,
- **bin/WOE** features (max |Gini| binning),
- **train** multiple candidates and **select** the least-drift model (PSI/JS) under an AUC floor, with optional **probability calibration**,
- **apply** the saved model to new data (with optional **risk segmentation**),
- **report** by **vintage × risk grade** with train-time bucket PDs.

Everything is orchestrated with a **Makefile** for fixed, timestamp-free outputs.

---

## Overview

```

raw quartered files
│
▼
[labels]  → data/processed/labels/window=Tm/quarter=YYYYQn/data.parquet
└→ pooled.parquet (+ oos.parquet if configured)
│
▼
[impute]  → data/processed/imputed/{train,validation}.parquet
(+ artifacts/imputer/imputer.joblib)
│
▼
[binning] → data/processed/binned/{train,validation}.parquet
(+ artifacts/binning_maxgini/bins.json)
│
▼
[train]   → artifacts/model_from_binned/{model_best.joblib, reports.csv,
importance.csv?, model_meta.json, risk_buckets.json}
│
▼
[apply]   → data/processed/scored/test_scored.parquet
│
▼
[results] → reports/by_vintage_grades.csv

```

**Key ideas**
- **Train** on pooled historical data; **validate** on a held-out quarter (or OOS).
- **Model selection** minimizes score drift (PSI/JS) between OOF(train) and validation predictions, subject to `min_auc`.
- **Segmentation**: risk buckets built **once** from **OOF(train)** of the selected (non-calibrated) model → stable deployment.
- **Results**: by-vintage grade tables with **class PD from train**, observed default rates, and bounds.

---

## Project layout (outputs)

```

data/
└── processed/
├── labels/
│   └── window=24m/
│       ├── quarter=2020Q4/data.parquet
│       ├── quarter=2021Q1/data.parquet
│       ├── pooled.parquet
│       ├── oos.parquet                 # if pooled_until provided
│       ├── _summary.csv
│       └── _manifest.json
├── imputed/
│   ├── train.parquet
│   └── validation.parquet
├── binned/
│   ├── train.parquet
│   ├── validation.parquet
│   └── test.parquet                    # optional target for binning_apply
└── scored/
└── test_scored.parquet

artifacts/
├── imputer/
│   └── imputer.joblib
├── binning_maxgini/
│   └── bins.json                           # learned bin schema (max |Gini|)
└── model_from_binned/
├── model_best.joblib
├── reports.csv
├── importance.csv                      # optional if produced
├── model_meta.json
└── risk_buckets.json

reports/
├── model/
│   ├── reports.csv
│   └── importance.csv
└── by_vintage_grades.csv                   # from results.py

````

> Note: the historical IV report is no longer generated by default in this pipeline.

---

## Prerequisites

- Python 3.11+ (3.12 recommended)
- [Poetry](https://python-poetry.org/)
- Recommended libs (handled by Poetry): `pandas`, `numpy`, `scikit-learn`, `pyarrow`, `joblib`, `yaml`

Install:

```bash
poetry install
````

Activate:

```bash
poetry shell
```

---

## Raw data expectation

Under `data/raw/mortgage_data/`, one folder per quarter:

```
data/raw/mortgage_data/
└── historical_data_<YYYYQn>/
    ├── historical_data_<YYYYQn>.txt         # origination
    └── historical_data_time_<YYYYQn>.txt    # performance
```

---

## Configuration (`config.yml`)

```yaml
data:
  root: "data/raw/mortgage_data"
  quarters: ["2019Q4","2020Q1","2020Q2","2020Q3","2020Q4",
             "2021Q1","2021Q2","2021Q3","2021Q4",
             "2022Q1","2022Q2","2022Q3","2022Q4",
             "2023Q1","2023Q2","2023Q3","2023Q4"]
labels:
  window_months: 24
  delinquency_threshold: 3
  liquidation_codes: ["02","03","09"]
  include_ra: true
  require_full_window: false
output:
  dir: "data/processed/labels"
  make_pooled: true
  # pooled_until: "2022Q4"      # optional: defines pooled vs oos split
  # format: parquet
```

---

## Makefile — main targets

```text
labels              Build quarterly labels (+pooled, +oos if set)
impute              Fit imputer on pooled, transform train/validation
binning_fit         Fit max |Gini| binning on train, apply to validation (+ bins.json)
binning_apply       Apply saved bins.json to a custom imputed dataset
model_train         Train from WOE/__BIN, optional isotonic calibration, save artifacts
model_apply         Apply saved model to binned dataset (probabilities only)
model_apply_segment Apply model + risk segmentation (requires buckets)
results             Build vintage × grade report from a scored file
pipeline            labels → impute → binning_fit → model_train
check_labels        Sanity check for required label files
env                 Print current important variables
clean_*             Remove derived datasets / artifacts / reports
```

### Important variables & new options

**Labels**

* `LABELS_CONFIG=config.yml`, `LABELS_POOLED=1`, `LABELS_WORKERS=<N>`, `LABELS_POOLED_UNTIL=YYYYQn`
* `LABELS_WINDOW=24`, `LABELS_FORMAT=parquet`

**Imputation & splits**

* `VAL_QUARTER=2022Q4`, `IMPUTE_VAL_SOURCE=quarter|oos`
* `SRC_LABELS_DIR=data/processed/labels`

**Binning (max |Gini|)**

* Structure: learned bins in `artifacts/binning_maxgini/bins.json`, transformed parquet in `data/processed/binned/`
* Core params:

  * `MAX_BINS_CATEG=6`, `MIN_BIN_SIZE_CATEG=200`
  * `MAX_BINS_NUM=6`, `MIN_BIN_SIZE_NUM=200`, `N_QUANTILES_NUM=50`
  * `BIN_INCLUDE_MISSING=1` (adds explicit missing bucket)
  * `BIN_MISSING_LABEL="__MISSING__"`, `BIN_COL_SUFFIX="__BIN"`
  * `MIN_GINI_KEEP` (optional keep threshold on post-split Gini)
* **New flags**

  * `BIN_DROP_MISSING_FLAGS=1` → pass `--drop-missing-flags` to remove **missing/was_missing** aux flags
  * `BIN_NO_DENYLIST=1` → pass `--no-denylist` to disable the shared deny list (by default it’s **enabled**)
  * `N_JOBS_CATEG=-1` and `N_JOBS_NUM=-1` → parallelize categorical & numerical bin search

    * `-1` = use all cores, `1` = sequential

**Model (from binned / or existing WOE)**

* `WOE_PREFIXES="woe__"` (or `""` to force WOE-from-__BIN)
* `BIN_SUFFIX="__BIN"`, `CV_FOLDS=5`, `CORR_THRESHOLD=0.85`
* `NO_ISOTONIC=0` (set `1` to disable isotonic; fallback to sigmoid)
* `DROP_PROXY_CUTOFF` (e.g. `0.25`) automatic drop using PSI(feature)
* `CONDITIONAL_PROXIES` (e.g. `"original_interest_rate"`)
* `NO_PRIOR_SHIFT_ADJUST=0` (set `1` to skip prior-shift intercept correction)

**Apply segmentation**

* `BUCKETS_PATH=artifacts/model_from_binned/risk_buckets.json`
* `SEGMENT_COL=risk_bucket`

---

## Step-by-step (recommended)

### 1) Build labels (parallel, with pooled/OOS)

```bash
make labels
# or with options:
make labels LABELS_POOLED=1 LABELS_WORKERS=6 LABELS_POOLED_UNTIL=2022Q4
```

Outputs in `data/processed/labels/window=<T>m/` (per-quarter files + `pooled.parquet`, optional `oos.parquet`).

### 2) Impute (train = pooled, validation = quarter or OOS)

```bash
# default VAL_QUARTER=2022Q4
make impute

# choose validation quarter
make impute VAL_QUARTER=2023Q2

# or validate on OOS (requires LABELS_POOLED_UNTIL in labels step)
make impute IMPUTE_VAL_SOURCE=oos
```

### 3) Binning / WOE (max |Gini|)

**Run with parallelism, denylist enabled, and drop auto missing flags**

```bash
make binning_fit BIN_INCLUDE_MISSING=1 BIN_DROP_MISSING_FLAGS=1 BIN_NO_DENYLIST=0 N_JOBS_CATEG=-1 N_JOBS_NUM=-1
```

**(Optional) Disable denylist to assess its impact**

```bash
make binning_fit BIN_NO_DENYLIST=1 N_JOBS_CATEG=-1 N_JOBS_NUM=-1
```

**Apply saved bins to any imputed dataset**

```bash
make binning_apply \
  BINNING_APPLY_DATA=data/processed/imputed/test.parquet \
  BINNING_APPLY_OUT=data/processed/binned/test.parquet
```

### 4) Train (drift-aware selection + optional calibration + risk buckets)

**Force WOE computation from `__BIN` (ignore existing WOE columns)**

```bash
make model_train WOE_PREFIXES=""
```

**Use existing WOE prefixes + drop unstable proxies conditionally**

```bash
make model_train WOE_PREFIXES="woe__,_WOE" DROP_PROXY_CUTOFF=0.25 CONDITIONAL_PROXIES="original_interest_rate"
```

Saves to `artifacts/model_from_binned/`:

* `model_best.joblib`
* `reports.csv` (copied also to `reports/model/reports.csv`)
* `importance.csv` (if produced; copied to `reports/model/importance.csv`)
* `model_meta.json`
* `risk_buckets.json`

### 5) Apply model (score new binned data)

```bash
# probabilities only
make model_apply \
  MODEL_APPLY_DATA=data/processed/binned/test.parquet \
  MODEL_OUT=data/processed/scored/test_scored.parquet

# probabilities + segmentation (adds SEGMENT_COL)
make model_apply_segment \
  MODEL_APPLY_DATA=data/processed/binned/test.parquet \
  MODEL_OUT=data/processed/scored/test_scored.parquet
```

If your scored file also contains the target (e.g. `default_24m`), the apply script can additionally emit **OOS metrics** (AUC, Brier, LogLoss, etc.) to a JSON file (see script help).

### 6) Vintage × grade reporting

Use `results.py` to produce a by-vintage summary per risk grade. It will:

* assign buckets per `risk_buckets.json`,
* show **grade**, **bounds**, **count**, **defaults**, **default rate**, **class PD from train** (if provided), and **mean predicted proba**.

Example:

```bash
poetry run python src/results.py \
  --data data/processed/scored/test_scored.parquet \
  --buckets artifacts/model_from_binned/risk_buckets.json \
  --target default_24m \
  --out reports/by_vintage_grades.csv
```

**Output columns**

* `vintage` — e.g. `2023Q2`
* `grade` — e.g. `G01`
* `bucket_index` — 0-based index
* `lower`, `upper` — bucket bounds (probability)
* `class_pd_train` — class PD observed on train (if present in JSON)
* `n`, `n_default`, `default_rate`
* `mean_proba`

---

## Risk segmentation

`risk_buckets.json` is produced at train time using **OOF(train)** scores from the selected model (**pre-calibration**), ensuring deployment stability.

Minimal schema:

```json
{
  "edges": [0.00, 0.03, 0.05, 0.08, 0.12, 1.00],
  "n_bins": 5,
  "labels": ["G01","G02","G03","G04","G05"],
  "bucket_pd": [0.01, 0.04, 0.06, 0.09, 0.20]
}
```

*Edges are ascending; bin rule: `(edges[i], edges[i+1]]`.*

---

## Scripts — quick reference

**Labels**

```bash
src/make_labels.py \
  --config config.yml \
  --outdir data/processed/labels \
  --format parquet \
  --pooled \
  --pooled-until 2022Q4 \
  --workers 6
```

**Impute**

```bash
src/impute_and_save.py \
  --train-csv data/processed/labels/window=24m/pooled.parquet \
  --validation-csv data/processed/labels/window=24m/quarter=2022Q4/data.parquet \
  --target default_24m \
  --outdir data/processed/imputed \
  --artifacts artifacts/imputer \
  --format parquet \
  --use-cohort \
  --missing-flag
```

**Binning (max |Gini|)**

```bash
src/fit_binning.py \
  --train data/processed/imputed/train.parquet \
  --validation data/processed/imputed/validation.parquet \
  --target default_24m \
  --outdir data/processed/binned \
  --artifacts artifacts/binning_maxgini \
  --format parquet \
  --bin-col-suffix "__BIN" \
  --max-bins-categ 6 --min-bin-size-categ 200 \
  --max-bins-num 6   --min-bin-size-num 200 --n-quantiles-num 50 \
  --missing-label "__MISSING__" \
  --include-missing \
  --n-jobs-categ -1 --n-jobs-num -1
# optional flags:
#   --min-gini-keep 0.02
#   --drop-missing-flags
#   --no-denylist
```

**Apply bins**

```bash
src/apply_binning.py \
  --data data/processed/imputed/test.parquet \
  --bins artifacts/binning_maxgini/bins.json \
  --out data/processed/binned/test.parquet
```

**Training (from binned)**

```bash
src/train_model.py \
  --train data/processed/binned/train.parquet \
  --validation data/processed/binned/validation.parquet \
  --target default_24m \
  --artifacts artifacts/model_from_binned \
  --bin-suffix "__BIN" \
  --woe-prefixes "" \
  --cv-folds 5 \
  --corr-threshold 0.85
# optional:
#   --no-isotonic
#   --drop-proxy-cutoff 0.25
#   --conditional-proxies "original_interest_rate"
#   --no-prior-shift-adjust
```

**Apply (scoring)**

```bash
src/apply_model.py \
  --data data/processed/binned/test.parquet \
  --model artifacts/model_from_binned/model_best.joblib \
  --out data/processed/scored/test_scored.parquet
# with segmentation:
#   --buckets artifacts/model_from_binned/risk_buckets.json --bucket-col risk_bucket
```

**Results**

```bash
src/results.py \
  --data data/processed/scored/test_scored.parquet \
  --buckets artifacts/model_from_binned/risk_buckets.json \
  --target default_24m \
  --out reports/by_vintage_grades.csv
```

> Run `poetry run python <script> --help` for full options.

---

## Tips & Troubleshooting

* **“Missing: …/pooled.parquet”**
  Run `make labels` first, or set `SRC_LABELS_DIR` to the folder that holds `window=<T>m/pooled.<fmt>`.

* **Quarter not found**
  Ensure the quarter exists under `labels/window=<T>m/quarter=<YYYYQn>/data.<fmt>`. Rebuild labels or adjust `VAL_QUARTER`.

* **PyArrow / Parquet**
  Make sure `pyarrow` is installed. Periods are converted to end-of-month timestamps on write.

* **Performance**
  Use `LABELS_WORKERS=<N>` for labels and `N_JOBS_CATEG/N_JOBS_NUM=-1` to parallelize binning.

* **Deny list**
  Enabled by default in binning. Set `BIN_NO_DENYLIST=1` to disable for experimentation.

---

## License

MIT (adapt as needed).

## Contributing

Issues and PRs welcome. Please include:

* the exact command used,
* `make env` output,
* relevant logs, and a brief description.

