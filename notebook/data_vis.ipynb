{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49d59061",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1139316d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20014dad",
   "metadata": {},
   "source": [
    "# Process data\n",
    "\n",
    "We want to define :\n",
    "- Definition of  default\n",
    "- Time step (12 months, 24 months)\n",
    "\n",
    "If the lender default after 24 months we do not take it into account.\n",
    "\n",
    "\n",
    "We define the default as having 90 days of non payment or having zero_balance code a 02, 03 or 09 (cf data details) between the \"FIRST PAYMENT DATE\" and the \"MONTLHLY REPORTING PERIOD\" being under 12 months."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1be0512",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### make_labels.py initial code\n",
    "\n",
    "# Paths to origination and performance datasets\n",
    "path_orig = \"../data/raw/mortgage_data/historical_data_2022Q1/historical_data_2022Q1.txt\"\n",
    "path_perf = \"../data/raw/mortgage_data/historical_data_2022Q1/historical_data_time_2022Q1.txt\"\n",
    "\n",
    "# Column names for the Origination dataset\n",
    "colnames_origination = [\n",
    "    \"credit_score\",                         # Borrower credit score\n",
    "    \"first_payment_date\",                   # First scheduled payment date (YYYYMM)\n",
    "    \"first_time_homebuyer_flag\",            # First-time homebuyer flag\n",
    "    \"maturity_date\",                        # Loan maturity date (YYYYMM)\n",
    "    \"msa_md\",                               # MSA / Metropolitan Division\n",
    "    \"mi_percent\",                           # Mortgage Insurance percentage\n",
    "    \"number_of_units\",                      # Number of units in the property\n",
    "    \"occupancy_status\",                     # Occupancy status (owner/second/investment)\n",
    "    \"original_cltv\",                        # Original Combined Loan-to-Value\n",
    "    \"original_dti\",                         # Original Debt-to-Income ratio\n",
    "    \"original_upb\",                         # Original Unpaid Principal Balance\n",
    "    \"original_ltv\",                         # Original Loan-to-Value\n",
    "    \"original_interest_rate\",               # Original Interest Rate\n",
    "    \"channel\",                              # Origination channel (Retail, Broker, etc.)\n",
    "    \"ppm_flag\",                             # Prepayment penalty flag\n",
    "    \"amortization_type\",                    # Amortization type (FRM/ARM)\n",
    "    \"property_state\",                       # Property state (2-letter code)\n",
    "    \"property_type\",                        # Property type\n",
    "    \"postal_code\",                          # Postal code (last 2 digits = 00)\n",
    "    \"loan_sequence_number\",                 # Unique loan identifier (primary key)\n",
    "    \"loan_purpose\",                         # Loan purpose (Purchase, Refinance)\n",
    "    \"original_loan_term\",                   # Original loan term (months)\n",
    "    \"number_of_borrowers\",                  # Number of borrowers\n",
    "    \"seller_name\",                          # Seller name\n",
    "    \"servicer_name\",                        # Servicer name\n",
    "    \"super_conforming_flag\",                # Super conforming flag\n",
    "    \"pre_relief_refi_loan_seq_number\",      # Pre-relief refinance loan sequence number\n",
    "    \"special_eligibility_program\",          # Special eligibility program\n",
    "    \"relief_refinance_indicator\",           # Relief refinance indicator\n",
    "    \"property_valuation_method\",            # Property valuation method\n",
    "    \"interest_only_indicator\",              # Interest-only indicator\n",
    "    \"mi_cancellation_indicator\"             # MI cancellation indicator\n",
    "]\n",
    "\n",
    "# Column names for the Performance dataset\n",
    "colnames_performance = [\n",
    "    \"loan_sequence_number\",                 # Loan identifier (primary key)\n",
    "    \"monthly_reporting_period\",             # Reporting period (YYYYMM)\n",
    "    \"current_actual_upb\",                   # Current actual Unpaid Principal Balance\n",
    "    \"current_loan_delinquency_status\",      # Loan delinquency status (0,1,2,..., RA)\n",
    "    \"loan_age\",                             # Loan age in months\n",
    "    \"remaining_months_to_legal_maturity\",   # Remaining months until legal maturity\n",
    "    \"defect_settlement_date\",               # Defect settlement date (YYYYMM)\n",
    "    \"modification_flag\",                    # Loan modification flag\n",
    "    \"zero_balance_code\",                    # Zero balance code (01,02,03,09, etc.)\n",
    "    \"zero_balance_effective_date\",          # Zero balance effective date (YYYYMM)\n",
    "    \"current_interest_rate\",                # Current interest rate\n",
    "    \"current_non_interest_bearing_upb\",     # Current non-interest-bearing UPB\n",
    "    \"ddlpi\",                                # Due Date of Last Paid Installment (YYYYMM)\n",
    "    \"mi_recoveries\",                        # Mortgage insurance recoveries\n",
    "    \"net_sale_proceeds\",                    # Net sale proceeds\n",
    "    \"non_mi_recoveries\",                    # Non-MI recoveries\n",
    "    \"total_expenses\",                       # Total expenses\n",
    "    \"legal_costs\",                          # Legal costs\n",
    "    \"maintenance_and_preservation_costs\",   # Maintenance & preservation costs\n",
    "    \"taxes_and_insurance\",                  # Taxes and insurance\n",
    "    \"miscellaneous_expenses\",               # Miscellaneous expenses\n",
    "    \"actual_loss_calculation\",              # Actual loss calculation\n",
    "    \"cumulative_modification_cost\",         # Cumulative modification cost\n",
    "    \"step_modification_flag\",               # Step modification flag\n",
    "    \"payment_deferral\",                     # Payment deferral indicator\n",
    "    \"estimated_ltv\",                        # Estimated Loan-to-Value (ELTV)\n",
    "    \"zero_balance_removal_upb\",             # Zero balance removal UPB\n",
    "    \"delinquent_accrued_interest\",          # Delinquent accrued interest\n",
    "    \"delinquency_due_to_disaster\",          # Delinquency due to disaster\n",
    "    \"borrower_assistance_status_code\",      # Borrower assistance status code\n",
    "    \"current_month_modification_cost\",      # Current month modification cost\n",
    "    \"interest_bearing_upb\"                  # Interest-bearing UPB\n",
    "]\n",
    "\n",
    "# Load both datasets (pipe-delimited, no header)\n",
    "df_train_train_orig = pd.read_csv(path_orig, sep=\"|\", header=None, names=colnames_origination)\n",
    "df_perf = pd.read_csv(path_perf, sep=\"|\", header=None, names=colnames_performance)\n",
    "\n",
    "\n",
    "# Shape data\n",
    "print(f\"Shape data orig : {df_orig.shape}\")\n",
    "print(f\"Shape data perf: {df_perf.shape}\")\n",
    "\n",
    "# Convert YYYYMM to datetime\n",
    "df_perf[\"monthly_reporting_period\"] = pd.to_datetime(\n",
    "    df_perf[\"monthly_reporting_period\"].astype(str), \n",
    "    format=\"%Y%m\"\n",
    ")\n",
    "df_orig[\"first_payment_date\"] = pd.to_datetime(\n",
    "    df_orig[\"first_payment_date\"].astype(str), \n",
    "    format=\"%Y%m\"\n",
    ")\n",
    "\n",
    "# Convert to monthly Period type (YYYY-MM), easier for month arithmetic\n",
    "df_perf[\"monthly_reporting_period\"] = df_perf[\"monthly_reporting_period\"].dt.to_period(\"M\")\n",
    "df_orig[\"first_payment_date\"] = df_orig[\"first_payment_date\"].dt.to_period(\"M\")\n",
    "\n",
    "# Merge Origination info into Performance dataset\n",
    "df_perf = pd.merge(\n",
    "    df_perf, \n",
    "    df_orig[[\"loan_sequence_number\", \"first_payment_date\"]], \n",
    "    on=\"loan_sequence_number\", \n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# Compute loan age in months since origination\n",
    "df_perf[\"months_since_orig\"] = (\n",
    "    df_perf[\"monthly_reporting_period\"] - df_perf[\"first_payment_date\"]\n",
    ").apply(lambda x: x.n)\n",
    "\n",
    "# Flag observations within the first 24 months after origination\n",
    "df_perf[\"within_24m\"] = df_perf[\"months_since_orig\"] <= 24\n",
    "\n",
    "\n",
    "\n",
    "df_perf_within = df_perf.copy()\n",
    "# print(df_perf_within.shape)\n",
    "df_perf_within = df_perf_within[df_perf_within[\"within_24m\"] == True]\n",
    "# print(df_perf_within.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Define default:\n",
    "# - delinquency status not in {0,1,2} (=> 90+ days delinquent or RA)\n",
    "# - OR zero_balance_code in {03,09,15,16,96} (dispositions / foreclosures)\n",
    "df_perf_within[\"default\"] = np.where(\n",
    "    (~df_perf_within[\"current_loan_delinquency_status\"].astype(str).isin([\"0\",\"1\",\"2\"])) |\n",
    "    (df_perf_within[\"zero_balance_code\"].astype(str).isin([\"03\",\"09\",\"15\",\"16\",\"96\"])),\n",
    "    1, 0\n",
    ")\n",
    "\n",
    "# Aggregate at loan level: max(default) = 1 if loan ever defaulted in 24m\n",
    "loan_level = (\n",
    "    df_perf_within.groupby(\"loan_sequence_number\")[\"default\"]\n",
    "    .max()  # 0 if always current, 1 if ever default\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "df_orig = pd.merge(df_orig, loan_level, on = \"loan_sequence_number\", how = \"left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c72b68b",
   "metadata": {},
   "source": [
    "# Feature engeenering\n",
    "\n",
    "\n",
    "When building a credit scoring model, it’s essential to respect the time dimension: the model should be trained on past vintages of loans and evaluated on future vintages. For example, if we have data for 2021Q4, 2022Q1, and 2022Q2, you would train on the first two quarters and keep 2022Q2 strictly for testing. This “out-of-time” validation mimics the real-world situation where a model is always used to predict the future, and it ensures that performance and calibration are not artificially inflated by information leakage across time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e49fd99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "PATH = Path(\"../data/processed/default_labels\")\n",
    "PATTERN = re.compile(r\"default_labels_24m_(\\d{4}Q[1-4])\\.csv$\", re.I)\n",
    "\n",
    "# Optionnel: accélère et économise de la RAM (pandas ≥ 2.0)\n",
    "READ_KW = dict(engine=\"pyarrow\", dtype_backend=\"pyarrow\")\n",
    "# Optionnel: ne charger que les colonnes utiles\n",
    "# READ_KW[\"usecols\"] = [\"loan_sequence_number\", \"default_24m\", \"vintage\", ...]\n",
    "\n",
    "files = sorted(\n",
    "    (p for p in PATH.glob(\"default_labels_24m_*.csv\") if PATTERN.match(p.name)),\n",
    "    key=lambda p: PATTERN.match(p.name).group(1)\n",
    ")\n",
    "\n",
    "buckets = {\"train\": [], \"validation\": [], \"test\": []}\n",
    "def year_to_split(y: int):\n",
    "    if 2021 <= y <= 2022: return \"train\"\n",
    "    if y == 2023:         return \"validation\"\n",
    "    if y == 2024:         return \"test\"\n",
    "    return None  # ignore/alerter si autre année\n",
    "\n",
    "for p in files:\n",
    "    qstr = PATTERN.match(p.name).group(1)       # ex: \"2021Q3\"\n",
    "    q = pd.Period(qstr, freq=\"Q\")\n",
    "    split = year_to_split(q.year)\n",
    "    if split is None:\n",
    "        print(f\"Ignoré: {p.name}\")\n",
    "        continue\n",
    "    df = pd.read_csv(p, **READ_KW)\n",
    "    df[\"vintage\"] = q                            # utile pour groupby/tri\n",
    "    buckets[split].append(df)\n",
    "\n",
    "# Concat une seule fois par split (plus rapide que concat successifs)\n",
    "df_train       = pd.concat(buckets[\"train\"], ignore_index=True)\n",
    "df_validation  = pd.concat(buckets[\"validation\"], ignore_index=True)\n",
    "df_test        = pd.concat(buckets[\"test\"], ignore_index=True)\n",
    "\n",
    "# (Optionnel) dédup si nécessaire\n",
    "# for d in (df_train, df_validation, df_test):\n",
    "#     d.drop_duplicates(subset=\"loan_sequence_number\", inplace=True)\n",
    "\n",
    "# Proportions jolies\n",
    "sizes = {\"train\": len(df_train), \"validation\": len(df_validation), \"test\": len(df_test)}\n",
    "total = sum(sizes.values())\n",
    "for k, n in sizes.items():\n",
    "    print(f\"{k.capitalize():<12}: {n:>10,} rows  ({n/total:.2%})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "548ddc33",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a2553f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas.api.types import CategoricalDtype\n",
    "\n",
    "df_train_clean = df_train.copy()\n",
    "\n",
    "# --- Helpers ---\n",
    "def yn_space_to_bool(s, na_vals=('9',)):\n",
    "    s = s.astype('string').str.strip().str.upper()\n",
    "    # blank (espace/vide) = False par défaut pour certains indicateurs (cf. doc)\n",
    "    s = s.fillna('').replace({' ': ''})\n",
    "    out = s.map({'Y': True, 'N': False, '': False})\n",
    "    out[s.isin(na_vals)] = pd.NA\n",
    "    return out.astype('boolean')\n",
    "\n",
    "def to_periodM(col):\n",
    "    s = col.astype('string').str.strip()\n",
    "    s = s.where(s.str.fullmatch(r'\\d{6}'), pd.NA)   # YYYYMM\n",
    "    return pd.PeriodIndex(s, freq='M')\n",
    "\n",
    "def to_periodQ(col):\n",
    "    s = col.astype('string').str.strip().str.upper()\n",
    "    # suppose un format type '2016Q4'\n",
    "    return pd.PeriodIndex(s.where(s.str.fullmatch(r'\\d{4}Q[1-4]'), pd.NA), freq='Q')\n",
    "\n",
    "# --- Dates / périodes ---\n",
    "df_train_clean['first_payment_date'] = pd.to_datetime(df_train_clean['first_payment_date'],\n",
    "                                                       errors=\"coerce\").dt.to_period(\"M\")\n",
    "df_train_clean['maturity_date']      = to_periodM(df_train_clean['maturity_date'])\n",
    "df_train_clean['vintage']            = to_periodQ(df_train_clean['vintage'])\n",
    "\n",
    "# --- Booléens (selon doc) ---\n",
    "df_train_clean['ppm_flag']                    = yn_space_to_bool(df_train_clean['ppm_flag'], na_vals=())\n",
    "df_train_clean['interest_only_indicator']     = yn_space_to_bool(df_train_clean['interest_only_indicator'], na_vals=())\n",
    "df_train_clean['super_conforming_flag']       = yn_space_to_bool(df_train_clean['super_conforming_flag'], na_vals=())\n",
    "df_train_clean['first_time_homebuyer_flag']   = yn_space_to_bool(df_train_clean['first_time_homebuyer_flag'], na_vals=('9',))\n",
    "# Relief refinance: Y / (blank)\n",
    "df_train_clean['relief_refinance_indicator']  = yn_space_to_bool(df_train_clean['relief_refinance_indicator'])\n",
    "\n",
    "# Si ta cible est 0/1 :\n",
    "if pd.api.types.is_integer_dtype(df_train_clean['default_24m']) or pd.api.types.is_bool_dtype(df_train_clean['default_24m']):\n",
    "    df_train_clean['default_24m'] = df_train_clean['default_24m'].map({1: True, 0: False}).astype('boolean')\n",
    "\n",
    "# --- Sentinelles -> NA puis cast num ---\n",
    "df_train_clean['credit_score']       = df_train_clean['credit_score'].replace({9999: pd.NA}).astype('Int16')\n",
    "df_train_clean['mi_percent']         = df_train_clean['mi_percent'].replace({999: pd.NA}).astype('Int16')\n",
    "df_train_clean['number_of_units']    = df_train_clean['number_of_units'].replace({99: pd.NA}).astype('Int8')\n",
    "df_train_clean['original_cltv']      = df_train_clean['original_cltv'].replace({999: pd.NA}).astype('Int16')\n",
    "df_train_clean['original_dti']       = df_train_clean['original_dti'].replace({999: pd.NA}).astype('Int16')\n",
    "df_train_clean['original_ltv']       = df_train_clean['original_ltv'].replace({999: pd.NA}).astype('Int16')\n",
    "df_train_clean['original_loan_term'] = df_train_clean['original_loan_term'].astype('Int16')\n",
    "df_train_clean['number_of_borrowers']= df_train_clean['number_of_borrowers'].replace({99: pd.NA}).astype('Int8')\n",
    "df_train_clean['original_upb']       = df_train_clean['original_upb'].astype('Int64')\n",
    "df_train_clean['msa_md']             = df_train_clean['msa_md'].astype('Int32', errors='ignore')  # si NA déjà ok\n",
    "\n",
    "# --- Identifiants / codes ---\n",
    "df_train_clean['loan_sequence_number']          = df_train_clean['loan_sequence_number'].astype('string')\n",
    "df_train_clean['pre_relief_refi_loan_seq_number']= df_train_clean['pre_relief_refi_loan_seq_number'].astype('string')\n",
    "\n",
    "# Postal code : string + padding\n",
    "df_train_clean['postal_code'] = (df_train_clean['postal_code']\n",
    "    .astype('Int64')        # si c'était numérique\n",
    "    .astype('string')\n",
    "    .str.strip().str.upper()\n",
    "    .str.zfill(5)\n",
    ")\n",
    "\n",
    "# --- Catégorielles (avec gestion des codes \"NA\") ---\n",
    "df_train_clean['occupancy_status'] = (df_train_clean['occupancy_status'].astype('string').str.strip().str.upper()\n",
    "                          .replace({'9': pd.NA})\n",
    "                          .astype(CategoricalDtype(categories=['P','S','I'], ordered=False)))\n",
    "\n",
    "df_train_clean['channel'] = (df_train_clean['channel'].astype('string').str.strip().str.upper()\n",
    "                 .replace({'9': pd.NA})\n",
    "                 .astype(CategoricalDtype(categories=['R','B','C','T'], ordered=False)))\n",
    "\n",
    "df_train_clean['amortization_type'] = (df_train_clean['amortization_type'].astype('string').str.strip().str.upper()\n",
    "                           .astype(CategoricalDtype(categories=['FRM','ARM'], ordered=False)))\n",
    "\n",
    "df_train_clean['property_state'] = df_train_clean['property_state'].astype('string').str.strip().str.upper().astype('category')\n",
    "\n",
    "df_train_clean['property_type'] = (df_train_clean['property_type'].astype('string').str.strip().str.upper()\n",
    "                       .replace({'99': pd.NA})\n",
    "                       .astype(CategoricalDtype(categories=['SF','CO','PU','CP','MH'], ordered=False)))\n",
    "\n",
    "df_train_clean['loan_purpose'] = (df_train_clean['loan_purpose'].astype('string').str.strip().str.upper()\n",
    "                      .replace({'9': pd.NA})\n",
    "                      .astype(CategoricalDtype(categories=['P','C','N','R'], ordered=False)))\n",
    "\n",
    "df_train_clean['special_eligibility_program'] = (df_train_clean['special_eligibility_program'].astype('string').str.strip().str.upper()\n",
    "                                     .replace({'9': pd.NA})\n",
    "                                     .astype(CategoricalDtype(categories=['H','F','R'], ordered=False)))\n",
    "\n",
    "# Valeurs 1..4..9 => catégorie (pas ordonnée)\n",
    "df_train_clean['property_valuation_method'] = (df_train_clean['property_valuation_method']\n",
    "                                   .replace({9: pd.NA})\n",
    "                                   .astype('Int8')\n",
    "                                   .astype('category'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4987fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ffb3f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a895097e",
   "metadata": {},
   "source": [
    "# Graph, data viz "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514d0d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = df_train[\"default_24m\"].value_counts(normalize=True, dropna=False) * 100\n",
    "\n",
    "# 4) Tracé Matplotlib (et non seaborn)\n",
    "fig, ax = plt.subplots()\n",
    "bars = ax.bar(counts.index.astype(str), counts.values, color=\"lightblue\")\n",
    "\n",
    "ax.set_title(\"Default modality proportion\")\n",
    "ax.set_xlabel(\"Modalité (default_24m)\")\n",
    "ax.set_ylabel(\"Pourcentage (%)\")\n",
    "\n",
    "# Légendes de pourcentage sur chaque barre\n",
    "ax.bar_label(bars, labels=[f\"{v:.1f}%\" for v in counts.values], padding=3)\n",
    "\n",
    "# Marges et rendu propre\n",
    "ax.set_ylim(0, max(100, counts.max() * 1.15))   # laisse un peu d'espace pour le label\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c91a063",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "\n",
    "# Données (sans NaN)\n",
    "x = df_train[\"original_upb\"].dropna().values\n",
    "\n",
    "# Bins robustes (Freedman–Diaconis) ; repli sur 'auto' si nécessaire\n",
    "try:\n",
    "    bins = np.histogram_bin_edges(x, bins='fd')\n",
    "    if np.isinf(bins).any() or len(bins) < 2:\n",
    "        raise ValueError\n",
    "except Exception:\n",
    "    bins = 'auto'\n",
    "\n",
    "# Mise en forme \"milliers avec espace\"\n",
    "fmt = FuncFormatter(lambda v, pos: f\"{v:,.0f}\".replace(\",\", \" \"))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(9, 5), dpi=120)\n",
    "\n",
    "# Histogramme (effectifs)\n",
    "n, b, patches = ax.hist(\n",
    "    x, bins=bins, density=False,\n",
    "    edgecolor='white', linewidth=0.8, alpha=0.9\n",
    ")\n",
    "\n",
    "# Lignes moyenne / médiane\n",
    "moy = np.mean(x)\n",
    "med = np.median(x)\n",
    "ax.axvline(moy, linestyle='--', linewidth=1.6, label=f\"Moyenne = {moy:,.0f}\".replace(\",\", \" \"))\n",
    "ax.axvline(med, linestyle=':',  linewidth=1.6, label=f\"Médiane = {med:,.0f}\".replace(\",\", \" \"))\n",
    "\n",
    "# Habillage\n",
    "ax.set_title(\"Distribution de original_upb\", pad=10)\n",
    "ax.set_xlabel(\"original_upb\")\n",
    "ax.set_ylabel(\"Effectifs\")\n",
    "ax.grid(axis='y', linestyle=':', alpha=0.5)\n",
    "ax.xaxis.set_major_formatter(fmt)\n",
    "ax.yaxis.set_major_formatter(fmt)\n",
    "ax.legend(frameon=False, loc='upper right')\n",
    "\n",
    "# (Optionnel) Utile si très asymétrique :\n",
    "# ax.set_xscale('log')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643f22ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemple : df est votre DataFrame et la colonne s’appelle 'status'\n",
    "# 1) Lister les modalités (valeurs distinctes)\n",
    "df_train['default_24m'].unique()\n",
    "\n",
    "# 2) Compter chaque modalité\n",
    "df['status'].value_counts()\n",
    "\n",
    "# 3) N’afficher que les lignes dont la modalité est 'default'\n",
    "df_default = df[df['status'].eq('default')]        # équiv. : df.query(\"status == 'default'\")\n",
    "\n",
    "# 4) Nombre et proportion de 'default'\n",
    "nb_default = df['status'].eq('default').sum()\n",
    "prop_default = df['status'].eq('default').mean()   # proportion entre 0 et 1\n",
    "\n",
    "# 5) Si la colonne est codée 0/1, la mapper vers des libellés puis (optionnel) en catégorie ordonnée\n",
    "df['status'] = df['status'].map({1: 'default', 0: 'non-default'}).astype('category')\n",
    "\n",
    "from pandas.api.types import CategoricalDtype\n",
    "cat = CategoricalDtype(categories=['non-default', 'default'], ordered=True)\n",
    "df['status'] = df['status'].astype(cat)\n",
    "\n",
    "# 6) Afficher la catégorie 'default' (si dtype catégoriel) et vérifier qu’elle existe\n",
    "'default' in df['status'].cat.categories\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pd-calibration-NMoSp0fs-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
