{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62cd6437",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['credit_score', 'first_payment_date', 'first_time_homebuyer_flag',\n",
       "       'maturity_date', 'msa_md', 'mi_percent', 'number_of_units',\n",
       "       'occupancy_status', 'original_cltv', 'original_dti', 'original_upb',\n",
       "       'original_ltv', 'original_interest_rate', 'channel', 'ppm_flag',\n",
       "       'amortization_type', 'property_state', 'property_type', 'postal_code',\n",
       "       'loan_sequence_number', 'loan_purpose', 'original_loan_term',\n",
       "       'number_of_borrowers', 'seller_name', 'servicer_name',\n",
       "       'super_conforming_flag', 'pre_relief_refi_loan_seq_number',\n",
       "       'special_eligibility_program', 'relief_refinance_indicator',\n",
       "       'property_valuation_method', 'interest_only_indicator',\n",
       "       'mi_cancellation_indicator', 'default_24m', '__file_quarter', 'vintage',\n",
       "       'window', 'quarter'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pandas import read_json\n",
    "\n",
    "data_oos = pd.read_parquet(\"../data/processed/default_labels/window=24m/oos.parquet\")\n",
    "data_oos.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b9af3db2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['vintage', 'loan_sequence_number', 'default_24m', 'score_ttc', 'pd',\n",
      "       'grade'],\n",
      "      dtype='object')\n",
      "Index(['__file_quarter__BIN', 'amortization_type__BIN', 'channel__BIN',\n",
      "       'first_time_homebuyer_flag__BIN', 'interest_only_indicator__BIN',\n",
      "       'loan_purpose__BIN', 'number_of_borrowers__BIN', 'number_of_units__BIN',\n",
      "       'occupancy_status__BIN', 'ppm_flag__BIN', 'property_state__BIN',\n",
      "       'property_type__BIN', 'property_valuation_method__BIN', 'quarter__BIN',\n",
      "       'relief_refinance_indicator__BIN', 'special_eligibility_program__BIN',\n",
      "       'super_conforming_flag__BIN', 'window__BIN', 'credit_score__BIN',\n",
      "       'mi_percent__BIN', 'original_cltv__BIN', 'original_dti__BIN',\n",
      "       'original_interest_rate__BIN', 'original_loan_term__BIN',\n",
      "       'original_ltv__BIN', 'original_upb__BIN', 'default_24m', 'vintage',\n",
      "       'loan_sequence_number'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "oos_classif = pd.read_parquet(\"../data/processed/scored/validation_scored.parquet\")\n",
    "print(oos_classif.columns)\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "df_binned_val = pd.read_parquet(\"../data/processed/binned/validation.parquet\")\n",
    "print(df_binned_val.columns)\n",
    "\n",
    "# import pandas as pd\n",
    "# oos_classif = pd.read_csv(\"../artifacts/model_from_binned/validation_scored.csv\")\n",
    "# print(oos_classif.columns)\n",
    "# print(oos_classif)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65089ca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    5.677148e+06\n",
      "mean     9.921210e-03\n",
      "std      1.216917e-02\n",
      "min      0.000000e+00\n",
      "25%      1.829386e-03\n",
      "50%      4.982932e-03\n",
      "75%      1.306956e-02\n",
      "max      1.312057e-01\n",
      "Name: pd, dtype: float64\n",
      "0.012124221528133493\n",
      "                   pd  default_24m\n",
      "pd           1.000000     0.113705\n",
      "default_24m  0.113705     1.000000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_parquet(\"../data/processed/scored/oos_scored.parquet\")\n",
    "print(df[\"pd\"].describe())\n",
    "print(df[\"default_24m\"].mean())\n",
    "print(df[[\"pd\", \"default_24m\"]].corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "381fb1f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   grade  nb_defaut  nb_individus  taux_defaut\n",
      "0      1         11          3520     0.003125\n",
      "1      2         51          9956     0.005123\n",
      "2      3         97         13949     0.006954\n",
      "3      4        186         20102     0.009253\n",
      "4      5        287         22058     0.013011\n",
      "5      6        568         28761     0.019749\n",
      "6      7        809         31486     0.025694\n",
      "7      8       1336         36907     0.036199\n",
      "8      9       2618         49332     0.053069\n",
      "9     10       6309         63790     0.098903\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import pandas as pd\n",
    "# df = pd.read_parquet(\"../data/processed/scored/oos_scored.parquet\")\n",
    "df = pd.read_parquet(\"../data/processed/scored/validation_scored.parquet\")\n",
    "\n",
    "def tables_par_vintage_defaut(\n",
    "    df,\n",
    "    vintage_col=\"vintage\",\n",
    "    grade_col=\"grade\",\n",
    "    default_col=\"default_24m\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Retourne un dict {vintage: DataFrame} où chaque DataFrame contient, pour chaque grade :\n",
    "      - nb_defaut : nombre de défauts\n",
    "      - nb_individus : nombre total d'individus\n",
    "      - taux_defaut : nb_defaut / nb_individus\n",
    "    \"\"\"\n",
    "    # Tableau global (vintage, grade)\n",
    "    table_global = (\n",
    "        df\n",
    "        .groupby([vintage_col, grade_col])[default_col]\n",
    "        .agg(\n",
    "            nb_defaut=\"sum\",\n",
    "            nb_individus=\"count\"\n",
    "        )\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    table_global[\"taux_defaut\"] = (\n",
    "        table_global[\"nb_defaut\"] / table_global[\"nb_individus\"]\n",
    "    )\n",
    "\n",
    "    # Dictionnaire : un DataFrame par vintage\n",
    "    dict_tables = {\n",
    "        vintage: sub_df.drop(columns=[vintage_col]).reset_index(drop=True)\n",
    "        for vintage, sub_df in table_global.groupby(vintage_col)\n",
    "    }\n",
    "\n",
    "    return dict_tables\n",
    "\n",
    "\n",
    "res = tables_par_vintage_defaut(df)\n",
    "\n",
    "# print(res)\n",
    "print(res[\"2019Q1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d5b25d1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "grade",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "nb_defaut",
         "rawType": "Int64",
         "type": "integer"
        },
        {
         "name": "nb_individus",
         "rawType": "Int64",
         "type": "integer"
        },
        {
         "name": "taux_defaut",
         "rawType": "Float64",
         "type": "float"
        },
        {
         "name": "pd_ttc",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "9782f79d-fc7b-4b76-b32b-5725ad0a139a",
       "rows": [
        [
         "0",
         "1",
         "1401",
         "54875",
         "0.025530751708428247",
         "0.00033959080050004377"
        ],
        [
         "1",
         "2",
         "2034",
         "113543",
         "0.017913918075090494",
         "0.0008062636699327342"
        ],
        [
         "2",
         "3",
         "1287",
         "120367",
         "0.010692299384382762",
         "0.0014292730411460063"
        ],
        [
         "3",
         "4",
         "1003",
         "129275",
         "0.007758654032102108",
         "0.0021524941392147166"
        ],
        [
         "4",
         "5",
         "701",
         "136026",
         "0.005153426550806464",
         "0.0033791074963156627"
        ],
        [
         "5",
         "6",
         "549",
         "129412",
         "0.004242265014063611",
         "0.00516126592808258"
        ],
        [
         "6",
         "7",
         "454",
         "151156",
         "0.003003519542724073",
         "0.007876324344019175"
        ],
        [
         "7",
         "8",
         "326",
         "144636",
         "0.0022539340136618824",
         "0.012376347952182428"
        ],
        [
         "8",
         "9",
         "207",
         "147170",
         "0.0014065366582863355",
         "0.021471906928679767"
        ],
        [
         "9",
         "10",
         "83",
         "93126",
         "0.00089126559714795",
         "0.04935974839235068"
        ]
       ],
       "shape": {
        "columns": 5,
        "rows": 10
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>grade</th>\n",
       "      <th>nb_defaut</th>\n",
       "      <th>nb_individus</th>\n",
       "      <th>taux_defaut</th>\n",
       "      <th>pd_ttc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1401</td>\n",
       "      <td>54875</td>\n",
       "      <td>0.025531</td>\n",
       "      <td>0.000340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2034</td>\n",
       "      <td>113543</td>\n",
       "      <td>0.017914</td>\n",
       "      <td>0.000806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1287</td>\n",
       "      <td>120367</td>\n",
       "      <td>0.010692</td>\n",
       "      <td>0.001429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1003</td>\n",
       "      <td>129275</td>\n",
       "      <td>0.007759</td>\n",
       "      <td>0.002152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>701</td>\n",
       "      <td>136026</td>\n",
       "      <td>0.005153</td>\n",
       "      <td>0.003379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>549</td>\n",
       "      <td>129412</td>\n",
       "      <td>0.004242</td>\n",
       "      <td>0.005161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>454</td>\n",
       "      <td>151156</td>\n",
       "      <td>0.003004</td>\n",
       "      <td>0.007876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>326</td>\n",
       "      <td>144636</td>\n",
       "      <td>0.002254</td>\n",
       "      <td>0.012376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>207</td>\n",
       "      <td>147170</td>\n",
       "      <td>0.001407</td>\n",
       "      <td>0.021472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>83</td>\n",
       "      <td>93126</td>\n",
       "      <td>0.000891</td>\n",
       "      <td>0.049360</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   grade  nb_defaut  nb_individus  taux_defaut    pd_ttc\n",
       "0      1       1401         54875     0.025531  0.000340\n",
       "1      2       2034        113543     0.017914  0.000806\n",
       "2      3       1287        120367     0.010692  0.001429\n",
       "3      4       1003        129275     0.007759  0.002152\n",
       "4      5        701        136026     0.005153  0.003379\n",
       "5      6        549        129412     0.004242  0.005161\n",
       "6      7        454        151156     0.003004  0.007876\n",
       "7      8        326        144636     0.002254  0.012376\n",
       "8      9        207        147170     0.001407  0.021472\n",
       "9     10         83         93126     0.000891  0.049360"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "\n",
    "\n",
    "def tables_par_vintage_defaut_avec_pd_ttc(\n",
    "    df,\n",
    "    bucket_stats_path=\"bucket_stats.json\",\n",
    "    vintage_col=\"vintage\",\n",
    "    grade_col=\"grade\",\n",
    "    default_col=\"default_24m\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Construit un dict {vintage: DataFrame} où chaque DataFrame contient, pour chaque grade :\n",
    "      - nb_defaut   : nombre de défauts observés (somme des 0/1)\n",
    "      - nb_individus: nombre total de lignes\n",
    "      - taux_defaut : nb_defaut / nb_individus\n",
    "      - pd_ttc      : PD TTC issue de bucket_stats.json (section 'train', champ 'pd'),\n",
    "                      en supposant que 'grade' == 'bucket'.\n",
    "    \"\"\"\n",
    "\n",
    "    # 1) Charger le fichier JSON avec les stats de buckets\n",
    "    with open(bucket_stats_path, \"r\") as f:\n",
    "        bucket_stats = json.load(f)\n",
    "\n",
    "    # 2) Construire un mapping bucket -> pd à partir de la section \"train\"\n",
    "    pd_map = {entry[\"bucket\"]: entry[\"pd\"] for entry in bucket_stats[\"train\"]}\n",
    "\n",
    "    # 3) Tableau global (vintage, grade) avec nb_defaut & nb_individus\n",
    "    table_global = (\n",
    "        df\n",
    "        .groupby([vintage_col, grade_col])[default_col]\n",
    "        .agg(\n",
    "            nb_defaut=\"sum\",\n",
    "            nb_individus=\"count\"\n",
    "        )\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    # 4) Calcul du taux de défaut\n",
    "    table_global[\"taux_defaut\"] = (\n",
    "        table_global[\"nb_defaut\"] / table_global[\"nb_individus\"]\n",
    "    )\n",
    "\n",
    "    # 5) Ajout de la PD TTC selon le grade/bucket\n",
    "    table_global[\"pd_ttc\"] = table_global[grade_col].map(pd_map)\n",
    "\n",
    "    # 6) Un DataFrame par vintage, sans la colonne vintage\n",
    "    dict_tables = {\n",
    "        vintage: sub_df.drop(columns=[vintage_col]).reset_index(drop=True)\n",
    "        for vintage, sub_df in table_global.groupby(vintage_col)\n",
    "    }\n",
    "\n",
    "    return dict_tables\n",
    "\n",
    "\n",
    "# df = ton DataFrame de départ\n",
    "tables_vintage = tables_par_vintage_defaut_avec_pd_ttc(df, \"../artifacts/model_from_binned/bucket_stats.json\")\n",
    "\n",
    "# Exemple : tableau pour la vintage 2021Q1\n",
    "tables_vintage[\"2021Q1\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "21ee8ae8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         credit_score first_payment_date first_time_homebuyer_flag  \\\n",
      "0               725.0         2021-03-31                         Y   \n",
      "1               737.0         2021-03-31                         N   \n",
      "2               744.0         2021-05-31                         N   \n",
      "3               676.0         2021-04-30                         N   \n",
      "4               765.0         2021-03-31                         N   \n",
      "...               ...                ...                       ...   \n",
      "5677143         791.0         2024-08-31                         N   \n",
      "5677144         750.0         2024-05-31                         N   \n",
      "5677145         773.0         2024-07-31                         N   \n",
      "5677146         817.0         2024-08-31                         N   \n",
      "5677147         696.0         2024-09-30                         N   \n",
      "\n",
      "        maturity_date   msa_md  mi_percent  number_of_units occupancy_status  \\\n",
      "0              205102  15804.0         0.0              1.0                P   \n",
      "1              205102      NaN         0.0              1.0                P   \n",
      "2              204104  48864.0         6.0              1.0                P   \n",
      "3              204103      NaN         0.0              1.0                P   \n",
      "4              203602  12700.0         0.0              1.0                S   \n",
      "...               ...      ...         ...              ...              ...   \n",
      "5677143        205407  19804.0         0.0              1.0                P   \n",
      "5677144        205404  48424.0        25.0              1.0                P   \n",
      "5677145        205406  27260.0         0.0              1.0                P   \n",
      "5677146        205407  45104.0         0.0              1.0                P   \n",
      "5677147        205408  24340.0         0.0              1.0                P   \n",
      "\n",
      "         original_cltv  original_dti  ...  interest_only_indicator  \\\n",
      "0                 80.0          30.0  ...                        N   \n",
      "1                 74.0          27.0  ...                        N   \n",
      "2                 85.0          34.0  ...                        N   \n",
      "3                 79.0          23.0  ...                        N   \n",
      "4                 60.0          43.0  ...                        N   \n",
      "...                ...           ...  ...                      ...   \n",
      "5677143           69.0          29.0  ...                        N   \n",
      "5677144           90.0          50.0  ...                        N   \n",
      "5677145           38.0          35.0  ...                        N   \n",
      "5677146           55.0          35.0  ...                        N   \n",
      "5677147           67.0          44.0  ...                        N   \n",
      "\n",
      "         mi_cancellation_indicator  default_24m __file_quarter vintage window  \\\n",
      "0                                7            0         2021Q1  2021Q1    24m   \n",
      "1                                7            0         2021Q1  2021Q1    24m   \n",
      "2                                Y            0         2021Q1  2021Q1    24m   \n",
      "3                                7            0         2021Q1  2021Q1    24m   \n",
      "4                                7            0         2021Q1  2021Q1    24m   \n",
      "...                            ...          ...            ...     ...    ...   \n",
      "5677143                          7            0         2022Q4  2022Q4    24m   \n",
      "5677144                          N            1         2022Q4  2022Q4    24m   \n",
      "5677145                          7            0         2022Q4  2022Q4    24m   \n",
      "5677146                          7            0         2022Q4  2022Q4    24m   \n",
      "5677147                          7            0         2022Q4  2022Q4    24m   \n",
      "\n",
      "        quarter  score_lr    pd_hat bucket  \n",
      "0        2021Q1 -4.140081  0.015672      7  \n",
      "1        2021Q1 -4.140081  0.015672      7  \n",
      "2        2021Q1 -4.140081  0.015672      7  \n",
      "3        2021Q1 -4.140081  0.015672      7  \n",
      "4        2021Q1 -4.140081  0.015672      7  \n",
      "...         ...       ...       ...    ...  \n",
      "5677143  2022Q4 -4.140081  0.015672      7  \n",
      "5677144  2022Q4 -4.140081  0.015672      7  \n",
      "5677145  2022Q4 -4.140081  0.015672      7  \n",
      "5677146  2022Q4 -4.140081  0.015672      7  \n",
      "5677147  2022Q4 -4.140081  0.015672      7  \n",
      "\n",
      "[5677148 rows x 40 columns]\n"
     ]
    }
   ],
   "source": [
    "print(oos_classif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "15f98879",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'risk_bucket'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[40]\u001b[39m\u001b[32m, line 43\u001b[39m\n\u001b[32m     37\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m res\n\u001b[32m     40\u001b[39m \u001b[38;5;66;03m# ===== Tableau global sur l'année (tous vintages confondus) =====\u001b[39;00m\n\u001b[32m     41\u001b[39m year_agg = (\n\u001b[32m     42\u001b[39m     \u001b[43moos_classif\u001b[49m\n\u001b[32m---> \u001b[39m\u001b[32m43\u001b[39m \u001b[43m    \u001b[49m\u001b[43m.\u001b[49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrisk_bucket\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     44\u001b[39m     .agg(\n\u001b[32m     45\u001b[39m         n=(\u001b[33m\"\u001b[39m\u001b[33mproba\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33msize\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m     46\u001b[39m         n_default=(\u001b[33m\"\u001b[39m\u001b[33mdefault_24m\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33msum\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m     47\u001b[39m         pd_obs=(\u001b[33m\"\u001b[39m\u001b[33mdefault_24m\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmean\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m     48\u001b[39m         pd_hat=(\u001b[33m\"\u001b[39m\u001b[33mproba\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmean\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m     49\u001b[39m     )\n\u001b[32m     50\u001b[39m     .reset_index()\n\u001b[32m     51\u001b[39m     .sort_values(\u001b[33m\"\u001b[39m\u001b[33mrisk_bucket\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     52\u001b[39m )\n\u001b[32m     55\u001b[39m year_agg[\u001b[33m\"\u001b[39m\u001b[33mpd_obs\u001b[39m\u001b[33m\"\u001b[39m] = year_agg[\u001b[33m\"\u001b[39m\u001b[33mpd_obs\u001b[39m\u001b[33m\"\u001b[39m].round(\u001b[32m6\u001b[39m)\n\u001b[32m     56\u001b[39m year_agg[\u001b[33m\"\u001b[39m\u001b[33mpd_hat\u001b[39m\u001b[33m\"\u001b[39m] = year_agg[\u001b[33m\"\u001b[39m\u001b[33mpd_hat\u001b[39m\u001b[33m\"\u001b[39m].round(\u001b[32m6\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/pd-calibration-NMoSp0fs-py3.12/lib/python3.12/site-packages/pandas/core/frame.py:9190\u001b[39m, in \u001b[36mDataFrame.groupby\u001b[39m\u001b[34m(self, by, axis, level, as_index, sort, group_keys, observed, dropna)\u001b[39m\n\u001b[32m   9187\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m level \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m by \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   9188\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mYou have to supply one of \u001b[39m\u001b[33m'\u001b[39m\u001b[33mby\u001b[39m\u001b[33m'\u001b[39m\u001b[33m and \u001b[39m\u001b[33m'\u001b[39m\u001b[33mlevel\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m9190\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameGroupBy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   9191\u001b[39m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   9192\u001b[39m \u001b[43m    \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m=\u001b[49m\u001b[43mby\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9193\u001b[39m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9194\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9195\u001b[39m \u001b[43m    \u001b[49m\u001b[43mas_index\u001b[49m\u001b[43m=\u001b[49m\u001b[43mas_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9196\u001b[39m \u001b[43m    \u001b[49m\u001b[43msort\u001b[49m\u001b[43m=\u001b[49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9197\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgroup_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9198\u001b[39m \u001b[43m    \u001b[49m\u001b[43mobserved\u001b[49m\u001b[43m=\u001b[49m\u001b[43mobserved\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9199\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdropna\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdropna\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9200\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/pd-calibration-NMoSp0fs-py3.12/lib/python3.12/site-packages/pandas/core/groupby/groupby.py:1330\u001b[39m, in \u001b[36mGroupBy.__init__\u001b[39m\u001b[34m(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, observed, dropna)\u001b[39m\n\u001b[32m   1327\u001b[39m \u001b[38;5;28mself\u001b[39m.dropna = dropna\n\u001b[32m   1329\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m grouper \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1330\u001b[39m     grouper, exclusions, obj = \u001b[43mget_grouper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1331\u001b[39m \u001b[43m        \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1332\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1333\u001b[39m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1334\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1335\u001b[39m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[43m=\u001b[49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1336\u001b[39m \u001b[43m        \u001b[49m\u001b[43mobserved\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobserved\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mlib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mno_default\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobserved\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1337\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdropna\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdropna\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1338\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1340\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m observed \u001b[38;5;129;01mis\u001b[39;00m lib.no_default:\n\u001b[32m   1341\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(ping._passed_categorical \u001b[38;5;28;01mfor\u001b[39;00m ping \u001b[38;5;129;01min\u001b[39;00m grouper.groupings):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/pd-calibration-NMoSp0fs-py3.12/lib/python3.12/site-packages/pandas/core/groupby/grouper.py:1043\u001b[39m, in \u001b[36mget_grouper\u001b[39m\u001b[34m(obj, key, axis, level, sort, observed, validate, dropna)\u001b[39m\n\u001b[32m   1041\u001b[39m         in_axis, level, gpr = \u001b[38;5;28;01mFalse\u001b[39;00m, gpr, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1042\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1043\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(gpr)\n\u001b[32m   1044\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(gpr, Grouper) \u001b[38;5;129;01mand\u001b[39;00m gpr.key \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1045\u001b[39m     \u001b[38;5;66;03m# Add key to exclusions\u001b[39;00m\n\u001b[32m   1046\u001b[39m     exclusions.add(gpr.key)\n",
      "\u001b[31mKeyError\u001b[39m: 'risk_bucket'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def vintage_grade_table(\n",
    "    df,\n",
    "    vint,\n",
    "    vintage_col=\"vintage\",\n",
    "    grade_col=\"risk_bucket\",\n",
    "    target_col=\"default_24m\",\n",
    "    proba_col=\"proba\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Retourne un tableau avec, pour un vintage donné :\n",
    "      - une ligne par grade\n",
    "      - n               : nombre d'individus dans le grade\n",
    "      - n_default       : nombre de défauts observés\n",
    "      - pd_obs          : proportion de défaut observée\n",
    "      - pd_hat          : proba moyenne attribuée à la classe (moyenne des proba individuelles)\n",
    "    \"\"\"\n",
    "    sub = df[df[vintage_col] == vint].copy()\n",
    "\n",
    "    res = (\n",
    "        sub.groupby(grade_col)\n",
    "        .agg(\n",
    "            n=(proba_col, \"size\"),\n",
    "            n_default=(target_col, \"sum\"),\n",
    "            pd_obs=(target_col, \"mean\"),\n",
    "            pd_hat=(proba_col, \"mean\"),\n",
    "        )\n",
    "        .reset_index()\n",
    "        .sort_values(grade_col)\n",
    "    )\n",
    "\n",
    "    # Optionnel : arrondir un peu pour la lisibilité\n",
    "    res[\"pd_obs\"] = res[\"pd_obs\"].round(6)\n",
    "    res[\"pd_hat\"] = res[\"pd_hat\"].round(6)\n",
    "\n",
    "    return res\n",
    "\n",
    "\n",
    "# ===== Tableau global sur l'année (tous vintages confondus) =====\n",
    "year_agg = (\n",
    "    oos_classif\n",
    "    .groupby(\"risk_bucket\")\n",
    "    .agg(\n",
    "        n=(\"proba\", \"size\"),\n",
    "        n_default=(\"default_24m\", \"sum\"),\n",
    "        pd_obs=(\"default_24m\", \"mean\"),\n",
    "        pd_hat=(\"proba\", \"mean\"),\n",
    "    )\n",
    "    .reset_index()\n",
    "    .sort_values(\"risk_bucket\")\n",
    ")\n",
    "\n",
    "\n",
    "year_agg[\"pd_obs\"] = year_agg[\"pd_obs\"].round(6)\n",
    "year_agg[\"pd_hat\"] = year_agg[\"pd_hat\"].round(6)\n",
    "\n",
    "print(\"\\n===== Année complète (tous vintages) =====\")\n",
    "print(year_agg)\n",
    "\n",
    "\n",
    "# ===== Agrégat par vintage × grade (pour affichage par vintage) =====\n",
    "agg = (\n",
    "    oos_classif\n",
    "    .groupby([\"vintage\", \"risk_bucket\"])\n",
    "    .agg(\n",
    "        n=(\"proba\", \"size\"),\n",
    "        n_default=(\"default_24m\", \"sum\"),\n",
    "        pd_obs=(\"default_24m\", \"mean\"),\n",
    "        pd_hat=(\"proba\", \"mean\"),\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "agg[\"pd_obs\"] = agg[\"pd_obs\"].round(6)\n",
    "agg[\"pd_hat\"] = agg[\"pd_hat\"].round(6)\n",
    "\n",
    "# Afficher le head pour chaque vintage\n",
    "for vint, sub in agg.groupby(\"vintage\"):\n",
    "    print(f\"\\n===== Vintage {vint} =====\")\n",
    "    print(sub.sort_values(\"risk_bucket\").head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65893866",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- ANALYSE CIBLE VALIDATION (2019-2020) ---\n",
      "default_24m\n",
      "0    5566820\n",
      "1     128068\n",
      "Name: count, dtype: Int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# On charge la VALIDATION (là où l'AUC est mauvais)\n",
    "# On prend le fichier 'imputed' car c'est lui qui entre dans le scoring\n",
    "df_val = pd.read_parquet(\"../data/processed/imputed/validation.parquet\")\n",
    "\n",
    "print(\"--- ANALYSE CIBLE VALIDATION (2019-2020) ---\")\n",
    "if \"default_24m\" in df_val.columns:\n",
    "    print(df_val[\"default_24m\"].value_counts(dropna=False))\n",
    "else:\n",
    "    print(\"La colonne default_24m n'est même pas là !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5d51152",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- ANALYSE DE LA PD (Le coupable de l'AUC 0.50) ---\n",
      "count    5.694888e+06\n",
      "mean     2.453348e-09\n",
      "std      4.834260e-07\n",
      "min      0.000000e+00\n",
      "25%      0.000000e+00\n",
      "50%      0.000000e+00\n",
      "75%      0.000000e+00\n",
      "max      3.168591e-04\n",
      "Name: pd, dtype: float64\n",
      "\n",
      "Nombre de clients avec PD ≈ 0 : 5694609 / 5694888\n",
      "Pourcentage saturé à 0 : 100.00%\n",
      "\n",
      "--- VISUALISATION ---\n",
      "        loan_sequence_number  score   pd  grade  default_24m\n",
      "1038961         F19Q30346847    860  0.0     10            0\n",
      "4116086         F20Q30893459    817  0.0     10            0\n",
      "1088161         F19Q30396166    852  0.0     10            0\n",
      "1592564         F19Q40357746    873  0.0     10            0\n",
      "3394692         F20Q30170743    870  0.0     10            0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "path = \"../data/processed/scored/validation_scored.parquet\"\n",
    "df = pd.read_parquet(path)\n",
    "\n",
    "print(f\"\\n--- ANALYSE DE LA PD (Le coupable de l'AUC 0.50) ---\")\n",
    "print(df[\"pd\"].describe())\n",
    "\n",
    "# Vérification saturation\n",
    "zeros = (df[\"pd\"] < 0.000001).sum()\n",
    "print(f\"\\nNombre de clients avec PD ≈ 0 : {zeros} / {len(df)}\")\n",
    "print(f\"Pourcentage saturé à 0 : {zeros/len(df)*100:.2f}%\")\n",
    "\n",
    "print(\"\\n--- VISUALISATION ---\")\n",
    "# On utilise loan_sequence_number\n",
    "cols = [\"loan_sequence_number\", \"score\", \"pd\", \"grade\", \"default_24m\"]\n",
    "# On filtre les colonnes existantes au cas où\n",
    "cols = [c for c in cols if c in df.columns]\n",
    "print(df[cols].sample(5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pd-calibration-NMoSp0fs-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
