{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "66796d7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN shape: (3278827, 33)\n",
      "VAL   shape: (766323, 27)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_train = pd.read_parquet(\"../data/processed/binned/train.parquet\")\n",
    "df_val   = pd.read_parquet(\"../data/processed/binned/validation.parquet\")\n",
    "\n",
    "print(\"TRAIN shape:\", df_train.shape)\n",
    "print(\"VAL   shape:\", df_val.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a149e4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "proba",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "risk_bucket",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "loan_sequence_number",
         "rawType": "string",
         "type": "string"
        },
        {
         "name": "vintage",
         "rawType": "string",
         "type": "string"
        },
        {
         "name": "default_24m",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "4406010a-7f8b-47fd-9c44-d24235abb06c",
       "rows": [
        [
         "0",
         "0.015019084089079981",
         "8",
         "F24Q10000001",
         "2024Q1",
         "0"
        ],
        [
         "1",
         "0.015019084089079981",
         "8",
         "F24Q10000002",
         "2024Q1",
         "0"
        ],
        [
         "2",
         "0.015019084089079981",
         "8",
         "F24Q10000003",
         "2024Q1",
         "0"
        ],
        [
         "3",
         "0.015019084089079981",
         "8",
         "F24Q10000004",
         "2024Q1",
         "0"
        ],
        [
         "4",
         "0.015019084089079981",
         "8",
         "F24Q10000005",
         "2024Q1",
         "0"
        ],
        [
         "5",
         "0.015019084089079981",
         "8",
         "F24Q10000006",
         "2024Q1",
         "0"
        ],
        [
         "6",
         "0.015019084089079981",
         "8",
         "F24Q10000007",
         "2024Q1",
         "0"
        ],
        [
         "7",
         "0.015019084089079981",
         "8",
         "F24Q10000008",
         "2024Q1",
         "0"
        ],
        [
         "8",
         "0.015019084089079981",
         "8",
         "F24Q10000009",
         "2024Q1",
         "0"
        ],
        [
         "9",
         "0.015019084089079981",
         "8",
         "F24Q10000010",
         "2024Q1",
         "0"
        ]
       ],
       "shape": {
        "columns": 5,
        "rows": 10
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>proba</th>\n",
       "      <th>risk_bucket</th>\n",
       "      <th>loan_sequence_number</th>\n",
       "      <th>vintage</th>\n",
       "      <th>default_24m</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.015019</td>\n",
       "      <td>8</td>\n",
       "      <td>F24Q10000001</td>\n",
       "      <td>2024Q1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.015019</td>\n",
       "      <td>8</td>\n",
       "      <td>F24Q10000002</td>\n",
       "      <td>2024Q1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.015019</td>\n",
       "      <td>8</td>\n",
       "      <td>F24Q10000003</td>\n",
       "      <td>2024Q1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.015019</td>\n",
       "      <td>8</td>\n",
       "      <td>F24Q10000004</td>\n",
       "      <td>2024Q1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.015019</td>\n",
       "      <td>8</td>\n",
       "      <td>F24Q10000005</td>\n",
       "      <td>2024Q1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.015019</td>\n",
       "      <td>8</td>\n",
       "      <td>F24Q10000006</td>\n",
       "      <td>2024Q1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.015019</td>\n",
       "      <td>8</td>\n",
       "      <td>F24Q10000007</td>\n",
       "      <td>2024Q1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.015019</td>\n",
       "      <td>8</td>\n",
       "      <td>F24Q10000008</td>\n",
       "      <td>2024Q1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.015019</td>\n",
       "      <td>8</td>\n",
       "      <td>F24Q10000009</td>\n",
       "      <td>2024Q1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.015019</td>\n",
       "      <td>8</td>\n",
       "      <td>F24Q10000010</td>\n",
       "      <td>2024Q1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      proba  risk_bucket loan_sequence_number vintage  default_24m\n",
       "0  0.015019            8         F24Q10000001  2024Q1            0\n",
       "1  0.015019            8         F24Q10000002  2024Q1            0\n",
       "2  0.015019            8         F24Q10000003  2024Q1            0\n",
       "3  0.015019            8         F24Q10000004  2024Q1            0\n",
       "4  0.015019            8         F24Q10000005  2024Q1            0\n",
       "5  0.015019            8         F24Q10000006  2024Q1            0\n",
       "6  0.015019            8         F24Q10000007  2024Q1            0\n",
       "7  0.015019            8         F24Q10000008  2024Q1            0\n",
       "8  0.015019            8         F24Q10000009  2024Q1            0\n",
       "9  0.015019            8         F24Q10000010  2024Q1            0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "oos_score = pd.read_parquet(\"../data/processed/scored/oos_scored.parquet\")\n",
    "oos_score.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "af26e2b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "loan_sequence_number",
         "rawType": "string",
         "type": "string"
        },
        {
         "name": "msa_md",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "postal_code",
         "rawType": "string",
         "type": "string"
        },
        {
         "name": "property_state",
         "rawType": "string",
         "type": "string"
        },
        {
         "name": "seller_name",
         "rawType": "string",
         "type": "string"
        },
        {
         "name": "servicer_name",
         "rawType": "string",
         "type": "string"
        },
        {
         "name": "default_24m",
         "rawType": "Int8",
         "type": "integer"
        },
        {
         "name": "__file_quarter__BIN",
         "rawType": "Int64",
         "type": "integer"
        },
        {
         "name": "amortization_type__BIN",
         "rawType": "Int64",
         "type": "integer"
        },
        {
         "name": "channel__BIN",
         "rawType": "Int64",
         "type": "integer"
        },
        {
         "name": "first_time_homebuyer_flag__BIN",
         "rawType": "Int64",
         "type": "integer"
        },
        {
         "name": "interest_only_indicator__BIN",
         "rawType": "Int64",
         "type": "integer"
        },
        {
         "name": "loan_purpose__BIN",
         "rawType": "Int64",
         "type": "integer"
        },
        {
         "name": "number_of_borrowers__BIN",
         "rawType": "Int64",
         "type": "integer"
        },
        {
         "name": "occupancy_status__BIN",
         "rawType": "Int64",
         "type": "integer"
        },
        {
         "name": "ppm_flag__BIN",
         "rawType": "Int64",
         "type": "integer"
        },
        {
         "name": "property_type__BIN",
         "rawType": "Int64",
         "type": "integer"
        },
        {
         "name": "property_valuation_method__BIN",
         "rawType": "Int64",
         "type": "integer"
        },
        {
         "name": "quarter__BIN",
         "rawType": "Int64",
         "type": "integer"
        },
        {
         "name": "relief_refinance_indicator__BIN",
         "rawType": "Int64",
         "type": "integer"
        },
        {
         "name": "special_eligibility_program__BIN",
         "rawType": "Int64",
         "type": "integer"
        },
        {
         "name": "super_conforming_flag__BIN",
         "rawType": "Int64",
         "type": "integer"
        },
        {
         "name": "window__BIN",
         "rawType": "Int64",
         "type": "integer"
        },
        {
         "name": "has__BIN",
         "rawType": "Int64",
         "type": "integer"
        },
        {
         "name": "credit_score__BIN",
         "rawType": "Int64",
         "type": "integer"
        },
        {
         "name": "mi_percent__BIN",
         "rawType": "Int64",
         "type": "integer"
        },
        {
         "name": "number_of_units__BIN",
         "rawType": "Int64",
         "type": "integer"
        },
        {
         "name": "original_cltv__BIN",
         "rawType": "Int64",
         "type": "integer"
        },
        {
         "name": "original_dti__BIN",
         "rawType": "Int64",
         "type": "integer"
        },
        {
         "name": "original_interest_rate__BIN",
         "rawType": "Int64",
         "type": "integer"
        },
        {
         "name": "original_loan_term__BIN",
         "rawType": "Int64",
         "type": "integer"
        },
        {
         "name": "original_ltv__BIN",
         "rawType": "Int64",
         "type": "integer"
        },
        {
         "name": "original_upb__BIN",
         "rawType": "Int64",
         "type": "integer"
        }
       ],
       "ref": "df26fe5f-71a4-42e5-be35-20fb80f9bbbc",
       "rows": [
        [
         "0",
         "F22Q10000001",
         "47664.0",
         "48000",
         "MI",
         "Other sellers",
         "Other servicers",
         "1",
         "3",
         "0",
         "1",
         "1",
         "0",
         "1",
         "1",
         "2",
         "0",
         "3",
         "4",
         "3",
         "0",
         "0",
         "0",
         "0",
         "0",
         "4",
         "0",
         "0",
         "4",
         "4",
         "0",
         "2",
         "1",
         "4"
        ],
        [
         "1",
         "F22Q10000002",
         "47664.0",
         "48000",
         "MI",
         "Other sellers",
         "Other servicers",
         "0",
         "3",
         "0",
         "1",
         "1",
         "0",
         "2",
         "1",
         "2",
         "0",
         "3",
         "4",
         "3",
         "0",
         "0",
         "0",
         "0",
         "0",
         "1",
         "0",
         "0",
         "1",
         "0",
         "0",
         "0",
         "0",
         "4"
        ],
        [
         "2",
         "F22Q10000003",
         "0.0",
         "81200",
         "CO",
         "Other sellers",
         "U.S. BANK N.A.",
         "0",
         "3",
         "0",
         "1",
         "1",
         "0",
         "2",
         "1",
         "2",
         "0",
         "3",
         "4",
         "3",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "1",
         "0",
         "3",
         "0",
         "0",
         "0",
         "2"
        ],
        [
         "3",
         "F22Q10000004",
         "33460.0",
         "54000",
         "WI",
         "Other sellers",
         "Other servicers",
         "0",
         "3",
         "0",
         "1",
         "1",
         "0",
         "1",
         "3",
         "2",
         "0",
         "3",
         "4",
         "3",
         "0",
         "0",
         "0",
         "0",
         "0",
         "5",
         "0",
         "0",
         "2",
         "0",
         "0",
         "2",
         "2",
         "2"
        ],
        [
         "4",
         "F22Q10000005",
         "0.0",
         "14800",
         "NY",
         "Other sellers",
         "Other servicers",
         "0",
         "3",
         "0",
         "1",
         "1",
         "0",
         "0",
         "3",
         "2",
         "0",
         "3",
         "4",
         "3",
         "0",
         "0",
         "0",
         "0",
         "0",
         "4",
         "0",
         "0",
         "1",
         "3",
         "0",
         "2",
         "1",
         "1"
        ]
       ],
       "shape": {
        "columns": 33,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loan_sequence_number</th>\n",
       "      <th>msa_md</th>\n",
       "      <th>postal_code</th>\n",
       "      <th>property_state</th>\n",
       "      <th>seller_name</th>\n",
       "      <th>servicer_name</th>\n",
       "      <th>default_24m</th>\n",
       "      <th>__file_quarter__BIN</th>\n",
       "      <th>amortization_type__BIN</th>\n",
       "      <th>channel__BIN</th>\n",
       "      <th>...</th>\n",
       "      <th>has__BIN</th>\n",
       "      <th>credit_score__BIN</th>\n",
       "      <th>mi_percent__BIN</th>\n",
       "      <th>number_of_units__BIN</th>\n",
       "      <th>original_cltv__BIN</th>\n",
       "      <th>original_dti__BIN</th>\n",
       "      <th>original_interest_rate__BIN</th>\n",
       "      <th>original_loan_term__BIN</th>\n",
       "      <th>original_ltv__BIN</th>\n",
       "      <th>original_upb__BIN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>F22Q10000001</td>\n",
       "      <td>47664.0</td>\n",
       "      <td>48000</td>\n",
       "      <td>MI</td>\n",
       "      <td>Other sellers</td>\n",
       "      <td>Other servicers</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>F22Q10000002</td>\n",
       "      <td>47664.0</td>\n",
       "      <td>48000</td>\n",
       "      <td>MI</td>\n",
       "      <td>Other sellers</td>\n",
       "      <td>Other servicers</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>F22Q10000003</td>\n",
       "      <td>0.0</td>\n",
       "      <td>81200</td>\n",
       "      <td>CO</td>\n",
       "      <td>Other sellers</td>\n",
       "      <td>U.S. BANK N.A.</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F22Q10000004</td>\n",
       "      <td>33460.0</td>\n",
       "      <td>54000</td>\n",
       "      <td>WI</td>\n",
       "      <td>Other sellers</td>\n",
       "      <td>Other servicers</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>F22Q10000005</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14800</td>\n",
       "      <td>NY</td>\n",
       "      <td>Other sellers</td>\n",
       "      <td>Other servicers</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  loan_sequence_number   msa_md postal_code property_state    seller_name  \\\n",
       "0         F22Q10000001  47664.0       48000             MI  Other sellers   \n",
       "1         F22Q10000002  47664.0       48000             MI  Other sellers   \n",
       "2         F22Q10000003      0.0       81200             CO  Other sellers   \n",
       "3         F22Q10000004  33460.0       54000             WI  Other sellers   \n",
       "4         F22Q10000005      0.0       14800             NY  Other sellers   \n",
       "\n",
       "     servicer_name  default_24m  __file_quarter__BIN  amortization_type__BIN  \\\n",
       "0  Other servicers            1                    3                       0   \n",
       "1  Other servicers            0                    3                       0   \n",
       "2   U.S. BANK N.A.            0                    3                       0   \n",
       "3  Other servicers            0                    3                       0   \n",
       "4  Other servicers            0                    3                       0   \n",
       "\n",
       "   channel__BIN  ...  has__BIN  credit_score__BIN  mi_percent__BIN  \\\n",
       "0             1  ...         0                  4                0   \n",
       "1             1  ...         0                  1                0   \n",
       "2             1  ...         0                  0                0   \n",
       "3             1  ...         0                  5                0   \n",
       "4             1  ...         0                  4                0   \n",
       "\n",
       "   number_of_units__BIN  original_cltv__BIN  original_dti__BIN  \\\n",
       "0                     0                   4                  4   \n",
       "1                     0                   1                  0   \n",
       "2                     1                   0                  3   \n",
       "3                     0                   2                  0   \n",
       "4                     0                   1                  3   \n",
       "\n",
       "   original_interest_rate__BIN  original_loan_term__BIN  original_ltv__BIN  \\\n",
       "0                            0                        2                  1   \n",
       "1                            0                        0                  0   \n",
       "2                            0                        0                  0   \n",
       "3                            0                        2                  2   \n",
       "4                            0                        2                  1   \n",
       "\n",
       "   original_upb__BIN  \n",
       "0                  4  \n",
       "1                  4  \n",
       "2                  2  \n",
       "3                  2  \n",
       "4                  1  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9fcccc31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['default_24m', 'vintage', 'credit_score', 'mi_percent',\n",
      "       'number_of_units', 'occupancy_status', 'original_cltv', 'original_dti',\n",
      "       'original_upb', 'original_ltv', 'original_interest_rate', 'channel',\n",
      "       'ppm_flag', 'amortization_type', 'property_state', 'property_type',\n",
      "       'loan_purpose', 'original_loan_term', 'number_of_borrowers',\n",
      "       'super_conforming_flag', 'special_eligibility_program',\n",
      "       'relief_refinance_indicator', 'property_valuation_method',\n",
      "       'interest_only_indicator', 'msa_md', 'has_mi',\n",
      "       'first_time_homebuyer_flag'],\n",
      "      dtype='object')\n",
      "(250000, 27)\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_parquet(\"../data/student/train_250000_p6.parquet\")\n",
    "print(df_train.columns)\n",
    "print(df_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e825d569",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  __file_quarter amortization_type channel  credit_score first_payment_date  \\\n",
      "0         2022Q1               FRM       R           763         2022-03-31   \n",
      "1         2022Q1               FRM       R           691         2022-03-31   \n",
      "2         2022Q1               FRM       R           678         2022-03-31   \n",
      "3         2022Q1               FRM       R           802         2022-03-31   \n",
      "4         2022Q1               FRM       R           767         2022-03-31   \n",
      "\n",
      "  first_time_homebuyer_flag interest_only_indicator loan_purpose  \\\n",
      "0                         N                       N            P   \n",
      "1                         N                       N            C   \n",
      "2                         N                       N            C   \n",
      "3                         N                       N            P   \n",
      "4                         N                       N            N   \n",
      "\n",
      "  loan_sequence_number  maturity_date  ... vintage  window  cs_missing  \\\n",
      "0         F22Q10000001         205202  ...  2022Q1     24m           0   \n",
      "1         F22Q10000002         203702  ...  2022Q1     24m           0   \n",
      "2         F22Q10000003         203702  ...  2022Q1     24m           0   \n",
      "3         F22Q10000004         205202  ...  2022Q1     24m           0   \n",
      "4         F22Q10000005         205202  ...  2022Q1     24m           0   \n",
      "\n",
      "   mi_missing  has_mi dti_missing  cltv_missing  original_loan_term_missing  \\\n",
      "0           0       0           0             0                           0   \n",
      "1           0       0           0             0                           0   \n",
      "2           0       0           0             0                           0   \n",
      "3           0       0           0             0                           0   \n",
      "4           0       0           0             0                           0   \n",
      "\n",
      "   number_of_borrowers_missing  default_24m  \n",
      "0                            0            1  \n",
      "1                            0            0  \n",
      "2                            0            0  \n",
      "3                            0            0  \n",
      "4                            0            0  \n",
      "\n",
      "[5 rows x 43 columns]\n",
      "  __file_quarter amortization_type channel  credit_score first_payment_date  \\\n",
      "0         2024Q4               FRM       R           802         2024-12-31   \n",
      "1         2024Q4               FRM       R           661         2024-12-31   \n",
      "2         2024Q4               FRM       C           759         2024-12-31   \n",
      "3         2024Q4               FRM       R           715         2025-01-31   \n",
      "4         2024Q4               FRM       R           790         2024-12-31   \n",
      "\n",
      "  first_time_homebuyer_flag interest_only_indicator loan_purpose  \\\n",
      "0                         N                       N            P   \n",
      "1                         Y                       N            P   \n",
      "2                         Y                       N            P   \n",
      "3                         Y                       N            P   \n",
      "4                         N                       N            N   \n",
      "\n",
      "  loan_sequence_number  maturity_date  ... vintage  window  cs_missing  \\\n",
      "0         F24Q40000056         205411  ...  2024Q4     24m           0   \n",
      "1         F24Q40000057         205411  ...  2024Q4     24m           0   \n",
      "2         F24Q40000058         205411  ...  2024Q4     24m           0   \n",
      "3         F24Q40000059         205412  ...  2024Q4     24m           0   \n",
      "4         F24Q40000060         205411  ...  2024Q4     24m           0   \n",
      "\n",
      "   mi_missing  has_mi dti_missing  cltv_missing  original_loan_term_missing  \\\n",
      "0           0       0           0             0                           0   \n",
      "1           0       0           0             0                           0   \n",
      "2           0       1           0             0                           0   \n",
      "3           0       0           0             0                           0   \n",
      "4           0       0           0             0                           0   \n",
      "\n",
      "   number_of_borrowers_missing  default_24m  \n",
      "0                            0            0  \n",
      "1                            0            0  \n",
      "2                            0            0  \n",
      "3                            0            0  \n",
      "4                            0            0  \n",
      "\n",
      "[5 rows x 43 columns]\n",
      "(3278827, 43)\n",
      "(280856, 43)\n"
     ]
    }
   ],
   "source": [
    "# df_imp_train.to_csv(\"train.csv\",index=False)\n",
    "# df_imp_val.to_csv(\"test.csv\",index=False)\n",
    "\n",
    "df_train = pd.read_csv(\"train.csv\")\n",
    "df_test = pd.read_csv(\"test.csv\")\n",
    "\n",
    "print(df_train.head())\n",
    "print(df_test.head())\n",
    "\n",
    "print(df_train.shape)\n",
    "print(df_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d71f0c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "__file_quarter",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "amortization_type",
         "rawType": "string",
         "type": "string"
        },
        {
         "name": "channel",
         "rawType": "string",
         "type": "string"
        },
        {
         "name": "credit_score",
         "rawType": "Int16",
         "type": "integer"
        },
        {
         "name": "first_payment_date",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        },
        {
         "name": "first_time_homebuyer_flag",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "interest_only_indicator",
         "rawType": "string",
         "type": "string"
        },
        {
         "name": "loan_purpose",
         "rawType": "string",
         "type": "string"
        },
        {
         "name": "loan_sequence_number",
         "rawType": "string",
         "type": "string"
        },
        {
         "name": "maturity_date",
         "rawType": "string",
         "type": "string"
        },
        {
         "name": "mi_cancellation_indicator",
         "rawType": "string",
         "type": "string"
        },
        {
         "name": "mi_percent",
         "rawType": "Float32",
         "type": "float"
        },
        {
         "name": "msa_md",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "number_of_borrowers",
         "rawType": "Int16",
         "type": "integer"
        },
        {
         "name": "number_of_units",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "occupancy_status",
         "rawType": "string",
         "type": "string"
        },
        {
         "name": "original_cltv",
         "rawType": "Float32",
         "type": "float"
        },
        {
         "name": "original_dti",
         "rawType": "Int16",
         "type": "integer"
        },
        {
         "name": "original_interest_rate",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "original_loan_term",
         "rawType": "Int16",
         "type": "integer"
        },
        {
         "name": "original_ltv",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "original_upb",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "postal_code",
         "rawType": "string",
         "type": "string"
        },
        {
         "name": "ppm_flag",
         "rawType": "string",
         "type": "string"
        },
        {
         "name": "property_state",
         "rawType": "string",
         "type": "string"
        },
        {
         "name": "property_type",
         "rawType": "string",
         "type": "string"
        },
        {
         "name": "property_valuation_method",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "quarter",
         "rawType": "category",
         "type": "unknown"
        },
        {
         "name": "relief_refinance_indicator",
         "rawType": "string",
         "type": "string"
        },
        {
         "name": "seller_name",
         "rawType": "string",
         "type": "string"
        },
        {
         "name": "servicer_name",
         "rawType": "string",
         "type": "string"
        },
        {
         "name": "special_eligibility_program",
         "rawType": "string",
         "type": "string"
        },
        {
         "name": "super_conforming_flag",
         "rawType": "string",
         "type": "string"
        },
        {
         "name": "vintage",
         "rawType": "string",
         "type": "string"
        },
        {
         "name": "window",
         "rawType": "category",
         "type": "unknown"
        },
        {
         "name": "has_mi",
         "rawType": "int8",
         "type": "integer"
        },
        {
         "name": "default_24m",
         "rawType": "Int8",
         "type": "integer"
        },
        {
         "name": "__file_quarter__BIN",
         "rawType": "Int64",
         "type": "integer"
        },
        {
         "name": "amortization_type__BIN",
         "rawType": "Int64",
         "type": "integer"
        },
        {
         "name": "channel__BIN",
         "rawType": "Int64",
         "type": "integer"
        },
        {
         "name": "first_time_homebuyer_flag__BIN",
         "rawType": "Int64",
         "type": "integer"
        },
        {
         "name": "interest_only_indicator__BIN",
         "rawType": "Int64",
         "type": "integer"
        },
        {
         "name": "loan_purpose__BIN",
         "rawType": "Int64",
         "type": "integer"
        },
        {
         "name": "number_of_borrowers__BIN",
         "rawType": "Int64",
         "type": "integer"
        },
        {
         "name": "occupancy_status__BIN",
         "rawType": "Int64",
         "type": "integer"
        },
        {
         "name": "ppm_flag__BIN",
         "rawType": "Int64",
         "type": "integer"
        },
        {
         "name": "property_type__BIN",
         "rawType": "Int64",
         "type": "integer"
        },
        {
         "name": "property_valuation_method__BIN",
         "rawType": "Int64",
         "type": "integer"
        },
        {
         "name": "quarter__BIN",
         "rawType": "Int64",
         "type": "integer"
        },
        {
         "name": "relief_refinance_indicator__BIN",
         "rawType": "Int64",
         "type": "integer"
        },
        {
         "name": "special_eligibility_program__BIN",
         "rawType": "Int64",
         "type": "integer"
        },
        {
         "name": "super_conforming_flag__BIN",
         "rawType": "Int64",
         "type": "integer"
        },
        {
         "name": "window__BIN",
         "rawType": "Int64",
         "type": "integer"
        },
        {
         "name": "credit_score__BIN",
         "rawType": "Int64",
         "type": "integer"
        },
        {
         "name": "mi_percent__BIN",
         "rawType": "Int64",
         "type": "integer"
        },
        {
         "name": "number_of_units__BIN",
         "rawType": "Int64",
         "type": "integer"
        },
        {
         "name": "original_cltv__BIN",
         "rawType": "Int64",
         "type": "integer"
        },
        {
         "name": "original_dti__BIN",
         "rawType": "Int64",
         "type": "integer"
        },
        {
         "name": "original_interest_rate__BIN",
         "rawType": "Int64",
         "type": "integer"
        },
        {
         "name": "original_loan_term__BIN",
         "rawType": "Int64",
         "type": "integer"
        },
        {
         "name": "original_ltv__BIN",
         "rawType": "Int64",
         "type": "integer"
        },
        {
         "name": "original_upb__BIN",
         "rawType": "Int64",
         "type": "integer"
        },
        {
         "name": "proba",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "risk_bucket",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "dd8aef66-2620-4ceb-9026-fe60593c993a",
       "rows": [
        [
         "0",
         "2024Q4",
         "FRM",
         "R",
         "802",
         "2024-12-31 00:00:00",
         "N",
         "N",
         "P",
         "F24Q40000056",
         "205411",
         "7",
         "0.0",
         "17410.0",
         "1",
         "1.0",
         "P",
         "80.0",
         "39",
         "6.875",
         "360",
         "80.0",
         "124000.0",
         "44000",
         "N",
         "OH",
         "SF",
         "2",
         "2024Q4",
         "Unknown",
         "Other sellers",
         "Other servicers",
         "9",
         "Y",
         "2024Q4",
         "24m",
         "0",
         "0",
         "-2",
         "0",
         "1",
         "1",
         "0",
         "1",
         "-2",
         "2",
         "0",
         "3",
         "-2",
         "-2",
         "0",
         "0",
         "0",
         "0",
         "5",
         "0",
         "0",
         "2",
         "2",
         "4",
         "2",
         "2",
         "0",
         "0.4977445945362738",
         "10"
        ],
        [
         "1",
         "2024Q4",
         "FRM",
         "R",
         "661",
         "2024-12-31 00:00:00",
         "Y",
         "N",
         "P",
         "F24Q40000057",
         "205411",
         "7",
         "0.0",
         "0.0",
         "2",
         "1.0",
         "P",
         "74.0",
         "39",
         "6.875",
         "360",
         "74.0",
         "324000.0",
         "46700",
         "N",
         "IN",
         "SF",
         "2",
         "2024Q4",
         "Unknown",
         "Other sellers",
         "Other servicers",
         "9",
         "Y",
         "2024Q4",
         "24m",
         "0",
         "0",
         "-2",
         "0",
         "1",
         "0",
         "0",
         "1",
         "-2",
         "2",
         "0",
         "3",
         "-2",
         "-2",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "2",
         "2",
         "4",
         "2",
         "1",
         "3",
         "0.006671818567448355",
         "10"
        ],
        [
         "2",
         "2024Q4",
         "FRM",
         "C",
         "759",
         "2024-12-31 00:00:00",
         "Y",
         "N",
         "P",
         "F24Q40000058",
         "205411",
         "N",
         "30.0",
         "45060.0",
         "1",
         "1.0",
         "P",
         "95.0",
         "34",
         "6.875",
         "360",
         "95.0",
         "152000.0",
         "13100",
         "N",
         "NY",
         "MH",
         "2",
         "2024Q4",
         "Unknown",
         "Other sellers",
         "ONSLOW BAY FINANCIAL LLC",
         "9",
         "Y",
         "2024Q4",
         "24m",
         "1",
         "0",
         "-2",
         "0",
         "0",
         "0",
         "0",
         "1",
         "-2",
         "2",
         "0",
         "4",
         "-2",
         "-2",
         "0",
         "0",
         "0",
         "0",
         "4",
         "3",
         "0",
         "4",
         "1",
         "4",
         "2",
         "4",
         "1",
         "0.4977445945362738",
         "10"
        ],
        [
         "3",
         "2024Q4",
         "FRM",
         "R",
         "715",
         "2025-01-31 00:00:00",
         "Y",
         "N",
         "P",
         "F24Q40000059",
         "205412",
         "7",
         "0.0",
         "30460.0",
         "2",
         "1.0",
         "P",
         "80.0",
         "31",
         "6.125",
         "360",
         "80.0",
         "165000.0",
         "40300",
         "N",
         "KY",
         "SF",
         "2",
         "2024Q4",
         "Unknown",
         "Other sellers",
         "Other servicers",
         "9",
         "Y",
         "2024Q4",
         "24m",
         "0",
         "0",
         "-2",
         "0",
         "1",
         "0",
         "0",
         "1",
         "-2",
         "2",
         "0",
         "3",
         "-2",
         "-2",
         "0",
         "0",
         "0",
         "0",
         "2",
         "0",
         "0",
         "2",
         "1",
         "3",
         "2",
         "2",
         "1",
         "0.06704216712455147",
         "10"
        ],
        [
         "4",
         "2024Q4",
         "FRM",
         "R",
         "790",
         "2024-12-31 00:00:00",
         "N",
         "N",
         "N",
         "F24Q40000060",
         "205411",
         "7",
         "0.0",
         "0.0",
         "1",
         "1.0",
         "P",
         "49.0",
         "46",
         "5.75",
         "360",
         "49.0",
         "520000.0",
         "81200",
         "N",
         "CO",
         "PU",
         "2",
         "2024Q4",
         "Unknown",
         "Other sellers",
         "NATIONSTAR MORTGAGE LLC DBA MR. COOPER",
         "9",
         "Y",
         "2024Q4",
         "24m",
         "0",
         "0",
         "-2",
         "0",
         "1",
         "1",
         "0",
         "0",
         "-2",
         "2",
         "0",
         "2",
         "-2",
         "-2",
         "0",
         "0",
         "0",
         "0",
         "5",
         "0",
         "0",
         "0",
         "4",
         "2",
         "2",
         "0",
         "4",
         "0.4977445945362738",
         "10"
        ]
       ],
       "shape": {
        "columns": 64,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>__file_quarter</th>\n",
       "      <th>amortization_type</th>\n",
       "      <th>channel</th>\n",
       "      <th>credit_score</th>\n",
       "      <th>first_payment_date</th>\n",
       "      <th>first_time_homebuyer_flag</th>\n",
       "      <th>interest_only_indicator</th>\n",
       "      <th>loan_purpose</th>\n",
       "      <th>loan_sequence_number</th>\n",
       "      <th>maturity_date</th>\n",
       "      <th>...</th>\n",
       "      <th>mi_percent__BIN</th>\n",
       "      <th>number_of_units__BIN</th>\n",
       "      <th>original_cltv__BIN</th>\n",
       "      <th>original_dti__BIN</th>\n",
       "      <th>original_interest_rate__BIN</th>\n",
       "      <th>original_loan_term__BIN</th>\n",
       "      <th>original_ltv__BIN</th>\n",
       "      <th>original_upb__BIN</th>\n",
       "      <th>proba</th>\n",
       "      <th>risk_bucket</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024Q4</td>\n",
       "      <td>FRM</td>\n",
       "      <td>R</td>\n",
       "      <td>802</td>\n",
       "      <td>2024-12-31</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>P</td>\n",
       "      <td>F24Q40000056</td>\n",
       "      <td>205411</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.497745</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024Q4</td>\n",
       "      <td>FRM</td>\n",
       "      <td>R</td>\n",
       "      <td>661</td>\n",
       "      <td>2024-12-31</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>P</td>\n",
       "      <td>F24Q40000057</td>\n",
       "      <td>205411</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.006672</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024Q4</td>\n",
       "      <td>FRM</td>\n",
       "      <td>C</td>\n",
       "      <td>759</td>\n",
       "      <td>2024-12-31</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>P</td>\n",
       "      <td>F24Q40000058</td>\n",
       "      <td>205411</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.497745</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024Q4</td>\n",
       "      <td>FRM</td>\n",
       "      <td>R</td>\n",
       "      <td>715</td>\n",
       "      <td>2025-01-31</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>P</td>\n",
       "      <td>F24Q40000059</td>\n",
       "      <td>205412</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.067042</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024Q4</td>\n",
       "      <td>FRM</td>\n",
       "      <td>R</td>\n",
       "      <td>790</td>\n",
       "      <td>2024-12-31</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>F24Q40000060</td>\n",
       "      <td>205411</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.497745</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  __file_quarter amortization_type channel  credit_score first_payment_date  \\\n",
       "0         2024Q4               FRM       R           802         2024-12-31   \n",
       "1         2024Q4               FRM       R           661         2024-12-31   \n",
       "2         2024Q4               FRM       C           759         2024-12-31   \n",
       "3         2024Q4               FRM       R           715         2025-01-31   \n",
       "4         2024Q4               FRM       R           790         2024-12-31   \n",
       "\n",
       "  first_time_homebuyer_flag interest_only_indicator loan_purpose  \\\n",
       "0                         N                       N            P   \n",
       "1                         Y                       N            P   \n",
       "2                         Y                       N            P   \n",
       "3                         Y                       N            P   \n",
       "4                         N                       N            N   \n",
       "\n",
       "  loan_sequence_number maturity_date  ... mi_percent__BIN  \\\n",
       "0         F24Q40000056        205411  ...               0   \n",
       "1         F24Q40000057        205411  ...               0   \n",
       "2         F24Q40000058        205411  ...               3   \n",
       "3         F24Q40000059        205412  ...               0   \n",
       "4         F24Q40000060        205411  ...               0   \n",
       "\n",
       "   number_of_units__BIN  original_cltv__BIN  original_dti__BIN  \\\n",
       "0                     0                   2                  2   \n",
       "1                     0                   2                  2   \n",
       "2                     0                   4                  1   \n",
       "3                     0                   2                  1   \n",
       "4                     0                   0                  4   \n",
       "\n",
       "   original_interest_rate__BIN original_loan_term__BIN  original_ltv__BIN  \\\n",
       "0                            4                       2                  2   \n",
       "1                            4                       2                  1   \n",
       "2                            4                       2                  4   \n",
       "3                            3                       2                  2   \n",
       "4                            2                       2                  0   \n",
       "\n",
       "   original_upb__BIN     proba  risk_bucket  \n",
       "0                  0  0.497745           10  \n",
       "1                  3  0.006672           10  \n",
       "2                  1  0.497745           10  \n",
       "3                  1  0.067042           10  \n",
       "4                  4  0.497745           10  \n",
       "\n",
       "[5 rows x 64 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_score = pd.read_parquet(\"../data/processed/scored/oos_scored.parquet\")\n",
    "df_score.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "20d91876",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<StringArray>\n",
      "['2022Q1', '2022Q2', '2022Q3', '2022Q4', '2023Q1', '2023Q2', '2023Q3',\n",
      " '2023Q4', '2024Q1', '2024Q2', '2024Q3']\n",
      "Length: 11, dtype: string\n",
      "Empty DataFrame\n",
      "Columns: [first_payment_date]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "df_pooled = pd.read_parquet(\"../data/processed/default_labels/window=24m/pooled.parquet\")\n",
    "print(df_pooled[\"vintage\"].unique())\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.read_parquet(\"../data/processed/default_labels/window=24m/pooled.parquet\")\n",
    "# Tu verras que les 2025Q1/Q2 ont un file_quarter=2024Q4 si on l’ajoute (voir plus bas),\n",
    "# ou au moins un first_payment_date en 2025:\n",
    "print(df.loc[df[\"vintage\"].isin([\"2025Q1\",\"2025Q2\"]), [\"first_payment_date\"]].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c0c9b39",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] Suppression des colonnes indicatrices de manquants : ['cltv_missing', 'cs_missing', 'dti_missing', 'mi_missing', 'number_of_borrowers_missing', 'original_loan_term_missing', 'was_missing_amortization_type', 'was_missing_channel', 'was_missing_credit_score', 'was_missing_first_payment_date', 'was_missing_first_time_homebuyer_flag', 'was_missing_interest_only_indicator', 'was_missing_loan_purpose', 'was_missing_loan_sequence_number', 'was_missing_maturity_date', 'was_missing_mi_cancellation_indicator', 'was_missing_mi_percent', 'was_missing_msa_md', 'was_missing_number_of_borrowers', 'was_missing_number_of_units', 'was_missing_occupancy_status', 'was_missing_original_cltv', 'was_missing_original_dti', 'was_missing_original_interest_rate', 'was_missing_original_loan_term', 'was_missing_original_ltv', 'was_missing_original_upb', 'was_missing_postal_code', 'was_missing_ppm_flag', 'was_missing_property_state', 'was_missing_property_type', 'was_missing_property_valuation_method', 'was_missing_relief_refinance_indicator', 'was_missing_seller_name', 'was_missing_servicer_name', 'was_missing_special_eligibility_program', 'was_missing_super_conforming_flag', 'was_missing_vintage']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SUBSET] train -> (150000, 73), val -> (50000, 73)\n",
      "train shape: (150000, 31)\n",
      "val   shape: (50000, 31)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  1 out of  1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.04551196098327637s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Done  2 out of 17 | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  4 out of 17 | elapsed:    0.1s remaining:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done  6 out of 17 | elapsed:    0.1s remaining:    0.1s\n",
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n",
      "[Parallel(n_jobs=-1)]: Done  8 out of 17 | elapsed:    0.7s remaining:    0.8s\n",
      "[Parallel(n_jobs=-1)]: Done 10 out of 17 | elapsed:    0.7s remaining:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done 12 out of 17 | elapsed:    1.4s remaining:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done 14 out of 17 | elapsed:    1.4s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done 17 out of 17 | elapsed:   13.8s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "/var/folders/yk/g149s5cs3m1f2t6smf32gc1m0000gn/T/ipykernel_6326/2373234138.py:479: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n",
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n",
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n",
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n",
      "/var/folders/yk/g149s5cs3m1f2t6smf32gc1m0000gn/T/ipykernel_6326/2373234138.py:479: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n",
      "/var/folders/yk/g149s5cs3m1f2t6smf32gc1m0000gn/T/ipykernel_6326/2373234138.py:479: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n",
      "/var/folders/yk/g149s5cs3m1f2t6smf32gc1m0000gn/T/ipykernel_6326/2373234138.py:479: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n",
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n",
      "/var/folders/yk/g149s5cs3m1f2t6smf32gc1m0000gn/T/ipykernel_6326/2373234138.py:479: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n",
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n",
      "/var/folders/yk/g149s5cs3m1f2t6smf32gc1m0000gn/T/ipykernel_6326/2373234138.py:479: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n",
      "/var/folders/yk/g149s5cs3m1f2t6smf32gc1m0000gn/T/ipykernel_6326/2373234138.py:479: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n",
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.07691383361816406s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Done 2 out of 8 | elapsed:    0.2s remaining:    0.6s\n",
      "/var/folders/yk/g149s5cs3m1f2t6smf32gc1m0000gn/T/ipykernel_6326/2373234138.py:479: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n",
      "[Parallel(n_jobs=-1)]: Done 3 out of 8 | elapsed:    0.8s remaining:    1.4s\n",
      "[Parallel(n_jobs=-1)]: Done 4 out of 8 | elapsed:    1.1s remaining:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Done 5 out of 8 | elapsed:    1.1s remaining:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done 6 out of 8 | elapsed:    1.2s remaining:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done 8 out of 8 | elapsed:    1.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22 variables retenues sur 25\n",
      "\n",
      "Résumé sélection : 22 retenues / 25 évaluées (seuil corr = 0.85)\n",
      "\n",
      "— Variables retenues (WOE) —\n",
      "  • credit_score_WOE\n",
      "  • original_interest_rate_WOE\n",
      "  • original_dti_WOE\n",
      "  • original_cltv_WOE\n",
      "  • number_of_borrowers_WOE\n",
      "  • loan_purpose_WOE\n",
      "  • mi_percent_WOE\n",
      "  • property_state_WOE\n",
      "  • original_loan_term_WOE\n",
      "  • original_upb_WOE\n",
      "  • first_time_homebuyer_flag_WOE\n",
      "  • special_eligibility_program_WOE\n",
      "  • property_type_WOE\n",
      "  • channel_WOE\n",
      "  • occupancy_status_WOE\n",
      "  • number_of_units_WOE\n",
      "  • super_conforming_flag_WOE\n",
      "  • amortization_type_WOE\n",
      "  • relief_refinance_indicator_WOE\n",
      "  • property_valuation_method_WOE\n",
      "  • interest_only_indicator_WOE\n",
      "  • ppm_flag_WOE\n",
      "\n",
      "— Variables écartées (WOE) —\n",
      "  • original_ltv_WOE\n",
      "  • has_mi_WOE\n",
      "  • has_special_program_WOE\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "kept_raw",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "dropped_raw",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "95b67acb-2346-4fac-bb68-ea3cc0344479",
       "rows": [
        [
         "0",
         "credit_score",
         "original_ltv"
        ],
        [
         "1",
         "original_interest_rate",
         "has_mi"
        ],
        [
         "2",
         "original_dti",
         "has_special_program"
        ],
        [
         "3",
         "original_cltv",
         ""
        ],
        [
         "4",
         "number_of_borrowers",
         ""
        ],
        [
         "5",
         "loan_purpose",
         ""
        ],
        [
         "6",
         "mi_percent",
         ""
        ],
        [
         "7",
         "property_state",
         ""
        ],
        [
         "8",
         "original_loan_term",
         ""
        ],
        [
         "9",
         "original_upb",
         ""
        ],
        [
         "10",
         "first_time_homebuyer_flag",
         ""
        ],
        [
         "11",
         "special_eligibility_program",
         ""
        ],
        [
         "12",
         "property_type",
         ""
        ],
        [
         "13",
         "channel",
         ""
        ],
        [
         "14",
         "occupancy_status",
         ""
        ],
        [
         "15",
         "number_of_units",
         ""
        ],
        [
         "16",
         "super_conforming_flag",
         ""
        ],
        [
         "17",
         "amortization_type",
         ""
        ],
        [
         "18",
         "relief_refinance_indicator",
         ""
        ],
        [
         "19",
         "property_valuation_method",
         ""
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 20
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kept_raw</th>\n",
       "      <th>dropped_raw</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>credit_score</td>\n",
       "      <td>original_ltv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>original_interest_rate</td>\n",
       "      <td>has_mi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>original_dti</td>\n",
       "      <td>has_special_program</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>original_cltv</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>number_of_borrowers</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>loan_purpose</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>mi_percent</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>property_state</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>original_loan_term</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>original_upb</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>first_time_homebuyer_flag</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>special_eligibility_program</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>property_type</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>channel</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>occupancy_status</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>number_of_units</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>super_conforming_flag</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>amortization_type</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>relief_refinance_indicator</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>property_valuation_method</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       kept_raw          dropped_raw\n",
       "0                  credit_score         original_ltv\n",
       "1        original_interest_rate               has_mi\n",
       "2                  original_dti  has_special_program\n",
       "3                 original_cltv                     \n",
       "4           number_of_borrowers                     \n",
       "5                  loan_purpose                     \n",
       "6                    mi_percent                     \n",
       "7                property_state                     \n",
       "8            original_loan_term                     \n",
       "9                  original_upb                     \n",
       "10    first_time_homebuyer_flag                     \n",
       "11  special_eligibility_program                     \n",
       "12                property_type                     \n",
       "13                      channel                     \n",
       "14             occupancy_status                     \n",
       "15              number_of_units                     \n",
       "16        super_conforming_flag                     \n",
       "17            amortization_type                     \n",
       "18   relief_refinance_indicator                     \n",
       "19    property_valuation_method                     "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "dropped_raw",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "kept_reason_raw",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "abs_corr_with_kept",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "1dc6a6c8-d7aa-4577-8dfb-19281687386c",
       "rows": [
        [
         "0",
         "original_ltv",
         "original_cltv",
         "0.993460759809993"
        ],
        [
         "2",
         "has_special_program",
         "special_eligibility_program",
         "0.9898345640985299"
        ],
        [
         "1",
         "has_mi",
         "mi_percent",
         "0.9837135558994485"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 3
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dropped_raw</th>\n",
       "      <th>kept_reason_raw</th>\n",
       "      <th>abs_corr_with_kept</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>original_ltv</td>\n",
       "      <td>original_cltv</td>\n",
       "      <td>0.993461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>has_special_program</td>\n",
       "      <td>special_eligibility_program</td>\n",
       "      <td>0.989835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>has_mi</td>\n",
       "      <td>mi_percent</td>\n",
       "      <td>0.983714</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           dropped_raw              kept_reason_raw  abs_corr_with_kept\n",
       "0         original_ltv                original_cltv            0.993461\n",
       "2  has_special_program  special_eligibility_program            0.989835\n",
       "1               has_mi                   mi_percent            0.983714"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n",
      "/Users/yoannpull/.pyenv/versions/3.12.10/lib/python3.12/multiprocessing/queues.py:122: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  return _ForkingPickler.loads(res)\n",
      "/Users/yoannpull/.pyenv/versions/3.12.10/lib/python3.12/multiprocessing/queues.py:122: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  return _ForkingPickler.loads(res)\n",
      "/Users/yoannpull/.pyenv/versions/3.12.10/lib/python3.12/multiprocessing/queues.py:122: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  return _ForkingPickler.loads(res)\n",
      "/Users/yoannpull/.pyenv/versions/3.12.10/lib/python3.12/multiprocessing/queues.py:122: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  return _ForkingPickler.loads(res)\n",
      "/Users/yoannpull/.pyenv/versions/3.12.10/lib/python3.12/multiprocessing/queues.py:122: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  return _ForkingPickler.loads(res)\n",
      "/Users/yoannpull/.pyenv/versions/3.12.10/lib/python3.12/multiprocessing/queues.py:122: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  return _ForkingPickler.loads(res)\n",
      "/Users/yoannpull/.pyenv/versions/3.12.10/lib/python3.12/multiprocessing/queues.py:122: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  return _ForkingPickler.loads(res)\n",
      "/Users/yoannpull/.pyenv/versions/3.12.10/lib/python3.12/multiprocessing/queues.py:122: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  return _ForkingPickler.loads(res)\n",
      "/Users/yoannpull/.pyenv/versions/3.12.10/lib/python3.12/multiprocessing/queues.py:122: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  return _ForkingPickler.loads(res)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC_val=0.7807 | Gini_val=0.5613 | Brier=0.01336 | LogLoss=0.06677\n",
      "KS_val=0.4404 | seuil_KS=0.0199\n",
      "\n",
      "PSI (train→val, probas) = 0.4502  (≈ <0.10 faible, 0.10–0.25 modéré, >0.25 fort)\n",
      "PSI (distribution des classes TRAIN→VAL) = 0.0002\n",
      "\n",
      "Top 15 PSI(feature):\n",
      "original_interest_rate__BIN       8.445305\n",
      "loan_purpose__BIN                 1.000609\n",
      "original_dti__BIN                 0.194258\n",
      "original_loan_term__BIN           0.185138\n",
      "original_cltv__BIN                0.166479\n",
      "mi_percent__BIN                   0.152745\n",
      "channel__BIN                      0.049591\n",
      "property_state__BIN               0.024527\n",
      "original_upb__BIN                 0.014642\n",
      "property_type__BIN                0.011123\n",
      "credit_score__BIN                 0.006475\n",
      "number_of_units__BIN              0.000127\n",
      "amortization_type__BIN            0.000000\n",
      "interest_only_indicator__BIN      0.000000\n",
      "property_valuation_method__BIN    0.000000\n",
      "dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yoannpull/Library/Caches/pypoetry/virtualenvs/pd-calibration-NMoSp0fs-py3.12/lib/python3.12/site-packages/joblib/externals/loky/process_executor.py:782: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n",
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n",
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n",
      "/Users/yoannpull/.pyenv/versions/3.12.10/lib/python3.12/multiprocessing/queues.py:122: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  return _ForkingPickler.loads(res)\n",
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n",
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n",
      "/Users/yoannpull/.pyenv/versions/3.12.10/lib/python3.12/multiprocessing/queues.py:122: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  return _ForkingPickler.loads(res)\n",
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start ablation: AUC=0.7807 | PSI(probas)=0.4502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n",
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n",
      "/Users/yoannpull/.pyenv/versions/3.12.10/lib/python3.12/multiprocessing/queues.py:122: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  return _ForkingPickler.loads(res)\n",
      "/Users/yoannpull/.pyenv/versions/3.12.10/lib/python3.12/multiprocessing/queues.py:122: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  return _ForkingPickler.loads(res)\n",
      "/Users/yoannpull/Library/Caches/pypoetry/virtualenvs/pd-calibration-NMoSp0fs-py3.12/lib/python3.12/site-packages/joblib/externals/loky/process_executor.py:782: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n",
      "/Users/yoannpull/.pyenv/versions/3.12.10/lib/python3.12/multiprocessing/queues.py:122: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  return _ForkingPickler.loads(res)\n",
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n",
      "/Users/yoannpull/.pyenv/versions/3.12.10/lib/python3.12/multiprocessing/queues.py:122: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  return _ForkingPickler.loads(res)\n",
      "/Users/yoannpull/.pyenv/versions/3.12.10/lib/python3.12/multiprocessing/queues.py:122: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  return _ForkingPickler.loads(res)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Try drop original_interest_rate__BIN         | AUC=0.7841 (Δ-0.0034) | PSI=0.1316 (Δ+0.3186)\n",
      "  -> kept removal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yoannpull/.pyenv/versions/3.12.10/lib/python3.12/multiprocessing/queues.py:122: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  return _ForkingPickler.loads(res)\n",
      "/Users/yoannpull/Library/Caches/pypoetry/virtualenvs/pd-calibration-NMoSp0fs-py3.12/lib/python3.12/site-packages/joblib/externals/loky/process_executor.py:782: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n",
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Try drop loan_purpose__BIN                   | AUC=0.7836 (Δ+0.0004) | PSI=0.1087 (Δ+0.0229)\n",
      "  -> kept removal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n",
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n",
      "/Users/yoannpull/.pyenv/versions/3.12.10/lib/python3.12/multiprocessing/queues.py:122: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  return _ForkingPickler.loads(res)\n",
      "/Users/yoannpull/Library/Caches/pypoetry/virtualenvs/pd-calibration-NMoSp0fs-py3.12/lib/python3.12/site-packages/joblib/externals/loky/process_executor.py:782: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n",
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n",
      "/Users/yoannpull/.pyenv/versions/3.12.10/lib/python3.12/multiprocessing/queues.py:122: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  return _ForkingPickler.loads(res)\n",
      "/Users/yoannpull/.pyenv/versions/3.12.10/lib/python3.12/multiprocessing/queues.py:122: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  return _ForkingPickler.loads(res)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Try drop original_dti__BIN                   | AUC=0.7813 (Δ+0.0023) | PSI=0.0833 (Δ+0.0254)\n",
      "  -> kept removal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yoannpull/.pyenv/versions/3.12.10/lib/python3.12/multiprocessing/queues.py:122: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  return _ForkingPickler.loads(res)\n",
      "/Users/yoannpull/Library/Caches/pypoetry/virtualenvs/pd-calibration-NMoSp0fs-py3.12/lib/python3.12/site-packages/joblib/externals/loky/process_executor.py:782: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n",
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n",
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n",
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n",
      "/Users/yoannpull/.pyenv/versions/3.12.10/lib/python3.12/multiprocessing/queues.py:122: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  return _ForkingPickler.loads(res)\n",
      "/Users/yoannpull/.pyenv/versions/3.12.10/lib/python3.12/multiprocessing/queues.py:122: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  return _ForkingPickler.loads(res)\n",
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n",
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n",
      "/Users/yoannpull/.pyenv/versions/3.12.10/lib/python3.12/multiprocessing/queues.py:122: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  return _ForkingPickler.loads(res)\n",
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Try drop original_loan_term__BIN             | AUC=0.7808 (Δ+0.0006) | PSI=0.0537 (Δ+0.0296)\n",
      "  -> kept removal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yoannpull/.pyenv/versions/3.12.10/lib/python3.12/multiprocessing/queues.py:122: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  return _ForkingPickler.loads(res)\n",
      "/Users/yoannpull/Library/Caches/pypoetry/virtualenvs/pd-calibration-NMoSp0fs-py3.12/lib/python3.12/site-packages/joblib/externals/loky/process_executor.py:782: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n",
      "/Users/yoannpull/.pyenv/versions/3.12.10/lib/python3.12/multiprocessing/queues.py:122: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  return _ForkingPickler.loads(res)\n",
      "/Users/yoannpull/.pyenv/versions/3.12.10/lib/python3.12/multiprocessing/queues.py:122: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  return _ForkingPickler.loads(res)\n",
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n",
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n",
      "/Users/yoannpull/.pyenv/versions/3.12.10/lib/python3.12/multiprocessing/queues.py:122: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  return _ForkingPickler.loads(res)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Try drop original_cltv__BIN                  | AUC=0.7805 (Δ+0.0003) | PSI=0.0499 (Δ+0.0037)\n",
      "  -> kept removal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n",
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n",
      "/Users/yoannpull/.pyenv/versions/3.12.10/lib/python3.12/multiprocessing/queues.py:122: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  return _ForkingPickler.loads(res)\n",
      "/Users/yoannpull/Library/Caches/pypoetry/virtualenvs/pd-calibration-NMoSp0fs-py3.12/lib/python3.12/site-packages/joblib/externals/loky/process_executor.py:782: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n",
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n",
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n",
      "/Users/yoannpull/.pyenv/versions/3.12.10/lib/python3.12/multiprocessing/queues.py:122: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  return _ForkingPickler.loads(res)\n",
      "/Users/yoannpull/.pyenv/versions/3.12.10/lib/python3.12/multiprocessing/queues.py:122: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  return _ForkingPickler.loads(res)\n",
      "/Users/yoannpull/.pyenv/versions/3.12.10/lib/python3.12/multiprocessing/queues.py:122: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  return _ForkingPickler.loads(res)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Try drop mi_percent__BIN                     | AUC=0.7760 (Δ+0.0045) | PSI=0.0527 (Δ-0.0028)\n",
      "  -> revert\n",
      "\n",
      "After ablation: AUC_val=0.7805 | Gini=0.5610 | Brier=0.01324 | LogLoss=0.06529 | PSI(probas)=0.0499\n",
      "Features finales : 17\n",
      "\n",
      "After prior-shift adjust:\n",
      "AUC_val=0.7805 | Gini_val=0.5610 | Brier=0.01327 | LogLoss=0.06563\n",
      "KS_val=0.4358 | seuil_KS=0.0173\n",
      "PSI (train→val, probas) après ajustement = 0.2240\n",
      "\n",
      "Déciles — APRÈS prior-shift :\n",
      "        count  events      rate     avg_p   capture        KS\n",
      "decile                                                       \n",
      "9        4978     248  0.049819  0.066526  0.365243  0.269341\n",
      "8        5016     137  0.027313  0.035259  0.567010  0.372185\n",
      "7        4934     109  0.022092  0.023970  0.727541  0.434886\n",
      "6        5019      61  0.012154  0.014971  0.817378  0.424199\n",
      "5        4110      41  0.009976  0.010243  0.877761  0.402082\n",
      "4        5931      38  0.006407  0.008158  0.933726  0.338564\n",
      "3        4603      14  0.003041  0.006298  0.954345  0.266139\n",
      "2        4876      17  0.003486  0.005596  0.979381  0.192658\n",
      "1        5256       8  0.001522  0.003995  0.991163  0.098035\n",
      "0        5277       6  0.001137  0.001554  1.000000  0.000000\n",
      "KS_val (déciles, après) = 0.4349\n",
      "\n",
      "Top variables (|coef|*sd) :\n",
      "                                      coef       std  std_coef\n",
      "credit_score__BIN                 1.013957  0.810538  0.821851\n",
      "number_of_borrowers__BIN          1.017911  0.372359  0.379028\n",
      "mi_percent__BIN                   0.964472  0.267768  0.258255\n",
      "property_state__BIN               0.854716  0.224556  0.191932\n",
      "channel__BIN                      1.552239  0.069649  0.108112\n",
      "super_conforming_flag__BIN       -7.896106  0.008228 -0.064967\n",
      "special_eligibility_program__BIN  0.326564  0.189286  0.061814\n",
      "property_type__BIN                0.560915  0.102704  0.057608\n",
      "original_upb__BIN                 0.406772  0.141617  0.057606\n",
      "occupancy_status__BIN             0.341558  0.161876  0.055290\n",
      "first_time_homebuyer_flag__BIN   -0.131593  0.174286 -0.022935\n",
      "number_of_units__BIN              0.323614  0.021813  0.007059\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# ============================================================\n",
    "# Binning max |Gini| (cat + num), WOE + sélection, logit + isotonic,\n",
    "# diagnostics (KS, déciles, calibration, PSI, importance, ablation, prior-shift)\n",
    "# Version complète, corrigée & optimisée + OPTION SUBSET\n",
    "# ============================================================\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning, message=\".*is_period_dtype is deprecated.*\")\n",
    "warnings.filterwarnings(\"ignore\", message=\".*pkg_resources is deprecated.*\")\n",
    "\n",
    "# ================================\n",
    "# Réglages généraux\n",
    "# ================================\n",
    "# Sous-échantillonnage pour accélérer (stratifié sur la cible si dispo)\n",
    "USE_SUBSET         = True\n",
    "SUBSET_FRAC_TRAIN  = None      # ex: 0.25  (prioritaire sur MAX si non-None)\n",
    "SUBSET_FRAC_VAL    = None      # ex: 0.25\n",
    "SUBSET_MAX_TRAIN   = 150_000   # nb max lignes train (utilisé si FRAC est None)\n",
    "SUBSET_MAX_VAL     = 50_000    # nb max lignes val   (utilisé si FRAC est None)\n",
    "SUBSET_RANDOM_STATE= 42\n",
    "SUBSET_MIN_PER_CL  = 100       # garde au moins N obs/classe si possible\n",
    "TARGET_NAME        = \"default_24m\"\n",
    "\n",
    "# Ablation\n",
    "ABLATION_MAX_STEPS = 10        # 0 pour désactiver l’ablation\n",
    "ABLATION_MAX_AUC_LOSS = 0.02   # perte AUC tolérée par étape\n",
    "\n",
    "# PSI proxy temporel (drop automatique si instable)\n",
    "PSI_CUTOFF_PROXY   = 0.25\n",
    "conditional_proxies = [\"original_interest_rate\"]  # variables \"sensibles\" au drift macro\n",
    "\n",
    "# ================================\n",
    "# Imports\n",
    "# ================================\n",
    "import re\n",
    "import json\n",
    "import math\n",
    "import logging\n",
    "from itertools import zip_longest\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "\n",
    "# Parallélisation\n",
    "try:\n",
    "    from joblib import Parallel, delayed\n",
    "except Exception:  # fallback si joblib indisponible\n",
    "    Parallel = None\n",
    "    def delayed(f): return f\n",
    "\n",
    "# Sklearn (modèle + metrics)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.metrics import roc_auc_score, brier_score_loss, log_loss, roc_curve\n",
    "\n",
    "# ================================\n",
    "# Logging\n",
    "# ================================\n",
    "logger = logging.getLogger(\"binning_pipeline\")\n",
    "if not logger.handlers:\n",
    "    _h = logging.StreamHandler()\n",
    "    _fmt = logging.Formatter(\"[%(levelname)s] %(message)s\")\n",
    "    _h.setFormatter(_fmt)\n",
    "    logger.addHandler(_h)\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "def set_verbosity(verbose: int = 0):\n",
    "    \"\"\"0: WARN, 5: INFO, 10+: DEBUG.\"\"\"\n",
    "    if verbose >= 10:\n",
    "        logger.setLevel(logging.DEBUG)\n",
    "    elif verbose >= 5:\n",
    "        logger.setLevel(logging.INFO)\n",
    "    else:\n",
    "        logger.setLevel(logging.WARN)\n",
    "\n",
    "# ================================\n",
    "# Options I/O (facultatif)\n",
    "# ================================\n",
    "no_flag_missing = True  # supprimer les *_missing auto-générées ?\n",
    "\n",
    "# ================================\n",
    "# Chargement des données (adapter les chemins)\n",
    "# ================================\n",
    "df_train_imp = pd.read_parquet(\"../data/processed/merged/imputed/train.parquet\")\n",
    "df_val_imp   = pd.read_parquet(\"../data/processed/merged/imputed/validation.parquet\")\n",
    "\n",
    "# --- 0) Sous-échantillonnage (facultatif, très utile pour itérer vite) ---\n",
    "def stratified_sample(df, y_col, frac=None, max_rows=None, random_state=42, min_per_class=50):\n",
    "    \"\"\"Sous-échantillonne df (stratifié sur y_col si dispo).\n",
    "       frac prioritaire sur max_rows si non-None.\n",
    "    \"\"\"\n",
    "    if frac is None and (max_rows is None or len(df) <= max_rows):\n",
    "        return df.copy()\n",
    "\n",
    "    if frac is not None:\n",
    "        if y_col in df.columns:\n",
    "            return (df\n",
    "                    .groupby(df[y_col], group_keys=False, dropna=False)\n",
    "                    .apply(lambda g: g.sample(frac=frac, random_state=random_state))\n",
    "                    .reset_index(drop=True))\n",
    "        else:\n",
    "            return df.sample(frac=frac, random_state=random_state).reset_index(drop=True)\n",
    "\n",
    "    # max_rows défini\n",
    "    n = len(df)\n",
    "    if n <= max_rows:\n",
    "        return df.copy()\n",
    "\n",
    "    if y_col in df.columns:\n",
    "        # répartition proportionnelle + min par classe si possible\n",
    "        counts = df[y_col].value_counts(dropna=False)\n",
    "        props = counts / counts.sum()\n",
    "        target_counts = (props * max_rows).astype(int)\n",
    "        # garantie min\n",
    "        for cls in counts.index:\n",
    "            target_counts.loc[cls] = max(target_counts.loc[cls], min_per_class if counts.loc[cls] >= min_per_class else counts.loc[cls])\n",
    "        # ajuste au total demandé\n",
    "        delta = max_rows - int(target_counts.sum())\n",
    "        if delta > 0:\n",
    "            # ajoute delta aux classes les plus fréquentes\n",
    "            order = counts.sort_values(ascending=False).index\n",
    "            for cls in order:\n",
    "                if delta == 0: break\n",
    "                can_add = counts.loc[cls] - target_counts.loc[cls]\n",
    "                add = min(delta, max(can_add, 0))\n",
    "                target_counts.loc[cls] += add\n",
    "                delta -= add\n",
    "        elif delta < 0:\n",
    "            # retire -delta depuis les plus fréquentes\n",
    "            order = counts.sort_values(ascending=False).index\n",
    "            for cls in order:\n",
    "                if delta == 0: break\n",
    "                can_remove = target_counts.loc[cls] - min_per_class\n",
    "                rm = min(-delta, max(can_remove, 0))\n",
    "                target_counts.loc[cls] -= rm\n",
    "                delta += rm\n",
    "\n",
    "        parts = []\n",
    "        for cls, n_take in target_counts.items():\n",
    "            g = df[df[y_col] == cls]\n",
    "            if n_take > 0 and len(g) > 0:\n",
    "                parts.append(g.sample(n=min(int(n_take), len(g)), random_state=random_state))\n",
    "        return pd.concat(parts, axis=0).sample(frac=1.0, random_state=random_state).reset_index(drop=True)\n",
    "    else:\n",
    "        return df.sample(n=max_rows, random_state=random_state).reset_index(drop=True)\n",
    "\n",
    "if USE_SUBSET:\n",
    "    df_train_imp = stratified_sample(\n",
    "        df_train_imp, y_col=TARGET_NAME,\n",
    "        frac=SUBSET_FRAC_TRAIN, max_rows=SUBSET_MAX_TRAIN,\n",
    "        random_state=SUBSET_RANDOM_STATE, min_per_class=SUBSET_MIN_PER_CL\n",
    "    )\n",
    "    df_val_imp = stratified_sample(\n",
    "        df_val_imp, y_col=TARGET_NAME,\n",
    "        frac=SUBSET_FRAC_VAL, max_rows=SUBSET_MAX_VAL,\n",
    "        random_state=SUBSET_RANDOM_STATE, min_per_class=SUBSET_MIN_PER_CL\n",
    "    )\n",
    "    print(f\"[SUBSET] train -> {df_train_imp.shape}, val -> {df_val_imp.shape}\")\n",
    "\n",
    "# --- 1) Drop des colonnes *_missing si demandé ---\n",
    "if no_flag_missing:\n",
    "    def _missing_flag_cols(df: pd.DataFrame) -> list[str]:\n",
    "        cols = df.columns\n",
    "        mask = cols.str.startswith(\"was_missing_\") | cols.str.endswith(\"_missing\")\n",
    "        return cols[mask].tolist()\n",
    "\n",
    "    missing_cols = sorted(set(_missing_flag_cols(df_train_imp)) | set(_missing_flag_cols(df_val_imp)))\n",
    "    if missing_cols:\n",
    "        logger.info(\"Suppression des colonnes indicatrices de manquants : %s\", missing_cols)\n",
    "        df_train_imp.drop(columns=missing_cols, inplace=True, errors=\"ignore\")\n",
    "        df_val_imp.drop(columns=missing_cols, inplace=True, errors=\"ignore\")\n",
    "\n",
    "\n",
    "# --- 2) Denylist FORTE (toujours retirée) ---\n",
    "denylist_strict = [\n",
    "    \"first_payment_date\",       # proxy temporel\n",
    "    \"maturity_date\",            # proxy temporel redondant\n",
    "    \"vintage\",                  # proxy temporel\n",
    "    \"mi_cancellation_indicator\" # post-événement → fuite\n",
    "]\n",
    "df_train_imp.drop(columns=denylist_strict, inplace=True, errors=\"ignore\")\n",
    "df_val_imp.drop(columns=denylist_strict, inplace=True, errors=\"ignore\")\n",
    "\n",
    "print(\"train shape:\", df_train_imp.shape)\n",
    "print(\"val   shape:\", df_val_imp.shape)\n",
    "\n",
    "# ============================================\n",
    "# Utils Gini (X=Good, Y=Bad)\n",
    "# ============================================\n",
    "def gini_trapz(df_cum,\n",
    "               y_col=\"bad_client_share_cumsum\",\n",
    "               x_col=\"good_client_share_cumsum\",\n",
    "               signed=False):\n",
    "    df = df_cum[[x_col, y_col]].astype(float).copy().sort_values(x_col)\n",
    "    df[x_col] = df[x_col].clip(0, 1)\n",
    "    df[y_col] = df[y_col].clip(0, 1)\n",
    "    if df[x_col].iloc[0] > 0 or df[y_col].iloc[0] > 0:\n",
    "        df = pd.concat([pd.DataFrame({x_col: [0.0], y_col: [0.0]}), df], ignore_index=True)\n",
    "    if df[x_col].iloc[-1] < 1 - 1e-12 or df[y_col].iloc[-1] < 1 - 1e-12:\n",
    "        df = pd.concat([df, pd.DataFrame({x_col: [1.0], y_col: [1.0]})], ignore_index=True)\n",
    "    x = df[x_col].to_numpy()\n",
    "    y = df[y_col].to_numpy()\n",
    "    area = np.trapezoid(y, x) if hasattr(np, \"trapezoid\") else np.trapz(y, x)\n",
    "    g = 1 - 2 * area\n",
    "    return g if signed else abs(g)\n",
    "\n",
    "# ======================================================\n",
    "# Dé-one-hot (protège la cible) + contrôle d'exclusivité\n",
    "# ======================================================\n",
    "def detect_onehot_groups(df, allow_singleton=True, exclude_cols=None,\n",
    "                         exclusivity_check=True, exclusivity_thr=0.95):\n",
    "    exclude = set(exclude_cols or [])\n",
    "    groups = {}\n",
    "    for col in df.columns:\n",
    "        if col in exclude or \"_\" not in col:\n",
    "            continue\n",
    "        base, label = col.rsplit(\"_\", 1)\n",
    "        s = df[col]\n",
    "        is_ohe = (pd.api.types.is_bool_dtype(s) or\n",
    "                  (pd.api.types.is_numeric_dtype(s) and s.dropna().isin([0, 1]).all()))\n",
    "        if is_ohe:\n",
    "            groups.setdefault(base, []).append((col, label))\n",
    "\n",
    "    clean = {}\n",
    "    for base, items in groups.items():\n",
    "        if len(items) >= 2 or allow_singleton:\n",
    "            if exclusivity_check:\n",
    "                cols_sorted = [c for c, _ in items]\n",
    "                vals = df[cols_sorted].apply(pd.to_numeric, errors=\"coerce\")\n",
    "                row_sum = vals.fillna(0).astype(\"Int64\").sum(axis=1)\n",
    "                excl_rate = float(((row_sum <= 1) | row_sum.isna()).mean())\n",
    "                if excl_rate < exclusivity_thr:\n",
    "                    logger.warning(\"[WARN] OHE: groupe '%s' exclus (exclusivité %.1f%% < %.1f%%).\",\n",
    "                                   base, 100*excl_rate, 100*exclusivity_thr)\n",
    "                    continue\n",
    "            clean[base] = items\n",
    "    return clean\n",
    "\n",
    "def deonehot_categoricals(df, allow_singleton=False, exclude_cols=None,\n",
    "                          ambiguous_label=None,\n",
    "                          exclusivity_check=True, exclusivity_thr=0.95):\n",
    "    groups = detect_onehot_groups(\n",
    "        df, allow_singleton=allow_singleton, exclude_cols=exclude_cols,\n",
    "        exclusivity_check=exclusivity_check, exclusivity_thr=exclusivity_thr\n",
    "    )\n",
    "    out = df.copy()\n",
    "\n",
    "    def label_sort_key(lab):\n",
    "        return (1, \"\") if lab == \"<NA>\" else (0, str(lab))\n",
    "\n",
    "    for base, items in groups.items():\n",
    "        items_sorted = sorted(items, key=lambda x: label_sort_key(x[1]))\n",
    "        cols_sorted = [c for c, _ in items_sorted]\n",
    "        labels = [lab for _, lab in items_sorted]\n",
    "\n",
    "        group_vals = df[cols_sorted].apply(pd.to_numeric, errors=\"coerce\")\n",
    "        row_sum = group_vals.fillna(0).astype(\"Int64\").sum(axis=1)\n",
    "        n_amb = int((row_sum > 1).sum())\n",
    "        if n_amb > 0:\n",
    "            rate = n_amb / max(len(df), 1)\n",
    "            logger.warning(\"[WARN] deonehot: groupe '%s' ambigu sur %d lignes (%.2f%%). NaN affectés.\",\n",
    "                           base, n_amb, 100*rate)\n",
    "\n",
    "        if len(items_sorted) == 1 and allow_singleton:\n",
    "            col, lab = items_sorted[0]\n",
    "            ser = pd.Series(\"__OTHER__\", index=df.index, dtype=\"object\")\n",
    "            mask = (df[col] == 1)\n",
    "            ser[mask] = (pd.NA if lab == \"<NA>\" else lab)\n",
    "            if n_amb > 0:\n",
    "                amb_mask = row_sum > 1\n",
    "                ser[amb_mask] = ambiguous_label if ambiguous_label is not None else pd.NA\n",
    "            out[base] = ser.astype(\"category\")\n",
    "            out.drop(columns=[col], inplace=True, errors=\"ignore\")\n",
    "            continue\n",
    "\n",
    "        if len(items_sorted) >= 2:\n",
    "            ser = pd.Series(pd.NA, index=df.index, dtype=\"object\")\n",
    "            for c, lab in zip(cols_sorted, labels):\n",
    "                mask = (df[c] == 1)\n",
    "                ser[mask] = (pd.NA if lab == \"<NA>\" else lab)\n",
    "            if n_amb > 0:\n",
    "                amb_mask = row_sum > 1\n",
    "                ser[amb_mask] = ambiguous_label if ambiguous_label is not None else pd.NA\n",
    "            out[base] = ser.astype(\"category\")\n",
    "            out.drop(columns=cols_sorted, inplace=True, errors=\"ignore\")\n",
    "\n",
    "    return out\n",
    "\n",
    "# ======================================\n",
    "# Cible binaire (auto/forcée)\n",
    "# ======================================\n",
    "def infer_binary_target(df, prefer_name_patterns=('default', 'delinq', 'bad', 'target', 'label')):\n",
    "    candidates = []\n",
    "    for col in df.columns:\n",
    "        s = df[col]\n",
    "        is_bool = pd.api.types.is_bool_dtype(s)\n",
    "        is_binary_int = (pd.api.types.is_integer_dtype(s) or pd.api.types.is_numeric_dtype(s)) and s.dropna().isin([0, 1]).all()\n",
    "        is_binary_cat = isinstance(s.dtype, pd.CategoricalDtype) and s.dropna().nunique() == 2\n",
    "        if is_bool or is_binary_int or is_binary_cat:\n",
    "            score = 0.0\n",
    "            name_lower = col.lower()\n",
    "            for p in prefer_name_patterns:\n",
    "                if p in name_lower:\n",
    "                    score += 10.0\n",
    "            try:\n",
    "                score += float(1 - min(max(float(s.astype(\"Int64\").mean(skipna=True)), 1e-6), 1 - 1e-6))\n",
    "            except Exception:\n",
    "                pass\n",
    "            candidates.append((score, col))\n",
    "    if not candidates:\n",
    "        raise ValueError(\"Aucune colonne binaire éligible trouvée pour servir de cible.\")\n",
    "    candidates.sort(reverse=True)\n",
    "    target = candidates[0][1]\n",
    "    rate = float(pd.to_numeric(df[target], errors=\"coerce\").fillna(0).mean())\n",
    "    logger.info(\"[INFO] Cible inférée: '%s' (taux d'événements ≈ %.3f)\", target, rate)\n",
    "    return target\n",
    "\n",
    "# ===================================================\n",
    "# Colonnes catégorielles brutes\n",
    "# ===================================================\n",
    "def find_categorical_columns(df, target_col=None, max_levels_object=50, exclude_ids=None):\n",
    "    exclude_ids = set(exclude_ids or [])\n",
    "    cat_cols = []\n",
    "    for col in df.columns:\n",
    "        if col == target_col or col in exclude_ids:\n",
    "            continue\n",
    "        s = df[col]\n",
    "        if isinstance(s.dtype, pd.CategoricalDtype) or pd.api.types.is_bool_dtype(s):\n",
    "            cat_cols.append(col)\n",
    "        elif pd.api.types.is_object_dtype(s) or str(s.dtype).startswith(\"string\"):\n",
    "            if s.nunique(dropna=True) <= max_levels_object:\n",
    "                cat_cols.append(col)\n",
    "        elif pd.api.types.is_integer_dtype(s) and s.nunique(dropna=True) <= 8:\n",
    "            if not any(k in col.lower() for k in ['id', 'sequence', 'loan_sequence']):\n",
    "                cat_cols.append(col)\n",
    "    return cat_cols\n",
    "\n",
    "def extract_ordinal_info(df, cat_cols):\n",
    "    ordinal_cols, explicit_orders = [], {}\n",
    "    for col in cat_cols:\n",
    "        s = df[col]\n",
    "        if isinstance(s.dtype, pd.CategoricalDtype) and getattr(s.dtype, \"ordered\", False):\n",
    "            ordinal_cols.append(col)\n",
    "            explicit_orders[col] = list(s.dtype.categories)\n",
    "    return ordinal_cols, explicit_orders\n",
    "\n",
    "# =========================================================\n",
    "# Binning catégoriel (fusion pour max |Gini|)\n",
    "# =========================================================\n",
    "def _cat_stats(df, col, target_col=\"target\",\n",
    "               include_missing=True, missing_label=\"__MISSING__\"):\n",
    "    target = df[target_col].astype(int)\n",
    "    ser = df[col]\n",
    "    if include_missing:\n",
    "        ser = ser.astype(\"object\").where(ser.notna(), missing_label)\n",
    "    tmp = pd.DataFrame({col: ser, target_col: target})\n",
    "    agg = tmp.groupby(col, dropna=not include_missing)[target_col].agg([\"sum\", \"count\"])\n",
    "    agg.rename(columns={\"sum\": \"n_bad\", \"count\": \"n_total\"}, inplace=True)\n",
    "    agg[\"n_good\"] = agg[\"n_total\"] - agg[\"n_bad\"]\n",
    "    n_total = len(df)\n",
    "    n_bad = int(target.sum())\n",
    "    n_good = n_total - n_bad\n",
    "    denom_bad = n_bad if n_bad > 0 else 1\n",
    "    denom_good = n_good if n_good > 0 else 1\n",
    "    agg[\"bad_rate\"] = agg[\"n_bad\"] / agg[\"n_total\"].where(agg[\"n_total\"] > 0, 1)\n",
    "    agg[\"bad_share\"] = agg[\"n_bad\"] / denom_bad\n",
    "    agg[\"good_share\"] = agg[\"n_good\"] / denom_good\n",
    "    return agg.reset_index().rename(columns={col: \"modality\"})\n",
    "\n",
    "def _groups_df_from_bins(stats_df, bins, order_key=\"bad_rate\", ascending=True):\n",
    "    rows = []\n",
    "    for i, mods in enumerate(bins):\n",
    "        sub = stats_df[stats_df[\"modality\"].isin(mods)]\n",
    "        n_bad = int(sub[\"n_bad\"].sum())\n",
    "        n_good = int(sub[\"n_good\"].sum())\n",
    "        n_tot = int(sub[\"n_total\"].sum())\n",
    "        br = n_bad / n_tot if n_tot > 0 else 0.0\n",
    "        rows.append({\"bin_id\": i, \"modalities\": tuple(mods),\n",
    "                     \"n_total\": n_tot, \"n_bad\": n_bad, \"n_good\": n_good,\n",
    "                     \"bad_rate\": br,\n",
    "                     \"bad_share\": sub[\"bad_share\"].sum(),\n",
    "                     \"good_share\": sub[\"good_share\"].sum()})\n",
    "    gdf = pd.DataFrame(rows).sort_values(order_key, ascending=ascending, kind=\"mergesort\").reset_index(drop=True)\n",
    "    gdf[\"bad_cum\"] = gdf[\"bad_share\"].cumsum()\n",
    "    gdf[\"good_cum\"] = gdf[\"good_share\"].cumsum()\n",
    "    return gdf\n",
    "\n",
    "def _gini_from_bins(stats_df, bins, order_key=\"bad_rate\", ascending=True):\n",
    "    gdf = _groups_df_from_bins(stats_df, bins, order_key, ascending)\n",
    "    df_cum = gdf.rename(columns={\"good_cum\": \"good_client_share_cumsum\",\n",
    "                                 \"bad_cum\": \"bad_client_share_cumsum\"})[[\"good_client_share_cumsum\", \"bad_client_share_cumsum\"]]\n",
    "    return gini_trapz(df_cum, y_col=\"bad_client_share_cumsum\",\n",
    "                      x_col=\"good_client_share_cumsum\", signed=False)\n",
    "\n",
    "def _initial_order(stats_df, ordered=False, explicit_order=None, nominal_order_key=\"bad_rate\"):\n",
    "    if ordered:\n",
    "        order = list(explicit_order) if explicit_order is not None else list(stats_df[\"modality\"])\n",
    "        order = [m for m in order if m in set(stats_df[\"modality\"])] + \\\n",
    "                [m for m in stats_df[\"modality\"] if m not in set(order)]\n",
    "    else:\n",
    "        order = list(stats_df.sort_values(nominal_order_key)[\"modality\"])\n",
    "    return order\n",
    "\n",
    "def _reorder_after_merge(groups, stats_df, ordered, nominal_order_key=\"bad_rate\"):\n",
    "    if ordered:\n",
    "        return groups\n",
    "\n",
    "    def grp_bad_rate(mods):\n",
    "        sub = stats_df[stats_df[\"modality\"].isin(mods)]\n",
    "        nb, nt = sub[\"n_bad\"].sum(), sub[\"n_total\"].sum()\n",
    "        return (nb / nt) if nt > 0 else 0.0\n",
    "\n",
    "    return sorted(groups, key=lambda mods: grp_bad_rate(mods))\n",
    "\n",
    "def maximize_gini_via_merging(\n",
    "    df, col, target_col,\n",
    "    include_missing=True, missing_label=\"__MISSING__\",\n",
    "    ordered=False, explicit_order=None,\n",
    "    max_bins=6, min_bin_size=200, min_bin_frac=None,\n",
    "    order_key_for_curve=\"bad_rate\", nominal_order_key=\"bad_rate\"\n",
    "):\n",
    "    stats_df = _cat_stats(df, col, target_col, include_missing, missing_label)\n",
    "    order = _initial_order(stats_df, ordered, explicit_order, nominal_order_key)\n",
    "    groups = [[m] for m in order]\n",
    "    if len(groups) <= 1:\n",
    "        mapping = {m: 0 for m in order}\n",
    "        gdf_final = _groups_df_from_bins(stats_df, groups, order_key_for_curve, True)\n",
    "        gini_single = _gini_from_bins(stats_df, groups, order_key_for_curve, True)\n",
    "        return {\"mapping\": mapping, \"gini_before\": float(gini_single), \"gini_after\": float(gini_single),\n",
    "                \"bins_table\": gdf_final, \"bins\": [tuple(grp) for grp in groups]}\n",
    "\n",
    "    n_total = int(stats_df[\"n_total\"].sum())\n",
    "    min_needed = 0\n",
    "    if min_bin_frac is not None:\n",
    "        min_needed = max(min_needed, math.ceil(float(min_bin_frac) * max(n_total, 1)))\n",
    "    if min_bin_size is not None:\n",
    "        min_needed = max(min_needed, int(min_bin_size))\n",
    "\n",
    "    def constraints_ok(groups_):\n",
    "        if max_bins is not None and len(groups_) > max_bins:\n",
    "            return False\n",
    "        if min_needed and min_needed > 0:\n",
    "            for mods in groups_:\n",
    "                if int(stats_df[stats_df[\"modality\"].isin(mods)][\"n_total\"].sum()) < min_needed:\n",
    "                    return False\n",
    "        return True\n",
    "\n",
    "    while not constraints_ok(groups):\n",
    "        best_g, best_i = -np.inf, None\n",
    "        for i in range(len(groups) - 1):\n",
    "            merged = groups[:i] + [groups[i] + groups[i + 1]] + groups[i + 2:]\n",
    "            merged = _reorder_after_merge(merged, stats_df, ordered, nominal_order_key)\n",
    "            g_try = _gini_from_bins(stats_df, merged, order_key_for_curve, True)\n",
    "            if g_try > best_g:\n",
    "                best_g, best_i = g_try, i\n",
    "        if best_i is None:\n",
    "            best_i = 0\n",
    "        groups = groups[:best_i] + [groups[best_i] + groups[best_i + 1]] + groups[best_i + 2:]\n",
    "        groups = _reorder_after_merge(groups, stats_df, ordered, nominal_order_key)\n",
    "\n",
    "    gini_before = _gini_from_bins(stats_df, [[m] for m in order], order_key_for_curve, True)\n",
    "    gini_after  = _gini_from_bins(stats_df, groups, order_key_for_curve, True)\n",
    "    final_bins  = [tuple(mods) for mods in groups]\n",
    "    mapping     = {m: b for b, mods in enumerate(final_bins) for m in mods}\n",
    "    gdf_final   = _groups_df_from_bins(stats_df, groups, order_key_for_curve, True)\n",
    "    return {\"mapping\": mapping, \"gini_before\": float(gini_before), \"gini_after\": float(gini_after),\n",
    "            \"bins_table\": gdf_final, \"bins\": final_bins}\n",
    "\n",
    "# ==========================================================\n",
    "# Binning numérique (quantiles glouton, max |Gini|)\n",
    "#            + conversions dates -> jours + edges sûres\n",
    "# ==========================================================\n",
    "def _is_period_dtype(dt):\n",
    "    try:\n",
    "        return pd.api.types.is_period_dtype(dt)\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "def _to_float_series(s):\n",
    "    if _is_period_dtype(s.dtype):\n",
    "        ts = s.dt.to_timestamp(how=\"start\")\n",
    "        days = (ts.astype(\"int64\") // 86_400_000_000_000)\n",
    "        return days.astype(\"float64\")\n",
    "    if pd.api.types.is_datetime64_any_dtype(s):\n",
    "        s_dt = s\n",
    "        try:\n",
    "            if getattr(s_dt.dt, \"tz\", None) is not None:\n",
    "                s_dt = s_dt.dt.tz_convert(None)\n",
    "        except Exception:\n",
    "            pass\n",
    "        s_dt = s_dt.astype(\"datetime64[ns]\")\n",
    "        days = (s_dt.astype(\"int64\") // 86_400_000_000_000)\n",
    "        return days.astype(\"float64\")\n",
    "    if pd.api.types.is_numeric_dtype(s):\n",
    "        return pd.to_numeric(s, errors=\"coerce\").astype(\"float64\")\n",
    "    return pd.to_numeric(s, errors=\"coerce\").astype(\"float64\")\n",
    "\n",
    "def _safe_edges_for_cut(edges, s_float):\n",
    "    e = np.array(edges, dtype=\"float64\")\n",
    "    for i in range(1, len(e)):\n",
    "        if not (e[i] > e[i - 1]):\n",
    "            e[i] = np.nextafter(e[i - 1], np.inf)\n",
    "    s_vals = s_float.to_numpy()\n",
    "    try:\n",
    "        s_min = float(np.nanmin(s_vals))\n",
    "        s_max = float(np.nanmax(s_vals))\n",
    "    except ValueError:\n",
    "        s_min, s_max = -1.0, 1.0\n",
    "    rel_eps_lo = 1e-6 * (abs(e[1]) + 1.0) if len(e) > 1 else 1e-6\n",
    "    rel_eps_hi = 1e-6 * (abs(e[-2]) + 1.0) if len(e) > 1 else 1e-6\n",
    "    if len(e) >= 2:\n",
    "        e[0]  = min(e[1] - rel_eps_lo, s_min - rel_eps_lo)\n",
    "        e[-1] = max(e[-2] + rel_eps_hi, s_max + rel_eps_hi)\n",
    "    return e\n",
    "\n",
    "def _gini_from_numeric_bins(y_int, x_float, edges, include_missing=True):\n",
    "    y = y_int.astype(int).to_numpy()\n",
    "    x = x_float.to_numpy()\n",
    "    bins_idx = np.digitize(x, edges[1:-1], right=True)\n",
    "    K = len(edges) - 1\n",
    "    n_total = len(y)\n",
    "    n_bad = int(y.sum())\n",
    "    n_good = n_total - n_bad\n",
    "    denom_bad = n_bad if n_bad > 0 else 1\n",
    "    denom_good = n_good if n_good > 0 else 1\n",
    "    rows = []\n",
    "    for k in range(K):\n",
    "        mask = (bins_idx == k) & ~np.isnan(x)\n",
    "        nk = int(mask.sum())\n",
    "        nb = int(y[mask].sum())\n",
    "        ng = nk - nb\n",
    "        br = nb / nk if nk > 0 else 0.0\n",
    "        rows.append({\"bin\": k, \"n_total\": nk, \"n_bad\": nb, \"n_good\": ng, \"bad_rate\": br})\n",
    "    if include_missing and np.isnan(x).any():\n",
    "        mask = np.isnan(x)\n",
    "        nk = int(mask.sum())\n",
    "        nb = int(y[mask].sum())\n",
    "        ng = nk - nb\n",
    "        br = nb / nk if nk > 0 else 0.0\n",
    "        rows.append({\"bin\": K, \"n_total\": nk, \"n_bad\": nb, \"n_good\": ng, \"bad_rate\": br})\n",
    "\n",
    "    gdf = pd.DataFrame(rows)\n",
    "    if gdf.empty:\n",
    "        return 0.0, gdf\n",
    "    gdf[\"bad_share\"]  = gdf[\"n_bad\"]  / denom_bad\n",
    "    gdf[\"good_share\"] = gdf[\"n_good\"] / denom_good\n",
    "    gdf = gdf.sort_values(\"bad_rate\").reset_index(drop=True)\n",
    "    gdf[\"bad_cum\"]  = gdf[\"bad_share\"].cumsum()\n",
    "    gdf[\"good_cum\"] = gdf[\"good_share\"].cumsum()\n",
    "    df_cum = gdf.rename(columns={\"good_cum\": \"good_client_share_cumsum\",\n",
    "                                 \"bad_cum\": \"bad_client_share_cumsum\"})[[\"good_client_share_cumsum\", \"bad_client_share_cumsum\"]]\n",
    "    g = gini_trapz(df_cum, y_col=\"bad_client_share_cumsum\",\n",
    "                   x_col=\"good_client_share_cumsum\", signed=False)\n",
    "    return g, gdf\n",
    "\n",
    "def optimize_numeric_binning_by_quantiles(\n",
    "    df, col, target_col,\n",
    "    max_bins=6, min_bin_size=200, min_bin_frac=None,\n",
    "    n_quantiles=50, q_low=0.02, q_high=0.98,\n",
    "    include_missing=True, min_gain=1e-5\n",
    "):\n",
    "    s = _to_float_series(df[col])\n",
    "    y = df[target_col].astype(int)\n",
    "    nunique = s.dropna().nunique()\n",
    "\n",
    "    if nunique < 2:\n",
    "        s_f = s[np.isfinite(s)]\n",
    "        if s_f.empty:\n",
    "            e_cut = np.array([-1.0, 1.0], dtype=\"float64\")\n",
    "        else:\n",
    "            lo, hi = float(np.nanmin(s_f)), float(np.nanmax(s_f))\n",
    "            eps = 1e-6 * (abs(lo) + abs(hi) + 1.0)\n",
    "            e_cut = np.array([lo - eps, hi + eps], dtype=\"float64\")\n",
    "        g0, _ = _gini_from_numeric_bins(y, s, [-np.inf, np.inf], include_missing)\n",
    "        return {\"edges\": [-np.inf, np.inf], \"edges_for_cut\": e_cut, \"labels\": [f\"({e_cut[0]}, {e_cut[1]}]\"],\n",
    "                \"gini_before\": float(g0), \"gini_after\": float(g0), \"bins_table\": pd.DataFrame()}\n",
    "\n",
    "    qs = np.linspace(q_low, q_high, n_quantiles)\n",
    "    cand_vals = s.quantile(qs).dropna().unique()\n",
    "    cand_vals = np.unique(cand_vals)\n",
    "    edges = [-np.inf, np.inf]\n",
    "\n",
    "    n = len(s)\n",
    "    min_needed = 0\n",
    "    if min_bin_frac is not None:\n",
    "        min_needed = max(min_needed, math.ceil(float(min_bin_frac) * max(n, 1)))\n",
    "    if min_bin_size is not None:\n",
    "        min_needed = max(min_needed, int(min_bin_size))\n",
    "\n",
    "    def edges_ok(e):\n",
    "        arr = s.to_numpy()\n",
    "        bins_idx = np.digitize(arr, e[1:-1], right=True)\n",
    "        for k in range(len(e) - 1):\n",
    "            if int(((bins_idx == k) & ~np.isnan(arr)).sum()) < min_needed:\n",
    "                return False\n",
    "        return True\n",
    "\n",
    "    gini0, _ = _gini_from_numeric_bins(y, s, edges, include_missing)\n",
    "    best_gini = gini0\n",
    "    improved = True\n",
    "    while improved and (len(edges) - 1) < max_bins:\n",
    "        improved = False\n",
    "        best_gain = min_gain\n",
    "        best_t = None\n",
    "        g_best = best_gini\n",
    "        for t in cand_vals:\n",
    "            if t in edges:\n",
    "                continue\n",
    "            new_edges = sorted([*edges, t])\n",
    "            if any(np.isclose(new_edges[i], new_edges[i + 1]) for i in range(len(new_edges) - 1)):\n",
    "                continue\n",
    "            if not edges_ok(new_edges):\n",
    "                continue\n",
    "            g_try, _ = _gini_from_numeric_bins(y, s, new_edges, include_missing)\n",
    "            gain = g_try - best_gini\n",
    "            if gain > best_gain:\n",
    "                best_gain, best_t, g_best = gain, t, g_try\n",
    "        if best_t is not None:\n",
    "            edges = sorted([*edges, best_t])\n",
    "            best_gini = g_best\n",
    "            improved = True\n",
    "\n",
    "    gini_after, bins_table = _gini_from_numeric_bins(y, s, edges, include_missing)\n",
    "    e = sorted(edges)\n",
    "    e_cut = _safe_edges_for_cut(e, s)\n",
    "    labels = [f\"({e[i]}, {e[i + 1]}]\" for i in range(len(e) - 1)]\n",
    "    return {\"edges\": e, \"edges_for_cut\": e_cut, \"labels\": labels,\n",
    "            \"gini_before\": float(gini0), \"gini_after\": float(gini_after),\n",
    "            \"bins_table\": bins_table}\n",
    "\n",
    "# ==========================================================\n",
    "# Parallélisation — helpers\n",
    "# ==========================================================\n",
    "def _compute_cat_bin_result(df_small, col, target_col,\n",
    "                            include_missing, missing_label,\n",
    "                            is_ord, explicit_order,\n",
    "                            max_bins, min_bin_size, min_bin_frac,\n",
    "                            order_key_for_curve, nominal_order_key):\n",
    "    res = maximize_gini_via_merging(\n",
    "        df=df_small, col=col, target_col=target_col,\n",
    "        include_missing=include_missing, missing_label=missing_label,\n",
    "        ordered=is_ord, explicit_order=explicit_order,\n",
    "        max_bins=max_bins, min_bin_size=min_bin_size, min_bin_frac=min_bin_frac,\n",
    "        order_key_for_curve=order_key_for_curve, nominal_order_key=nominal_order_key\n",
    "    )\n",
    "    return col, res\n",
    "\n",
    "def _compute_num_bin_result(df_small, col, target_col,\n",
    "                            max_bins, min_bin_size, min_bin_frac, n_quantiles,\n",
    "                            include_missing):\n",
    "    res = optimize_numeric_binning_by_quantiles(\n",
    "        df=df_small, col=col, target_col=target_col,\n",
    "        max_bins=max_bins, min_bin_size=min_bin_size, min_bin_frac=min_bin_frac,\n",
    "        n_quantiles=n_quantiles, include_missing=include_missing\n",
    "    )\n",
    "    return col, res\n",
    "\n",
    "# ==========================================================\n",
    "# Catégorielles (parallélisées)\n",
    "# ==========================================================\n",
    "def auto_bin_all_categoricals(\n",
    "    df, cat_columns, target_col,\n",
    "    include_missing=True, missing_label=\"__MISSING__\",\n",
    "    ordinal_cols=None, explicit_orders=None,\n",
    "    max_bins=6, min_bin_size=200, min_bin_frac=None,\n",
    "    order_key_for_curve=\"bad_rate\", nominal_order_key=\"bad_rate\",\n",
    "    add_binned_columns=True, bin_col_suffix=\"__BIN\",\n",
    "    n_jobs=1, verbose=0\n",
    "):\n",
    "    set_verbosity(verbose)\n",
    "    ordinal_cols = set(ordinal_cols or [])\n",
    "    explicit_orders = explicit_orders or {}\n",
    "    df_out = df.copy()\n",
    "    results, summary_rows = {}, []\n",
    "\n",
    "    if n_jobs != 1 and Parallel is not None and len(cat_columns) > 0:\n",
    "        tasks = (\n",
    "            delayed(_compute_cat_bin_result)(\n",
    "                df_out[[col, target_col]].copy(),\n",
    "                col, target_col,\n",
    "                include_missing, missing_label,\n",
    "                (col in ordinal_cols), explicit_orders.get(col),\n",
    "                max_bins, min_bin_size, min_bin_frac,\n",
    "                order_key_for_curve, nominal_order_key\n",
    "            )\n",
    "            for col in cat_columns\n",
    "        )\n",
    "        out = Parallel(n_jobs=n_jobs, backend=\"loky\", verbose=verbose)(list(tasks))\n",
    "        for col, res in out:\n",
    "            results[col] = res\n",
    "    else:\n",
    "        for col in cat_columns:\n",
    "            is_ord = col in ordinal_cols\n",
    "            res = maximize_gini_via_merging(\n",
    "                df=df_out, col=col, target_col=target_col,\n",
    "                include_missing=include_missing, missing_label=missing_label,\n",
    "                ordered=is_ord, explicit_order=explicit_orders.get(col),\n",
    "                max_bins=max_bins, min_bin_size=min_bin_size, min_bin_frac=min_bin_frac,\n",
    "                order_key_for_curve=order_key_for_curve, nominal_order_key=nominal_order_key\n",
    "            )\n",
    "            results[col] = res\n",
    "\n",
    "    for col, res in results.items():\n",
    "        summary_rows.append({\n",
    "            \"variable\": col, \"type\": \"categorical\",\n",
    "            \"n_bins_final\": len(res[\"bins\"]),\n",
    "            \"gini_before\": res[\"gini_before\"],\n",
    "            \"gini_after\": res[\"gini_after\"],\n",
    "            \"gini_gain\": res[\"gini_after\"] - res[\"gini_before\"]\n",
    "        })\n",
    "        if add_binned_columns and col in df_out.columns:\n",
    "            ser = df_out[col].astype(\"object\")\n",
    "            if include_missing:\n",
    "                ser = ser.where(ser.notna(), missing_label)\n",
    "            df_out[col + bin_col_suffix] = ser.map(res[\"mapping\"]).astype(\"Int64\")\n",
    "\n",
    "    summary = (pd.DataFrame(summary_rows)\n",
    "               .sort_values(\"gini_after\", ascending=False)\n",
    "               .reset_index(drop=True))\n",
    "    return {\"results\": results, \"summary\": summary, \"df\": df_out}\n",
    "\n",
    "# ==========================================================\n",
    "# Numériques (parallélisées)\n",
    "# ==========================================================\n",
    "def auto_bin_all_numerics(\n",
    "    df, target_col,\n",
    "    max_bins=6, min_bin_size=200, min_bin_frac=None,\n",
    "    n_quantiles=50, include_missing=True,\n",
    "    add_binned_columns=True, bin_col_suffix=\"__BIN\",\n",
    "    exclude_ids=None,\n",
    "    n_jobs=1, verbose=0\n",
    "):\n",
    "    set_verbosity(verbose)\n",
    "    exclude_ids = set(exclude_ids or [])\n",
    "    df_out = df.copy()\n",
    "    results, summary_rows = {}, []\n",
    "\n",
    "    numeric_cols = []\n",
    "    for col in df.columns:\n",
    "        if col == target_col or col in exclude_ids:\n",
    "            continue\n",
    "        s = df[col]\n",
    "        if pd.api.types.is_numeric_dtype(s) and not pd.api.types.is_bool_dtype(s):\n",
    "            if s.dropna().isin([0, 1]).all():\n",
    "                continue\n",
    "            if pd.api.types.is_integer_dtype(s) and s.dropna().nunique() <= 8:\n",
    "                continue\n",
    "            if any(k in col.lower() for k in ['id', 'sequence', 'postal', 'zip', 'msa', 'code', 'seller', 'servicer']):\n",
    "                continue\n",
    "            numeric_cols.append(col)\n",
    "        elif _is_period_dtype(s.dtype) or pd.api.types.is_datetime64_any_dtype(s):\n",
    "            numeric_cols.append(col)\n",
    "\n",
    "    if n_jobs != 1 and Parallel is not None and len(numeric_cols) > 0:\n",
    "        tasks = (\n",
    "            delayed(_compute_num_bin_result)(\n",
    "                df_out[[col, target_col]].copy(),\n",
    "                col, target_col,\n",
    "                max_bins, min_bin_size, min_bin_frac, n_quantiles,\n",
    "                include_missing\n",
    "            )\n",
    "            for col in numeric_cols\n",
    "        )\n",
    "        out = Parallel(n_jobs=n_jobs, backend=\"loky\", verbose=verbose)(list(tasks))\n",
    "        for col, res in out:\n",
    "            results[col] = res\n",
    "    else:\n",
    "        for col in numeric_cols:\n",
    "            res = optimize_numeric_binning_by_quantiles(\n",
    "                df=df_out, col=col, target_col=target_col,\n",
    "                max_bins=max_bins, min_bin_size=min_bin_size, min_bin_frac=min_bin_frac,\n",
    "                n_quantiles=n_quantiles, include_missing=include_missing\n",
    "            )\n",
    "            results[col] = res\n",
    "\n",
    "    for col, res in results.items():\n",
    "        summary_rows.append({\n",
    "            \"variable\": col, \"type\": \"numeric\",\n",
    "            \"n_bins_final\": len(res[\"edges\"]) - 1,\n",
    "            \"gini_before\": res[\"gini_before\"],\n",
    "            \"gini_after\": res[\"gini_after\"],\n",
    "            \"gini_gain\": res[\"gini_after\"] - res[\"gini_before\"]\n",
    "        })\n",
    "        if add_binned_columns and col in df_out.columns:\n",
    "            s = _to_float_series(df_out[col])\n",
    "            b = pd.cut(s, bins=res[\"edges_for_cut\"], include_lowest=True, duplicates=\"drop\")\n",
    "            b = b.cat.codes.astype(\"Int64\")\n",
    "            if include_missing and s.isna().any():\n",
    "                b = b.where(~s.isna(), -1).astype(\"Int64\")\n",
    "            df_out[col + bin_col_suffix] = b\n",
    "\n",
    "    summary = (pd.DataFrame(summary_rows)\n",
    "               .sort_values(\"gini_after\", ascending=False)\n",
    "               .reset_index(drop=True))\n",
    "    return {\"results\": results, \"summary\": summary, \"df\": df_out}\n",
    "\n",
    "# ============================================\n",
    "# Assemblage final + One-Hot des BIN (avec -1/-2)\n",
    "# ============================================\n",
    "def _ensure_sentinel_categories(base_df: pd.DataFrame, bin_cols):\n",
    "    base = base_df.copy()\n",
    "    for c in bin_cols:\n",
    "        if c in base.columns:\n",
    "            s = base[c].astype(\"Int64\")\n",
    "            cats = sorted(set([int(v) for v in s.dropna().unique()]).union({-1, -2}))\n",
    "            base[c] = pd.Categorical(s, categories=cats)\n",
    "    return base\n",
    "\n",
    "def build_final_datasets(out_cat, out_num, drop_original=True, bin_col_suffix=\"__BIN\",\n",
    "                         keep_vars=None):\n",
    "    df_enrichi = out_num[\"df\"].copy()\n",
    "    for c in out_cat[\"df\"].columns:\n",
    "        if c.endswith(bin_col_suffix) and c not in df_enrichi.columns:\n",
    "            df_enrichi[c] = out_cat[\"df\"][c]\n",
    "\n",
    "    cat_all = list(out_cat[\"results\"].keys())\n",
    "    num_all = list(out_num[\"results\"].keys())\n",
    "\n",
    "    if keep_vars is not None:\n",
    "        keep_vars = set(keep_vars)\n",
    "        cat_keep = [c for c in cat_all if c in keep_vars]\n",
    "        num_keep = [c for c in num_all if c in keep_vars]\n",
    "    else:\n",
    "        cat_keep, num_keep = cat_all, num_all\n",
    "\n",
    "    all_bin_cols  = [c for c in df_enrichi.columns if c.endswith(bin_col_suffix)]\n",
    "    keep_bin_cols = [c + bin_col_suffix for c in (cat_keep + num_keep)]\n",
    "    drop_bin_cols = [c for c in all_bin_cols if c not in keep_bin_cols]\n",
    "\n",
    "    base_drop = cat_all + num_all + drop_bin_cols\n",
    "    if drop_original:\n",
    "        df_binned = (df_enrichi\n",
    "                     .drop(columns=base_drop, errors=\"ignore\")\n",
    "                     .rename(columns={c: c.replace(bin_col_suffix, \"\") for c in keep_bin_cols}))\n",
    "    else:\n",
    "        df_binned = df_enrichi.drop(columns=drop_bin_cols, errors=\"ignore\").copy()\n",
    "\n",
    "    base = df_enrichi.drop(columns=base_drop, errors=\"ignore\")\n",
    "    base = _ensure_sentinel_categories(base, keep_bin_cols)\n",
    "\n",
    "    df_ohe = pd.get_dummies(\n",
    "        base,\n",
    "        columns=keep_bin_cols,\n",
    "        prefix={c: c.replace(bin_col_suffix, \"\") for c in keep_bin_cols},\n",
    "        dummy_na=False,\n",
    "        dtype=np.uint8\n",
    "    )\n",
    "    df_ohe = df_ohe.reindex(sorted(df_ohe.columns), axis=1)\n",
    "    return df_enrichi, df_binned, df_ohe\n",
    "\n",
    "# ============================================\n",
    "# Sérialisation binnings (JSON)\n",
    "# ============================================\n",
    "def bins_to_dict(res, include_missing=True, missing_label=\"__MISSING__\", bin_col_suffix=\"__BIN\"):\n",
    "    return {\n",
    "        \"target\": res[\"target\"],\n",
    "        \"include_missing\": include_missing,\n",
    "        \"missing_label\": missing_label,\n",
    "        \"bin_col_suffix\": bin_col_suffix,\n",
    "        \"cat_results\": {\n",
    "            var: {\n",
    "                \"mapping\": {str(k): int(v) for k, v in info[\"mapping\"].items()},\n",
    "                \"gini_before\": info[\"gini_before\"],\n",
    "                \"gini_after\": info[\"gini_after\"],\n",
    "                \"bins\": [list(b) for b in info[\"bins\"]],\n",
    "            }\n",
    "            for var, info in res[\"cat_results\"].items()\n",
    "        },\n",
    "        \"num_results\": {\n",
    "            var: {\n",
    "                \"edges\": list(info[\"edges\"]),\n",
    "                \"edges_for_cut\": list(np.asarray(info[\"edges_for_cut\"], dtype=\"float64\")),\n",
    "                \"gini_before\": info[\"gini_before\"],\n",
    "                \"gini_after\": info[\"gini_after\"],\n",
    "                \"labels\": list(info.get(\"labels\", [])),\n",
    "            }\n",
    "            for var, info in res[\"num_results\"].items()\n",
    "        },\n",
    "    }\n",
    "\n",
    "def bins_from_dict(d):\n",
    "    return d\n",
    "\n",
    "def save_bins_json(res, path, **meta):\n",
    "    d = bins_to_dict(res, **meta)\n",
    "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(d, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "def load_bins_json(path):\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "# ============================================\n",
    "# LANCEUR complet (protège la cible, parallélisé)\n",
    "# ============================================\n",
    "def run_full_pipeline_on_onehot_df(\n",
    "    df_onehot,\n",
    "    target_col=None,\n",
    "    max_bins_categ=6, min_bin_size_categ=200, min_bin_frac_categ=None,\n",
    "    max_bins_num=6,   min_bin_size_num=200, min_bin_frac_num=200, n_quantiles_num=50,\n",
    "    include_missing=True, missing_label=\"__MISSING__\", max_levels_object=50,\n",
    "    bin_col_suffix=\"__BIN\",\n",
    "    exclude_ids=(\"loan_sequence_number\", \"postal_code\", \"seller_name\", \"servicer_name\", \"msa_md\"),\n",
    "    n_jobs_categ=-1, n_jobs_num=-1, verbose=0,\n",
    "    min_gini_keep=None\n",
    "):\n",
    "    set_verbosity(verbose)\n",
    "\n",
    "    DF = deonehot_categoricals(\n",
    "        df_onehot,\n",
    "        allow_singleton=False,\n",
    "        exclude_cols=[target_col] if target_col else None,\n",
    "        exclusivity_check=True, exclusivity_thr=0.95\n",
    "    )\n",
    "\n",
    "    if target_col is not None and target_col not in DF.columns:\n",
    "        logger.info(\"[INFO] Colonne cible '%s' introuvable après préparation. Inférence automatique...\", target_col)\n",
    "        TARGET = infer_binary_target(DF)\n",
    "    else:\n",
    "        TARGET = target_col if target_col is not None else infer_binary_target(DF)\n",
    "\n",
    "    cat_cols = find_categorical_columns(DF, target_col=TARGET, max_levels_object=max_levels_object,\n",
    "                                        exclude_ids=exclude_ids)\n",
    "    ordinal_cols, explicit_orders = extract_ordinal_info(DF, cat_cols)\n",
    "    out_cat = auto_bin_all_categoricals(\n",
    "        df=DF, cat_columns=cat_cols, target_col=TARGET,\n",
    "        include_missing=include_missing, missing_label=missing_label,\n",
    "        ordinal_cols=ordinal_cols, explicit_orders=explicit_orders,\n",
    "        max_bins=max_bins_categ, min_bin_size=min_bin_size_categ, min_bin_frac=min_bin_frac_categ,\n",
    "        order_key_for_curve=\"bad_rate\", nominal_order_key=\"bad_rate\",\n",
    "        add_binned_columns=True, bin_col_suffix=bin_col_suffix,\n",
    "        n_jobs=n_jobs_categ, verbose=verbose\n",
    "    )\n",
    "\n",
    "    out_num = auto_bin_all_numerics(\n",
    "        df=out_cat[\"df\"], target_col=TARGET,\n",
    "        max_bins=max_bins_num, min_bin_size=min_bin_size_num, min_bin_frac=min_bin_frac_num,\n",
    "        n_quantiles=n_quantiles_num, include_missing=include_missing,\n",
    "        add_binned_columns=True, bin_col_suffix=bin_col_suffix,\n",
    "        exclude_ids=exclude_ids,\n",
    "        n_jobs=n_jobs_num, verbose=verbose\n",
    "    )\n",
    "\n",
    "    summary = (pd.concat([out_cat[\"summary\"], out_num[\"summary\"]], ignore_index=True)\n",
    "               .sort_values([\"type\", \"gini_after\"], ascending=[True, False])\n",
    "               .reset_index(drop=True))\n",
    "    keep_vars = None\n",
    "    if min_gini_keep is not None:\n",
    "        keep_vars = summary.loc[summary[\"gini_after\"] >= float(min_gini_keep), \"variable\"].tolist()\n",
    "        if verbose:\n",
    "            nb_drop = (summary[\"gini_after\"] < float(min_gini_keep)).sum()\n",
    "            logger.info(\"[INFO] min_gini_keep=%s -> exclusion de %d variables.\", min_gini_keep, int(nb_drop))\n",
    "\n",
    "    df_enrichi, df_binned, df_ohe = build_final_datasets(\n",
    "        out_cat, out_num,\n",
    "        drop_original=True,\n",
    "        bin_col_suffix=bin_col_suffix,\n",
    "        keep_vars=keep_vars\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"target\": TARGET,\n",
    "        \"summary\": summary,\n",
    "        \"df_enrichi\": df_enrichi,\n",
    "        \"df_binned\": df_binned,\n",
    "        \"df_ohe\": df_ohe,\n",
    "        \"cat_results\": out_cat[\"results\"],\n",
    "        \"num_results\": out_num[\"results\"]\n",
    "    }\n",
    "\n",
    "# ============================================\n",
    "# Transformer val/test avec bins appris (protège la cible)\n",
    "# ============================================\n",
    "def transform_with_learned_bins(df_raw_onehot, res, bin_col_suffix=\"__BIN\",\n",
    "                                include_missing=True,\n",
    "                                exclude_ids=(\"loan_sequence_number\", \"postal_code\", \"seller_name\", \"servicer_name\", \"msa_md\")):\n",
    "    DF = deonehot_categoricals(\n",
    "        df_raw_onehot,\n",
    "        allow_singleton=False,\n",
    "        exclude_cols=[res[\"target\"]]\n",
    "    )\n",
    "\n",
    "    for col, r in res[\"cat_results\"].items():\n",
    "        if col not in DF.columns:\n",
    "            continue\n",
    "        s = DF[col].astype(\"object\").where(DF[col].notna(), \"__MISSING__\")\n",
    "        mapped = s.map(r[\"mapping\"]).astype(\"Int64\").fillna(-2).astype(\"Int64\")\n",
    "        DF[col + bin_col_suffix] = mapped\n",
    "\n",
    "    for col, r in res[\"num_results\"].items():\n",
    "        if col not in DF.columns:\n",
    "            continue\n",
    "        s = _to_float_series(DF[col])\n",
    "        e = np.array(r[\"edges_for_cut\"], dtype=\"float64\")\n",
    "        b = pd.cut(s, bins=e, include_lowest=True, duplicates=\"drop\").cat.codes.astype(\"Int64\")\n",
    "        if include_missing and s.isna().any():\n",
    "            b = b.where(~s.isna(), -1).astype(\"Int64\")\n",
    "        DF[col + bin_col_suffix] = b\n",
    "\n",
    "    cat_cols = list(res[\"cat_results\"].keys())\n",
    "    num_cols = list(res[\"num_results\"].keys())\n",
    "    bin_cols = [c + bin_col_suffix for c in cat_cols + num_cols if c + bin_col_suffix in DF.columns]\n",
    "\n",
    "    base = DF.drop(columns=cat_cols + num_cols, errors=\"ignore\")\n",
    "    base = _ensure_sentinel_categories(base, bin_cols)\n",
    "\n",
    "    df_model = pd.get_dummies(\n",
    "        base,\n",
    "        columns=bin_cols,\n",
    "        prefix={c: c.replace(bin_col_suffix, \"\") for c in bin_cols},\n",
    "        dummy_na=False,\n",
    "        dtype=np.uint8\n",
    "    )\n",
    "    df_model = df_model.reindex(sorted(df_model.columns), axis=1)\n",
    "    df_model = df_model.drop(columns=[c for c in exclude_ids if c in df_model.columns], errors=\"ignore\")\n",
    "    return df_model\n",
    "\n",
    "# ============================================\n",
    "# Plots des courbes (départ à 0,0)\n",
    "# ============================================\n",
    "def _curve_from_binned(df, bcol, target):\n",
    "    y = df[target].astype(int)\n",
    "    s = df[bcol].astype(\"Int64\").fillna(-1).astype(\"int64\")\n",
    "\n",
    "    agg = pd.DataFrame({bcol: s, target: y}).groupby(bcol)[target].agg([\"sum\", \"count\"])\n",
    "    agg.columns = [\"n_bad\", \"n_total\"]\n",
    "    agg[\"n_good\"] = agg[\"n_total\"] - agg[\"n_bad\"]\n",
    "\n",
    "    n_bad = int(agg[\"n_bad\"].sum())\n",
    "    n_good = int(agg[\"n_good\"].sum())\n",
    "    if n_bad == 0 or n_good == 0:\n",
    "        df_cum = pd.DataFrame({\"good_client_share_cumsum\": [0.0, 1.0],\n",
    "                               \"bad_client_share_cumsum\": [0.0, 1.0]})\n",
    "        return df_cum, 0.0\n",
    "\n",
    "    agg[\"bad_rate\"] = agg[\"n_bad\"] / agg[\"n_total\"].where(agg[\"n_total\"] > 0, 1)\n",
    "    agg[\"bad_share\"] = agg[\"n_bad\"] / n_bad\n",
    "    agg[\"good_share\"] = agg[\"n_good\"] / n_good\n",
    "\n",
    "    agg = agg.sort_values(\"bad_rate\", kind=\"mergesort\")\n",
    "    good_cum = np.r_[0.0, agg[\"good_share\"].cumsum().values]\n",
    "    bad_cum  = np.r_[0.0, agg[\"bad_share\"].cumsum().values]\n",
    "\n",
    "    df_cum = pd.DataFrame({\"good_client_share_cumsum\": good_cum,\n",
    "                           \"bad_client_share_cumsum\": bad_cum})\n",
    "    g = gini_trapz(df_cum, signed=False)\n",
    "    return df_cum, float(g)\n",
    "\n",
    "def plot_all_concentration_curves_from_binned(res, top_n=None, types=(\"categorical\", \"numeric\")):\n",
    "    df_base = res[\"df_enrichi\"]\n",
    "    target = res[\"target\"]\n",
    "    rows = []\n",
    "    for t, store in ((\"categorical\", res[\"cat_results\"]), (\"numeric\", res[\"num_results\"])):\n",
    "        if t not in types:\n",
    "            continue\n",
    "        for var, info in store.items():\n",
    "            bcol = f\"{var}__BIN\"\n",
    "            if bcol not in df_base.columns:\n",
    "                continue\n",
    "            df_cum, g = _curve_from_binned(df_base, bcol, target)\n",
    "            rows.append((t, var, g, df_cum))\n",
    "    rows.sort(key=lambda x: x[2], reverse=True)\n",
    "    if top_n is not None:\n",
    "        rows = rows[:int(top_n)]\n",
    "    for t, var, g, df_cum in rows:\n",
    "        plt.figure(figsize=(6, 6))\n",
    "        plt.plot(df_cum[\"good_client_share_cumsum\"], df_cum[\"bad_client_share_cumsum\"], marker=\"o\")\n",
    "        plt.plot([0, 1], [0, 1], linestyle=\"--\")\n",
    "        plt.title(f\"{var} [{t}] — Gini = {g:.4f}\")\n",
    "        plt.xlabel(\"Cumulative good share\")\n",
    "        plt.ylabel(\"Cumulative bad share\")\n",
    "        plt.grid(True)\n",
    "        plt.xlim(0, 1)\n",
    "        plt.ylim(0, 1)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        print(f\"{t} — {var}: Gini = {g:.6f}, nb_points={len(df_cum)}\")\n",
    "\n",
    "# =======================\n",
    "# Fit + WOE + sélection\n",
    "# =======================\n",
    "res = run_full_pipeline_on_onehot_df(\n",
    "    df_onehot=df_train_imp,\n",
    "    target_col=TARGET_NAME,\n",
    "    max_bins_categ=6, min_bin_size_categ=200, min_bin_frac_categ=None,\n",
    "    max_bins_num=6,   min_bin_size_num=200, min_bin_frac_num=None, n_quantiles_num=50,\n",
    "    include_missing=True, missing_label=\"__MISSING__\", bin_col_suffix=\"__BIN\",\n",
    "    n_jobs_categ=-1, n_jobs_num=-1,\n",
    "    verbose=10,\n",
    ")\n",
    "\n",
    "# Jeu final OHE (dispo mais non utilisé ensuite)\n",
    "cols_id = [\"loan_sequence_number\", \"postal_code\", \"seller_name\", \"servicer_name\", \"msa_md\"]\n",
    "df_final = res[\"df_ohe\"].drop(columns=[c for c in cols_id if c in res[\"df_ohe\"].columns], errors=\"ignore\")\n",
    "y_train = df_final.pop(res[\"target\"]).astype(int)\n",
    "X_train = df_final\n",
    "\n",
    "# WOE à partir des BIN sur TRAIN\n",
    "def woe_from_bin(df, target, bcol, smooth=0.5):\n",
    "    if bcol not in df.columns:\n",
    "        raise KeyError(f\"Colonne '{bcol}' absente du DataFrame.\")\n",
    "    tab = df.groupby(bcol, dropna=True)[target].agg(['sum', 'count'])\n",
    "    tab['good'] = tab['count'] - tab['sum']\n",
    "    B = float(tab['sum'].sum()); G = float(tab['good'].sum()); K = int(len(tab))\n",
    "    tab['bad_share']  = (tab['sum']  + smooth) / (B + smooth * K if B + smooth * K > 0 else 1.0)\n",
    "    tab['good_share'] = (tab['good'] + smooth) / (G + smooth * K if G + smooth * K > 0 else 1.0)\n",
    "    tab['woe'] = np.log(tab['bad_share'] / tab['good_share']).replace([np.inf, -np.inf], np.nan)\n",
    "    return df[bcol].map(tab['woe']).astype(float)\n",
    "\n",
    "train_enrichi = res[\"df_enrichi\"].copy()\n",
    "target = res[\"target\"]\n",
    "bin_cols = [c for c in train_enrichi.columns if c.endswith(\"__BIN\")]\n",
    "woe_train = pd.DataFrame({c.replace(\"__BIN\", \"_WOE\"): woe_from_bin(train_enrichi, target, c) for c in bin_cols})\n",
    "\n",
    "# Classement des WOE par gini_after\n",
    "order_woe = (res[\"summary\"]\n",
    "             .sort_values(\"gini_after\", ascending=False)[\"variable\"]\n",
    "             .apply(lambda v: f\"{v}_WOE\")\n",
    "             .tolist())\n",
    "order_woe = [v for v in order_woe if v in woe_train.columns]\n",
    "\n",
    "# Sélection anti-colinéarité\n",
    "if len(order_woe) == 0:\n",
    "    raise RuntimeError(\"Aucune variable WOE disponible pour la sélection.\")\n",
    "corr = woe_train[order_woe].corr().abs().fillna(0.0)\n",
    "\n",
    "threshold_corr = 0.85\n",
    "selected = []\n",
    "for v in order_woe:\n",
    "    if not selected:\n",
    "        selected.append(v); continue\n",
    "    mc = corr.loc[v, corr.columns.intersection(selected)]\n",
    "    max_corr = float(mc.max()) if len(mc) else 0.0\n",
    "    if not np.isfinite(max_corr) or np.isnan(max_corr):\n",
    "        max_corr = 0.0\n",
    "    if max_corr < threshold_corr:\n",
    "        selected.append(v)\n",
    "\n",
    "selected_woe_cols = selected\n",
    "selected_vars     = [c.removesuffix(\"_WOE\") for c in selected_woe_cols]\n",
    "print(f\"{len(selected_woe_cols)} variables retenues sur {len(order_woe)}\")\n",
    "\n",
    "def summarize_selection(order_woe, selected_woe_cols, corr, threshold=0.85, save_csv=False, csv_prefix=\"selection\"):\n",
    "    all_woe     = list(order_woe)\n",
    "    kept_woe    = list(selected_woe_cols)\n",
    "    dropped_woe = [v for v in all_woe if v not in set(kept_woe)]\n",
    "    kept_raw    = [v.removesuffix(\"_WOE\") for v in kept_woe]\n",
    "    dropped_raw = [v.removesuffix(\"_WOE\") for v in dropped_woe]\n",
    "\n",
    "    print(f\"\\nRésumé sélection : {len(kept_woe)} retenues / {len(all_woe)} évaluées (seuil corr = {threshold})\")\n",
    "    print(\"\\n— Variables retenues (WOE) —\")\n",
    "    for v in kept_woe: print(\"  •\", v)\n",
    "    print(\"\\n— Variables écartées (WOE) —\")\n",
    "    for v in dropped_woe: print(\"  •\", v)\n",
    "\n",
    "    df_vars = pd.DataFrame(list(zip_longest(kept_raw, dropped_raw, fillvalue=\"\")),\n",
    "                           columns=[\"kept_raw\", \"dropped_raw\"])\n",
    "\n",
    "    diag_rows = []\n",
    "    if len(kept_woe) and len(dropped_woe):\n",
    "        corr_f = corr.fillna(0.0)\n",
    "        for v in dropped_woe:\n",
    "            if (v in corr_f.index) and set(kept_woe).intersection(corr_f.columns):\n",
    "                ser_abs = corr_f.loc[v, list(kept_woe)].abs()\n",
    "                if len(ser_abs):\n",
    "                    top_kept = ser_abs.idxmax()\n",
    "                    top_val  = float(ser_abs.loc[top_kept])\n",
    "                else:\n",
    "                    top_kept, top_val = None, np.nan\n",
    "            else:\n",
    "                top_kept, top_val = None, np.nan\n",
    "            diag_rows.append({\n",
    "                \"dropped_raw\": v.removesuffix(\"_WOE\"),\n",
    "                \"kept_reason_raw\": (top_kept.removesuffix(\"_WOE\") if isinstance(top_kept, str) else None),\n",
    "                \"abs_corr_with_kept\": top_val\n",
    "            })\n",
    "    df_diag = pd.DataFrame(diag_rows).sort_values(\"abs_corr_with_kept\", ascending=False, na_position=\"last\")\n",
    "\n",
    "    if save_csv:\n",
    "        df_vars.to_csv(f\"{csv_prefix}_kept_vs_dropped.csv\", index=False)\n",
    "        df_diag.to_csv(f\"{csv_prefix}_dropped_diagnostics.csv\", index=False)\n",
    "        print(f\"\\nFichiers écrits :\\n - {csv_prefix}_kept_vs_dropped.csv\\n - {csv_prefix}_dropped_diagnostics.csv\")\n",
    "\n",
    "    display(df_vars.head(20))\n",
    "    display(df_diag.head(20))\n",
    "    return df_vars, df_diag\n",
    "\n",
    "df_vars, df_diag = summarize_selection(order_woe, selected_woe_cols, corr, threshold=threshold_corr)\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# WOE pipeline (maps, application train/val)\n",
    "# ----------------------------------------------------------\n",
    "def build_woe_maps(df_enrichi, target, smooth=0.5):\n",
    "    maps = {}\n",
    "    y = df_enrichi[target].astype(int)\n",
    "    B_all = float(y.sum()); G_all = float(len(y) - y.sum())\n",
    "    global_woe = np.log((B_all + smooth) / (G_all + smooth))\n",
    "    for bcol in [c for c in df_enrichi.columns if c.endswith(\"__BIN\")]:\n",
    "        tab = df_enrichi.groupby(bcol, dropna=True)[target].agg(['sum','count'])\n",
    "        tab['good'] = tab['count'] - tab['sum']\n",
    "        B = float(tab['sum'].sum()); G = float(tab['good'].sum()); K = int(len(tab)) if len(tab) > 0 else 1\n",
    "        denom_bad  = (B + smooth * K) if (B + smooth * K) > 0 else 1.0\n",
    "        denom_good = (G + smooth * K) if (G + smooth * K) > 0 else 1.0\n",
    "        w = np.log(((tab['sum']+smooth)/denom_bad) / ((tab['good']+smooth)/denom_good)).replace([np.inf, -np.inf], np.nan)\n",
    "        maps[bcol] = {\"map\": w.to_dict(), \"default\": global_woe}\n",
    "    return maps\n",
    "\n",
    "def make_enriched_with_bins(df_raw_onehot, res, include_missing=True, bin_col_suffix=\"__BIN\"):\n",
    "    DF = deonehot_categoricals(\n",
    "        df_raw_onehot,\n",
    "        allow_singleton=False,\n",
    "        exclude_cols=[res[\"target\"]] if res[\"target\"] in df_raw_onehot.columns else None\n",
    "    )\n",
    "    for col, r in res[\"cat_results\"].items():\n",
    "        if col not in DF.columns:\n",
    "            continue\n",
    "        s = DF[col].astype(\"object\").where(DF[col].notna(), \"__MISSING__\")\n",
    "        DF[col + bin_col_suffix] = s.map(r[\"mapping\"]).astype(\"Int64\").fillna(-2).astype(\"Int64\")\n",
    "    for col, r in res[\"num_results\"].items():\n",
    "        if col not in DF.columns:\n",
    "            continue\n",
    "        s = _to_float_series(DF[col])\n",
    "        e = np.array(r[\"edges_for_cut\"], dtype=\"float64\")\n",
    "        b = pd.cut(s, bins=e, include_lowest=True, duplicates=\"drop\").cat.codes.astype(\"Int64\")\n",
    "        if include_missing and s.isna().any():\n",
    "            b = b.where(~s.isna(), -1).astype(\"Int64\")\n",
    "        DF[col + bin_col_suffix] = b\n",
    "    return DF\n",
    "\n",
    "def apply_woe(df_enrichi_with_bins, woe_maps, kept_vars_raw, bin_col_suffix=\"__BIN\"):\n",
    "    cols = []\n",
    "    for v in kept_vars_raw:\n",
    "        bcol = f\"{v}{bin_col_suffix}\"\n",
    "        if bcol not in df_enrichi_with_bins.columns or bcol not in woe_maps:\n",
    "            continue\n",
    "        ser = df_enrichi_with_bins[bcol].astype(\"Int64\")\n",
    "        wmap = woe_maps[bcol][\"map\"]; wdef = float(woe_maps[bcol][\"default\"])\n",
    "        x = ser.map(wmap).astype(float).fillna(wdef)\n",
    "        cols.append((f\"{v}_WOE\", x))\n",
    "    if not cols:\n",
    "        return pd.DataFrame(index=df_enrichi_with_bins.index)\n",
    "    return pd.concat([s for _, s in cols], axis=1)\n",
    "\n",
    "# Variables retenues\n",
    "kept_woe = list(selected_woe_cols)\n",
    "kept_vars_raw = [c.removesuffix(\"_WOE\") for c in kept_woe]\n",
    "\n",
    "# TRAIN / VAL WOE\n",
    "woe_maps = build_woe_maps(res[\"df_enrichi\"], res[\"target\"])\n",
    "X_train_woe_full = apply_woe(res[\"df_enrichi\"], woe_maps, kept_vars_raw)\n",
    "y_train_full = res[\"df_enrichi\"][res[\"target\"]].astype(int)\n",
    "\n",
    "df_val_enrichi = make_enriched_with_bins(df_val_imp, res)\n",
    "X_val_woe_full = apply_woe(df_val_enrichi, woe_maps, kept_vars_raw)\n",
    "y_val = df_val_enrichi[res[\"target\"]].astype(int) if res[\"target\"] in df_val_enrichi.columns else None\n",
    "\n",
    "# Aligne colonnes\n",
    "X_val_woe_full = X_val_woe_full.reindex(columns=X_train_woe_full.columns, fill_value=0.0)\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# Entraînement : logistique + tuning AUC + calibration isotonic\n",
    "# ----------------------------------------------------------\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "grid = {\n",
    "    \"C\": [0.03, 0.1, 0.3, 1, 3, 10],\n",
    "    \"penalty\": [\"l2\"],\n",
    "    \"solver\": [\"lbfgs\"],\n",
    "    \"class_weight\": [None, \"balanced\"],\n",
    "    \"max_iter\": [2000],\n",
    "}\n",
    "gs = GridSearchCV(LogisticRegression(), grid, scoring=\"roc_auc\", cv=cv, n_jobs=-1, refit=True)\n",
    "\n",
    "def fit_calibrate(Xtr, ytr, Xva):\n",
    "    gs.fit(Xtr, ytr)\n",
    "    lr = gs.best_estimator_\n",
    "    cal = CalibratedClassifierCV(lr, method=\"isotonic\", cv=cv).fit(Xtr, ytr)\n",
    "    p_tr = cal.predict_proba(Xtr)[:,1]\n",
    "    p_va = cal.predict_proba(Xva)[:,1]\n",
    "    return cal, lr, p_tr, p_va\n",
    "\n",
    "def ks_best_threshold(y, p):\n",
    "    y = pd.Series(y).astype(int).to_numpy()\n",
    "    p = pd.Series(p).astype(float).to_numpy()\n",
    "    if np.unique(y).size < 2:\n",
    "        return np.nan, np.nan\n",
    "    fpr, tpr, thr = roc_curve(y, p)\n",
    "    ks_arr = tpr - fpr\n",
    "    i = int(np.nanargmax(ks_arr))\n",
    "    return float(ks_arr[i]), float(thr[i])\n",
    "\n",
    "def decile_table(y, p, q=10):\n",
    "    df = pd.DataFrame({\"y\": pd.Series(y).astype(int), \"p\": pd.Series(p).astype(float)})\n",
    "    try:\n",
    "        df[\"decile\"] = pd.qcut(df[\"p\"], q=q, labels=False, duplicates=\"drop\")\n",
    "    except Exception:\n",
    "        n = len(df)\n",
    "        if n == 0: return pd.DataFrame()\n",
    "        ranks = df[\"p\"].rank(method=\"first\") / max(n, 1)\n",
    "        df[\"decile\"] = pd.cut(ranks, bins=np.linspace(0, 1, q+1), labels=False, include_lowest=True)\n",
    "    tab = (df.groupby(\"decile\", dropna=True)\n",
    "             .agg(events=(\"y\", \"sum\"), count=(\"y\", \"size\"), avg_p=(\"p\", \"mean\"))\n",
    "             .sort_index(ascending=False))\n",
    "    if tab.empty: return tab\n",
    "    tab[\"rate\"] = tab[\"events\"] / tab[\"count\"].where(tab[\"count\"] > 0, 1)\n",
    "    tab[\"cum_events\"] = tab[\"events\"].cumsum()\n",
    "    tab[\"cum_count\"]  = tab[\"count\"].cumsum()\n",
    "    total_events = float(tab[\"events\"].sum())\n",
    "    total_count  = float(tab[\"count\"].sum())\n",
    "    tab[\"capture\"]   = tab[\"cum_events\"] / (total_events if total_events > 0 else 1.0)\n",
    "    tab[\"cum_share\"] = tab[\"cum_count\"]  / (total_count  if total_count  > 0 else 1.0)\n",
    "    cum_good = tab[\"count\"] - tab[\"events\"]\n",
    "    denom_good = float(cum_good.sum()) if float(cum_good.sum()) > 0 else 1.0\n",
    "    tab[\"TPR\"] = tab[\"cum_events\"] / (total_events if total_events > 0 else 1.0)\n",
    "    tab[\"FPR\"] = cum_good.cumsum() / denom_good\n",
    "    tab[\"KS\"]  = tab[\"TPR\"] - tab[\"FPR\"]\n",
    "    return tab\n",
    "\n",
    "def calibration_slope_intercept(y, p, eps=1e-9):\n",
    "    p = np.asarray(p, dtype=\"float64\")\n",
    "    y = np.asarray(y, dtype=int)\n",
    "    if np.unique(y).size < 2:\n",
    "        return np.nan, np.nan\n",
    "    p_clip = np.clip(p, eps, 1 - eps)\n",
    "    logit_p = np.log(p_clip / (1 - p_clip)).reshape(-1, 1)\n",
    "    try:\n",
    "        lr = LogisticRegression(penalty=\"none\", solver=\"lbfgs\", max_iter=2000)\n",
    "        lr.fit(logit_p, y)\n",
    "    except Exception:\n",
    "        lr = LogisticRegression(penalty=None, solver=\"lbfgs\", max_iter=2000)\n",
    "        lr.fit(logit_p, y)\n",
    "    a = float(lr.intercept_[0]); b = float(lr.coef_[0][0])\n",
    "    return a, b\n",
    "\n",
    "def psi(a, b, bins=10, eps=1e-9):\n",
    "    a = np.asarray(a, dtype=\"float64\"); b = np.asarray(b, dtype=\"float64\")\n",
    "    a_f = a[np.isfinite(a)]; b_f = b[np.isfinite(b)]\n",
    "    if a_f.size == 0 or b_f.size == 0: return np.nan\n",
    "    q = np.quantile(a_f, np.linspace(0, 1, bins + 1))\n",
    "    q = np.unique(q)\n",
    "    if q.size < 2: return 0.0\n",
    "    q[0], q[-1] = -np.inf, np.inf\n",
    "    for i in range(1, len(q)):\n",
    "        if not (q[i] > q[i-1]): q[i] = np.nextafter(q[i-1], np.inf)\n",
    "    ca, _ = np.histogram(a_f, bins=q); cb, _ = np.histogram(b_f, bins=q)\n",
    "    pa = ca / max(ca.sum(), 1); pb = cb / max(cb.sum(), 1)\n",
    "    return float(np.sum((pa - pb) * np.log((pa + eps) / (pb + eps))))\n",
    "\n",
    "def psi_classes(y_tr, y_va, eps=1e-9):\n",
    "    y_tr = np.asarray(y_tr, int); y_va = np.asarray(y_va, int)\n",
    "    pa1 = np.mean(y_tr == 1); pa0 = 1 - pa1\n",
    "    pb1 = np.mean(y_va == 1); pb0 = 1 - pb1\n",
    "    return float((pa0 - pb0) * np.log((pa0 + eps) / (pb0 + eps)) +\n",
    "                 (pa1 - pb1) * np.log((pa1 + eps) / (pb1 + eps)))\n",
    "\n",
    "# Fit initial (full WOE sélectionné)\n",
    "cal0, lr0, p_tr0, p_va0 = fit_calibrate(X_train_woe_full, y_train_full, X_val_woe_full)\n",
    "if y_val is not None:\n",
    "    auc0 = roc_auc_score(y_val, p_va0); gini0 = 2*auc0 - 1\n",
    "    brier0 = brier_score_loss(y_val, p_va0); ll0 = log_loss(y_val, p_va0)\n",
    "    ks0, thr0 = ks_best_threshold(y_val, p_va0)\n",
    "    psi0 = psi(p_tr0, p_va0, bins=10)\n",
    "    print(f\"AUC_val={auc0:.4f} | Gini_val={gini0:.4f} | Brier={brier0:.5f} | LogLoss={ll0:.5f}\")\n",
    "    print(f\"KS_val={ks0:.4f} | seuil_KS={thr0:.4f}\")\n",
    "    print(f\"\\nPSI (train→val, probas) = {psi0:.4f}  (≈ <0.10 faible, 0.10–0.25 modéré, >0.25 fort)\")\n",
    "    print(f\"PSI (distribution des classes TRAIN→VAL) = {psi_classes(y_train_full, y_val):.4f}\")\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# PSI par feature (sur WOE) + drop des proxies temporels instables\n",
    "# ----------------------------------------------------------\n",
    "def psi_by_feature(a, b, bins=10, eps=1e-9):\n",
    "    a = np.asarray(a, float); b = np.asarray(b, float)\n",
    "    a = a[np.isfinite(a)]; b = b[np.isfinite(b)]\n",
    "    if a.size==0 or b.size==0: return np.nan\n",
    "    q = np.quantile(a, np.linspace(0,1,bins+1))\n",
    "    q = np.unique(q); q[0], q[-1] = -np.inf, np.inf\n",
    "    for i in range(1,len(q)):\n",
    "        if not (q[i] > q[i-1]): q[i] = np.nextafter(q[i-1], np.inf)\n",
    "    ca,_ = np.histogram(a, bins=q); cb,_ = np.histogram(b, bins=q)\n",
    "    pa, pb = ca/ca.sum(), cb/cb.sum()\n",
    "    return float(np.sum((pa-pb)*np.log((pa+eps)/(pb+eps))))\n",
    "\n",
    "psi_feat = pd.Series({c: psi_by_feature(X_train_woe_full[c], X_val_woe_full[c]) for c in X_train_woe_full.columns}).sort_values(ascending=False)\n",
    "print(\"\\nTop 15 PSI(feature):\")\n",
    "print(psi_feat.head(15))\n",
    "\n",
    "# Drop automatique des proxys temporels si PSI(feature) > cutoff\n",
    "drop_conditional = []\n",
    "for raw in conditional_proxies:\n",
    "    c = f\"{raw}_WOE\"\n",
    "    if c in psi_feat.index and psi_feat.loc[c] > PSI_CUTOFF_PROXY:\n",
    "        drop_conditional.append(c)\n",
    "\n",
    "X_train_curr = X_train_woe_full.copy()\n",
    "X_val_curr   = X_val_woe_full.copy()\n",
    "if drop_conditional:\n",
    "    print(\"\\nDrop proxies instables (PSI>cutoff):\", drop_conditional)\n",
    "    X_train_curr = X_train_curr.drop(columns=drop_conditional, errors=\"ignore\")\n",
    "    X_val_curr   = X_val_curr.drop(columns=drop_conditional, errors=\"ignore\")\n",
    "\n",
    "# Refit après éventuel drop proxy\n",
    "cal_curr, lr_curr, p_tr_curr, p_va_curr = fit_calibrate(X_train_curr, y_train_full, X_val_curr)\n",
    "best_auc  = roc_auc_score(y_val, p_va_curr) if y_val is not None else np.nan\n",
    "best_psi  = psi(p_tr_curr, p_va_curr) if y_val is not None else np.nan\n",
    "keep_cols = list(X_train_curr.columns)\n",
    "print(f\"\\nStart ablation: AUC={best_auc:.4f} | PSI(probas)={best_psi:.4f}\")\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# Ablation gloutonne (peut être désactivée en mettant ABLATION_MAX_STEPS=0)\n",
    "# ----------------------------------------------------------\n",
    "for step in range(min(ABLATION_MAX_STEPS, len(keep_cols))):\n",
    "    # recompute PSI(feature) sur l'ensemble courant\n",
    "    psi_feat_now = pd.Series({c: psi_by_feature(X_train_curr[c], X_val_curr[c]) for c in keep_cols}).sort_values(ascending=False)\n",
    "    cand = psi_feat_now.index[0]  # feature avec PSI max\n",
    "    Xtr_try = X_train_curr.drop(columns=[cand])\n",
    "    Xva_try = X_val_curr.drop(columns=[cand], errors=\"ignore\")\n",
    "    cal2, lr2, p_tr2, p_va2 = fit_calibrate(Xtr_try, y_train_full, Xva_try)\n",
    "    auc2  = roc_auc_score(y_val, p_va2) if y_val is not None else np.nan\n",
    "    psi2  = psi(p_tr2, p_va2) if y_val is not None else np.nan\n",
    "    gain_psi = (best_psi - psi2) if (not np.isnan(best_psi) and not np.isnan(psi2)) else np.nan\n",
    "    loss_auc = (best_auc - auc2) if (not np.isnan(best_auc) and not np.isnan(auc2)) else np.nan\n",
    "    print(f\"Try drop {cand:35s} | AUC={auc2:.4f} (Δ{loss_auc:+.4f}) | PSI={psi2:.4f} (Δ{gain_psi:+.4f})\")\n",
    "\n",
    "    # garde la suppression si PSI baisse et perte AUC tolérée\n",
    "    if (not np.isnan(psi2)) and (psi2 + 1e-6) < best_psi and (np.isnan(loss_auc) or loss_auc <= ABLATION_MAX_AUC_LOSS):\n",
    "        X_train_curr, X_val_curr = Xtr_try, Xva_try\n",
    "        cal_curr, lr_curr, p_tr_curr, p_va_curr = cal2, lr2, p_tr2, p_va2\n",
    "        best_auc, best_psi = auc2, psi2\n",
    "        keep_cols.remove(cand)\n",
    "        print(\"  -> kept removal\")\n",
    "    else:\n",
    "        print(\"  -> revert\")\n",
    "        break\n",
    "\n",
    "# Scores finaux post-ablation\n",
    "if y_val is not None:\n",
    "    auc = roc_auc_score(y_val, p_va_curr); gini = 2*auc - 1\n",
    "    brier = brier_score_loss(y_val, p_va_curr); ll = log_loss(y_val, p_va_curr)\n",
    "    print(f\"\\nAfter ablation: AUC_val={auc:.4f} | Gini={gini:.4f} | Brier={brier:.5f} | LogLoss={ll:.5f} | PSI(probas)={best_psi:.4f}\")\n",
    "    print(\"Features finales :\", len(keep_cols))\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# Prior-shift adjust (correction d'intercept) + déciles APRÈS\n",
    "# ----------------------------------------------------------\n",
    "def prior_shift_adjust(p, base_train, base_val, eps=1e-9):\n",
    "    p = np.clip(np.asarray(p, float), eps, 1-eps)\n",
    "    logit = np.log(p/(1-p))\n",
    "    delta = np.log((base_val+eps)/(1-base_val+eps)) - np.log((base_train+eps)/(1-base_train+eps))\n",
    "    z = logit + delta\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "if y_val is not None:\n",
    "    base_train = float(np.mean(y_train_full)); base_val = float(np.mean(y_val))\n",
    "    p_val_adj = prior_shift_adjust(p_va_curr, base_train, base_val)\n",
    "\n",
    "    auc_adj = roc_auc_score(y_val, p_val_adj); gini_adj = 2*auc_adj - 1\n",
    "    brier_adj = brier_score_loss(y_val, p_val_adj); ll_adj = log_loss(y_val, p_val_adj)\n",
    "    ks_adj, thr_adj = ks_best_threshold(y_val, p_val_adj)\n",
    "    psi_adj = psi(p_tr_curr, p_val_adj, bins=10)\n",
    "\n",
    "    print(f\"\\nAfter prior-shift adjust:\")\n",
    "    print(f\"AUC_val={auc_adj:.4f} | Gini_val={gini_adj:.4f} | Brier={brier_adj:.5f} | LogLoss={ll_adj:.5f}\")\n",
    "    print(f\"KS_val={ks_adj:.4f} | seuil_KS={thr_adj:.4f}\")\n",
    "    print(f\"PSI (train→val, probas) après ajustement = {psi_adj:.4f}\")\n",
    "\n",
    "    dec_val_after = decile_table(y_val, p_val_adj, q=10)\n",
    "    if not dec_val_after.empty:\n",
    "        print(\"\\nDéciles — APRÈS prior-shift :\")\n",
    "        print(dec_val_after[[\"count\",\"events\",\"rate\",\"avg_p\",\"capture\",\"KS\"]])\n",
    "        print(f\"KS_val (déciles, après) = {float(dec_val_after['KS'].max()):.4f}\")\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# Importance des variables (coeffs standardisés) — ROBUSTE\n",
    "# ----------------------------------------------------------\n",
    "def compute_standardized_importance(estimator, X_ref, fallback_X=None, topn=15):\n",
    "    \"\"\"\n",
    "    estimator : LogisticRegression déjà fit (le dernier utilisé)\n",
    "    X_ref     : DataFrame aligné avec le fit final (idéalement la matrice passée au dernier .fit())\n",
    "    fallback_X: DataFrame de secours si besoin (ex: X_train_woe_full)\n",
    "    \"\"\"\n",
    "    if not hasattr(estimator, \"coef_\"):\n",
    "        print(\"Importance non calculée : l'estimateur n'a pas d'attribut coef_.\")\n",
    "        return\n",
    "\n",
    "    beta = np.asarray(estimator.coef_).ravel()\n",
    "\n",
    "    # 1) Colonnes réellement utilisées pour le dernier fit\n",
    "    if X_ref is not None and isinstance(X_ref, pd.DataFrame):\n",
    "        feat_cols_used = list(X_ref.columns)\n",
    "    elif hasattr(estimator, \"feature_names_in_\"):\n",
    "        feat_cols_used = list(estimator.feature_names_in_)\n",
    "    elif fallback_X is not None:\n",
    "        feat_cols_used = list(fallback_X.columns[:len(beta)])\n",
    "    else:\n",
    "        print(\"Impossible de déterminer les noms de variables utilisés.\")\n",
    "        return\n",
    "\n",
    "    # 2) Alignement par troncature prudente si tailles décalées\n",
    "    if len(beta) != len(feat_cols_used):\n",
    "        logger.warning(\"Taille coef_ (%d) ≠ nb colonnes (%d). Alignement par troncature.\",\n",
    "                       len(beta), len(feat_cols_used))\n",
    "        m = min(len(beta), len(feat_cols_used))\n",
    "        beta = beta[:m]\n",
    "        feat_cols_used = feat_cols_used[:m]\n",
    "\n",
    "    # 3) Construire le X pour std, en réindexant sur les features attendues\n",
    "    if X_ref is None and fallback_X is not None:\n",
    "        X_for_std = fallback_X.reindex(columns=feat_cols_used)\n",
    "    else:\n",
    "        X_for_std = X_ref.reindex(columns=feat_cols_used)\n",
    "\n",
    "    missing = [c for c in feat_cols_used if c not in (X_for_std.columns)]\n",
    "    if missing:\n",
    "        logger.warning(\"Features absentes pour std (ignorées): %s\", missing)\n",
    "\n",
    "    coefs = pd.Series(beta, index=feat_cols_used)\n",
    "    stds  = X_for_std.std(ddof=0).replace(0, np.nan)\n",
    "    std_coef = coefs * stds\n",
    "\n",
    "    imp = (pd.DataFrame({\"coef\": coefs, \"std\": stds, \"std_coef\": std_coef})\n",
    "           .dropna(subset=[\"std_coef\"])\n",
    "           .sort_values(\"std_coef\", key=lambda s: s.abs(), ascending=False))\n",
    "\n",
    "    print(\"\\nTop variables (|coef|*sd) :\")\n",
    "    print(imp.head(topn))\n",
    "    return imp\n",
    "\n",
    "# Importance sur le modèle final\n",
    "lr_final   = lr_curr\n",
    "X_train_fit= X_train_curr\n",
    "_ = compute_standardized_importance(\n",
    "    estimator=lr_final,\n",
    "    X_ref=X_train_fit,\n",
    "    fallback_X=X_train_woe_full,\n",
    "    topn=15\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7114452a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "set",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "n",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "defaults",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "default_rate",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "AUC",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Gini",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Brier",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "LogLoss",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "KS",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "KS_threshold",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Calib_intercept",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Calib_slope",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "e51b0a5f-0b43-4d40-9ec5-30763ed015a9",
       "rows": [
        [
         "0",
         "TRAIN (final)",
         "9590892",
         "116762",
         "0.012174258661238183",
         "0.7587505649492394",
         "0.5175011298984789",
         "0.01185560729508443",
         "0.06028150879245165",
         "0.39218024860589684",
         "0.011885334187931829",
         "-0.005970897293535112",
         "0.9985209408591237"
        ]
       ],
       "shape": {
        "columns": 12,
        "rows": 1
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>set</th>\n",
       "      <th>n</th>\n",
       "      <th>defaults</th>\n",
       "      <th>default_rate</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Gini</th>\n",
       "      <th>Brier</th>\n",
       "      <th>LogLoss</th>\n",
       "      <th>KS</th>\n",
       "      <th>KS_threshold</th>\n",
       "      <th>Calib_intercept</th>\n",
       "      <th>Calib_slope</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TRAIN (final)</td>\n",
       "      <td>9590892</td>\n",
       "      <td>116762</td>\n",
       "      <td>0.012174</td>\n",
       "      <td>0.758751</td>\n",
       "      <td>0.517501</td>\n",
       "      <td>0.011856</td>\n",
       "      <td>0.060282</td>\n",
       "      <td>0.39218</td>\n",
       "      <td>0.011885</td>\n",
       "      <td>-0.005971</td>\n",
       "      <td>0.998521</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             set        n  defaults  default_rate       AUC      Gini  \\\n",
       "0  TRAIN (final)  9590892    116762      0.012174  0.758751  0.517501   \n",
       "\n",
       "      Brier   LogLoss       KS  KS_threshold  Calib_intercept  Calib_slope  \n",
       "0  0.011856  0.060282  0.39218      0.011885        -0.005971     0.998521  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "class",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "set",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "count",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "share",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "defaults",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "default_rate",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "avg_p",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "lift",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "capture",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "cum_share",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "KS",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "4928316e-e82d-4512-893a-9783be29b423",
       "rows": [
        [
         "1",
         "TRAIN (final)",
         "948905",
         "0.09893813839213286",
         "41871",
         "0.044125597399107395",
         "0.04422921326913406",
         "3.624499743840633",
         "0.3586012572583546",
         "0.09893813839213286",
         "0.2628632844840735"
        ],
        [
         "2",
         "TRAIN (final)",
         "962315",
         "0.10033633993584747",
         "23050",
         "0.023952655835147534",
         "0.02388974705384814",
         "1.967483729535892",
         "0.5560113735633169",
         "0.19927447832798034",
         "0.36113342698669193"
        ],
        [
         "3",
         "TRAIN (final)",
         "963795",
         "0.10049065300704042",
         "15235",
         "0.015807303420333162",
         "0.015782437929899546",
         "1.2984202044813036",
         "0.686490467789178",
         "0.29976513133502075",
         "0.3914914546871834"
        ],
        [
         "4",
         "TRAIN (final)",
         "942837",
         "0.09830545480024173",
         "10349",
         "0.010976446618026233",
         "0.011001327079014366",
         "0.9016110897145891",
         "0.7751237560165122",
         "0.39807058613526247",
         "0.38170008545256595"
        ],
        [
         "5",
         "TRAIN (final)",
         "960719",
         "0.10016993205637181",
         "8111",
         "0.008442635151381413",
         "0.008426709036074093",
         "0.6934824851604356",
         "0.844589849437317",
         "0.49824051819163434",
         "0.3506178435644822"
        ],
        [
         "6",
         "TRAIN (final)",
         "971988",
         "0.10134490097479984",
         "6059",
         "0.006233616052873081",
         "0.00625180950090182",
         "0.5120324962965007",
         "0.8964817320703654",
         "0.5995854191664342",
         "0.3005553514950514"
        ],
        [
         "7",
         "TRAIN (final)",
         "883250",
         "0.09209258116971811",
         "4056",
         "0.004592131333144636",
         "0.004597913531470286",
         "0.37720007935806366",
         "0.9312190609958719",
         "0.6916780003361522",
         "0.24249323603885742"
        ],
        [
         "8",
         "TRAIN (final)",
         "1036780",
         "0.10810047699421493",
         "3890",
         "0.0037520013889156814",
         "0.003728429840321058",
         "0.30819136452733165",
         "0.9645346945067744",
         "0.7997784773303672",
         "0.1667867218697091"
        ],
        [
         "9",
         "TRAIN (final)",
         "944659",
         "0.0984954267027509",
         "2594",
         "0.0027459644167895504",
         "0.002755510598719365",
         "0.22555495929558902",
         "0.9867508264675151",
         "0.8982739040331181",
         "0.08956733837942676"
        ],
        [
         "10",
         "TRAIN (final)",
         "975644",
         "0.10172609596688191",
         "1547",
         "0.001585619344760999",
         "0.0015558299311226997",
         "0.130243605699744",
         "1.0",
         "1.0",
         "0.0"
        ]
       ],
       "shape": {
        "columns": 10,
        "rows": 10
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>set</th>\n",
       "      <th>count</th>\n",
       "      <th>share</th>\n",
       "      <th>defaults</th>\n",
       "      <th>default_rate</th>\n",
       "      <th>avg_p</th>\n",
       "      <th>lift</th>\n",
       "      <th>capture</th>\n",
       "      <th>cum_share</th>\n",
       "      <th>KS</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TRAIN (final)</td>\n",
       "      <td>948905</td>\n",
       "      <td>0.098938</td>\n",
       "      <td>41871</td>\n",
       "      <td>0.044126</td>\n",
       "      <td>0.044229</td>\n",
       "      <td>3.624500</td>\n",
       "      <td>0.358601</td>\n",
       "      <td>0.098938</td>\n",
       "      <td>0.262863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TRAIN (final)</td>\n",
       "      <td>962315</td>\n",
       "      <td>0.100336</td>\n",
       "      <td>23050</td>\n",
       "      <td>0.023953</td>\n",
       "      <td>0.023890</td>\n",
       "      <td>1.967484</td>\n",
       "      <td>0.556011</td>\n",
       "      <td>0.199274</td>\n",
       "      <td>0.361133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TRAIN (final)</td>\n",
       "      <td>963795</td>\n",
       "      <td>0.100491</td>\n",
       "      <td>15235</td>\n",
       "      <td>0.015807</td>\n",
       "      <td>0.015782</td>\n",
       "      <td>1.298420</td>\n",
       "      <td>0.686490</td>\n",
       "      <td>0.299765</td>\n",
       "      <td>0.391491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TRAIN (final)</td>\n",
       "      <td>942837</td>\n",
       "      <td>0.098305</td>\n",
       "      <td>10349</td>\n",
       "      <td>0.010976</td>\n",
       "      <td>0.011001</td>\n",
       "      <td>0.901611</td>\n",
       "      <td>0.775124</td>\n",
       "      <td>0.398071</td>\n",
       "      <td>0.381700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TRAIN (final)</td>\n",
       "      <td>960719</td>\n",
       "      <td>0.100170</td>\n",
       "      <td>8111</td>\n",
       "      <td>0.008443</td>\n",
       "      <td>0.008427</td>\n",
       "      <td>0.693482</td>\n",
       "      <td>0.844590</td>\n",
       "      <td>0.498241</td>\n",
       "      <td>0.350618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>TRAIN (final)</td>\n",
       "      <td>971988</td>\n",
       "      <td>0.101345</td>\n",
       "      <td>6059</td>\n",
       "      <td>0.006234</td>\n",
       "      <td>0.006252</td>\n",
       "      <td>0.512032</td>\n",
       "      <td>0.896482</td>\n",
       "      <td>0.599585</td>\n",
       "      <td>0.300555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>TRAIN (final)</td>\n",
       "      <td>883250</td>\n",
       "      <td>0.092093</td>\n",
       "      <td>4056</td>\n",
       "      <td>0.004592</td>\n",
       "      <td>0.004598</td>\n",
       "      <td>0.377200</td>\n",
       "      <td>0.931219</td>\n",
       "      <td>0.691678</td>\n",
       "      <td>0.242493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>TRAIN (final)</td>\n",
       "      <td>1036780</td>\n",
       "      <td>0.108100</td>\n",
       "      <td>3890</td>\n",
       "      <td>0.003752</td>\n",
       "      <td>0.003728</td>\n",
       "      <td>0.308191</td>\n",
       "      <td>0.964535</td>\n",
       "      <td>0.799778</td>\n",
       "      <td>0.166787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>TRAIN (final)</td>\n",
       "      <td>944659</td>\n",
       "      <td>0.098495</td>\n",
       "      <td>2594</td>\n",
       "      <td>0.002746</td>\n",
       "      <td>0.002756</td>\n",
       "      <td>0.225555</td>\n",
       "      <td>0.986751</td>\n",
       "      <td>0.898274</td>\n",
       "      <td>0.089567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>TRAIN (final)</td>\n",
       "      <td>975644</td>\n",
       "      <td>0.101726</td>\n",
       "      <td>1547</td>\n",
       "      <td>0.001586</td>\n",
       "      <td>0.001556</td>\n",
       "      <td>0.130244</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 set    count     share  defaults  default_rate     avg_p  \\\n",
       "class                                                                       \n",
       "1      TRAIN (final)   948905  0.098938     41871      0.044126  0.044229   \n",
       "2      TRAIN (final)   962315  0.100336     23050      0.023953  0.023890   \n",
       "3      TRAIN (final)   963795  0.100491     15235      0.015807  0.015782   \n",
       "4      TRAIN (final)   942837  0.098305     10349      0.010976  0.011001   \n",
       "5      TRAIN (final)   960719  0.100170      8111      0.008443  0.008427   \n",
       "6      TRAIN (final)   971988  0.101345      6059      0.006234  0.006252   \n",
       "7      TRAIN (final)   883250  0.092093      4056      0.004592  0.004598   \n",
       "8      TRAIN (final)  1036780  0.108100      3890      0.003752  0.003728   \n",
       "9      TRAIN (final)   944659  0.098495      2594      0.002746  0.002756   \n",
       "10     TRAIN (final)   975644  0.101726      1547      0.001586  0.001556   \n",
       "\n",
       "           lift   capture  cum_share        KS  \n",
       "class                                           \n",
       "1      3.624500  0.358601   0.098938  0.262863  \n",
       "2      1.967484  0.556011   0.199274  0.361133  \n",
       "3      1.298420  0.686490   0.299765  0.391491  \n",
       "4      0.901611  0.775124   0.398071  0.381700  \n",
       "5      0.693482  0.844590   0.498241  0.350618  \n",
       "6      0.512032  0.896482   0.599585  0.300555  \n",
       "7      0.377200  0.931219   0.691678  0.242493  \n",
       "8      0.308191  0.964535   0.799778  0.166787  \n",
       "9      0.225555  0.986751   0.898274  0.089567  \n",
       "10     0.130244  1.000000   1.000000  0.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monotonicité des taux de défaut (haut → bas risque) : OK ✅\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "set",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "n",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "defaults",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "default_rate",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "AUC",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Gini",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Brier",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "LogLoss",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "KS",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "KS_threshold",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Calib_intercept",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Calib_slope",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "01968a15-6222-48e5-8553-4f2ef18ec679",
       "rows": [
        [
         "0",
         "VAL (final, prior-shift)",
         "931745",
         "12670",
         "0.013598141122302777",
         "0.7944300764291059",
         "0.5888601528582118",
         "0.013155658243009138",
         "0.06451898321968817",
         "0.45115889420836613",
         "0.018257847551095694",
         "0.458238301822803",
         "1.1953742656326427"
        ]
       ],
       "shape": {
        "columns": 12,
        "rows": 1
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>set</th>\n",
       "      <th>n</th>\n",
       "      <th>defaults</th>\n",
       "      <th>default_rate</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Gini</th>\n",
       "      <th>Brier</th>\n",
       "      <th>LogLoss</th>\n",
       "      <th>KS</th>\n",
       "      <th>KS_threshold</th>\n",
       "      <th>Calib_intercept</th>\n",
       "      <th>Calib_slope</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>VAL (final, prior-shift)</td>\n",
       "      <td>931745</td>\n",
       "      <td>12670</td>\n",
       "      <td>0.013598</td>\n",
       "      <td>0.79443</td>\n",
       "      <td>0.58886</td>\n",
       "      <td>0.013156</td>\n",
       "      <td>0.064519</td>\n",
       "      <td>0.451159</td>\n",
       "      <td>0.018258</td>\n",
       "      <td>0.458238</td>\n",
       "      <td>1.195374</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        set       n  defaults  default_rate      AUC     Gini  \\\n",
       "0  VAL (final, prior-shift)  931745     12670      0.013598  0.79443  0.58886   \n",
       "\n",
       "      Brier   LogLoss        KS  KS_threshold  Calib_intercept  Calib_slope  \n",
       "0  0.013156  0.064519  0.451159      0.018258         0.458238     1.195374  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "class",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "set",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "count",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "share",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "defaults",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "default_rate",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "avg_p",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "lift",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "capture",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "cum_share",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "KS",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "2130d83f-0a90-445d-a71a-8375321d6c70",
       "rows": [
        [
         "1",
         "VAL (final, prior-shift)",
         "167407",
         "0.17967040338289983",
         "7262",
         "0.0433793091089381",
         "0.048533574420994575",
         "3.1900911101584475",
         "0.5731649565903709",
         "0.17967040338289983",
         "0.3989191115831626"
        ],
        [
         "2",
         "VAL (final, prior-shift)",
         "110303",
         "0.11838324863562455",
         "2150",
         "0.019491763596638352",
         "0.024240593065193244",
         "1.4334138336503395",
         "0.7428571428571429",
         "0.2980536520185244",
         "0.4509353736870534"
        ],
        [
         "3",
         "VAL (final, prior-shift)",
         "109791",
         "0.11783374206462069",
         "1284",
         "0.011694947673306555",
         "0.01600777110971127",
         "0.8600401752063943",
         "0.8441988950276244",
         "0.41588739408314507",
         "0.43421603182277163"
        ],
        [
         "4",
         "VAL (final, prior-shift)",
         "121965",
         "0.13089954869626347",
         "921",
         "0.007551346697823146",
         "0.01085063126345516",
         "0.5553219833435854",
         "0.9168902920284135",
         "0.5467869427794085",
         "0.3752054458515509"
        ],
        [
         "5",
         "VAL (final, prior-shift)",
         "62511",
         "0.06709024464848215",
         "323",
         "0.0051670905920557985",
         "0.008417404032354489",
         "0.3799850689577766",
         "0.9423835832675612",
         "0.6138771874278907",
         "0.3330350534957798"
        ],
        [
         "6",
         "VAL (final, prior-shift)",
         "93616",
         "0.10047384209198869",
         "318",
         "0.003396855238420783",
         "0.006324090654523836",
         "0.24980291113830877",
         "0.9674822415153906",
         "0.7143510295198794",
         "0.25662077754346235"
        ],
        [
         "7",
         "VAL (final, prior-shift)",
         "82816",
         "0.08888268785987583",
         "188",
         "0.0022700927357032458",
         "0.004786966190947632",
         "0.16694140142287456",
         "0.9823204419889503",
         "0.8032337173797552",
         "0.18155554249761385"
        ],
        [
         "8",
         "VAL (final, prior-shift)",
         "80674",
         "0.0865837756038401",
         "142",
         "0.0017601705630066688",
         "0.0037749919506011756",
         "0.12944199851844107",
         "0.9935280189423836",
         "0.8898174929835952",
         "0.10514023774933623"
        ],
        [
         "9",
         "VAL (final, prior-shift)",
         "51788",
         "0.055581731053024164",
         "56",
         "0.001081331582606009",
         "0.002630038350215675",
         "0.07952054423324671",
         "0.997947908445146",
         "0.9453992240366195",
         "0.0532730995340126"
        ],
        [
         "10",
         "VAL (final, prior-shift)",
         "50874",
         "0.05460077596338054",
         "26",
         "0.0005110665565907929",
         "0.001651509965592829",
         "0.03758356028182228",
         "1.0",
         "1.0",
         "0.0"
        ]
       ],
       "shape": {
        "columns": 10,
        "rows": 10
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>set</th>\n",
       "      <th>count</th>\n",
       "      <th>share</th>\n",
       "      <th>defaults</th>\n",
       "      <th>default_rate</th>\n",
       "      <th>avg_p</th>\n",
       "      <th>lift</th>\n",
       "      <th>capture</th>\n",
       "      <th>cum_share</th>\n",
       "      <th>KS</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>VAL (final, prior-shift)</td>\n",
       "      <td>167407</td>\n",
       "      <td>0.179670</td>\n",
       "      <td>7262</td>\n",
       "      <td>0.043379</td>\n",
       "      <td>0.048534</td>\n",
       "      <td>3.190091</td>\n",
       "      <td>0.573165</td>\n",
       "      <td>0.179670</td>\n",
       "      <td>0.398919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>VAL (final, prior-shift)</td>\n",
       "      <td>110303</td>\n",
       "      <td>0.118383</td>\n",
       "      <td>2150</td>\n",
       "      <td>0.019492</td>\n",
       "      <td>0.024241</td>\n",
       "      <td>1.433414</td>\n",
       "      <td>0.742857</td>\n",
       "      <td>0.298054</td>\n",
       "      <td>0.450935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>VAL (final, prior-shift)</td>\n",
       "      <td>109791</td>\n",
       "      <td>0.117834</td>\n",
       "      <td>1284</td>\n",
       "      <td>0.011695</td>\n",
       "      <td>0.016008</td>\n",
       "      <td>0.860040</td>\n",
       "      <td>0.844199</td>\n",
       "      <td>0.415887</td>\n",
       "      <td>0.434216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>VAL (final, prior-shift)</td>\n",
       "      <td>121965</td>\n",
       "      <td>0.130900</td>\n",
       "      <td>921</td>\n",
       "      <td>0.007551</td>\n",
       "      <td>0.010851</td>\n",
       "      <td>0.555322</td>\n",
       "      <td>0.916890</td>\n",
       "      <td>0.546787</td>\n",
       "      <td>0.375205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>VAL (final, prior-shift)</td>\n",
       "      <td>62511</td>\n",
       "      <td>0.067090</td>\n",
       "      <td>323</td>\n",
       "      <td>0.005167</td>\n",
       "      <td>0.008417</td>\n",
       "      <td>0.379985</td>\n",
       "      <td>0.942384</td>\n",
       "      <td>0.613877</td>\n",
       "      <td>0.333035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>VAL (final, prior-shift)</td>\n",
       "      <td>93616</td>\n",
       "      <td>0.100474</td>\n",
       "      <td>318</td>\n",
       "      <td>0.003397</td>\n",
       "      <td>0.006324</td>\n",
       "      <td>0.249803</td>\n",
       "      <td>0.967482</td>\n",
       "      <td>0.714351</td>\n",
       "      <td>0.256621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>VAL (final, prior-shift)</td>\n",
       "      <td>82816</td>\n",
       "      <td>0.088883</td>\n",
       "      <td>188</td>\n",
       "      <td>0.002270</td>\n",
       "      <td>0.004787</td>\n",
       "      <td>0.166941</td>\n",
       "      <td>0.982320</td>\n",
       "      <td>0.803234</td>\n",
       "      <td>0.181556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>VAL (final, prior-shift)</td>\n",
       "      <td>80674</td>\n",
       "      <td>0.086584</td>\n",
       "      <td>142</td>\n",
       "      <td>0.001760</td>\n",
       "      <td>0.003775</td>\n",
       "      <td>0.129442</td>\n",
       "      <td>0.993528</td>\n",
       "      <td>0.889817</td>\n",
       "      <td>0.105140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>VAL (final, prior-shift)</td>\n",
       "      <td>51788</td>\n",
       "      <td>0.055582</td>\n",
       "      <td>56</td>\n",
       "      <td>0.001081</td>\n",
       "      <td>0.002630</td>\n",
       "      <td>0.079521</td>\n",
       "      <td>0.997948</td>\n",
       "      <td>0.945399</td>\n",
       "      <td>0.053273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>VAL (final, prior-shift)</td>\n",
       "      <td>50874</td>\n",
       "      <td>0.054601</td>\n",
       "      <td>26</td>\n",
       "      <td>0.000511</td>\n",
       "      <td>0.001652</td>\n",
       "      <td>0.037584</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            set   count     share  defaults  default_rate  \\\n",
       "class                                                                       \n",
       "1      VAL (final, prior-shift)  167407  0.179670      7262      0.043379   \n",
       "2      VAL (final, prior-shift)  110303  0.118383      2150      0.019492   \n",
       "3      VAL (final, prior-shift)  109791  0.117834      1284      0.011695   \n",
       "4      VAL (final, prior-shift)  121965  0.130900       921      0.007551   \n",
       "5      VAL (final, prior-shift)   62511  0.067090       323      0.005167   \n",
       "6      VAL (final, prior-shift)   93616  0.100474       318      0.003397   \n",
       "7      VAL (final, prior-shift)   82816  0.088883       188      0.002270   \n",
       "8      VAL (final, prior-shift)   80674  0.086584       142      0.001760   \n",
       "9      VAL (final, prior-shift)   51788  0.055582        56      0.001081   \n",
       "10     VAL (final, prior-shift)   50874  0.054601        26      0.000511   \n",
       "\n",
       "          avg_p      lift   capture  cum_share        KS  \n",
       "class                                                     \n",
       "1      0.048534  3.190091  0.573165   0.179670  0.398919  \n",
       "2      0.024241  1.433414  0.742857   0.298054  0.450935  \n",
       "3      0.016008  0.860040  0.844199   0.415887  0.434216  \n",
       "4      0.010851  0.555322  0.916890   0.546787  0.375205  \n",
       "5      0.008417  0.379985  0.942384   0.613877  0.333035  \n",
       "6      0.006324  0.249803  0.967482   0.714351  0.256621  \n",
       "7      0.004787  0.166941  0.982320   0.803234  0.181556  \n",
       "8      0.003775  0.129442  0.993528   0.889817  0.105140  \n",
       "9      0.002630  0.079521  0.997948   0.945399  0.053273  \n",
       "10     0.001652  0.037584  1.000000   1.000000  0.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monotonicité des taux de défaut (haut → bas risque) : OK ✅\n",
      "PSI (distribution des classes TRAIN→VAL) = 0.1353  (≈ <0.10 faible, 0.10–0.25 modéré, >0.25 fort)\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "class",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "count_train",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "share_train",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "defaults_train",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "default_rate_train",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "avg_p_train",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "lift_train",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "capture_train",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "cum_share_train",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "KS_train",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "count_val",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "share_val",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "defaults_val",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "default_rate_val",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "avg_p_val",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "lift_val",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "capture_val",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "cum_share_val",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "KS_val",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "default_rate_diff",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "share_diff",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "psi_component",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "3b73da4c-0d1c-48f6-bcb4-a167c5df7702",
       "rows": [
        [
         "1",
         "948905",
         "0.09893813839213286",
         "41871",
         "0.044125597399107395",
         "0.04422921326913406",
         "3.624499743840633",
         "0.3586012572583546",
         "0.09893813839213286",
         "0.2628632844840735",
         "167407",
         "0.17967040338289983",
         "7262",
         "0.0433793091089381",
         "0.048533574420994575",
         "3.1900911101584475",
         "0.5731649565903709",
         "0.17967040338289983",
         "0.3989191115831626",
         "0.000746288290169296",
         "-0.08073226499076697",
         "0.048167233572847995"
        ],
        [
         "2",
         "962315",
         "0.10033633993584747",
         "23050",
         "0.023952655835147534",
         "0.02388974705384814",
         "1.967483729535892",
         "0.5560113735633169",
         "0.19927447832798034",
         "0.36113342698669193",
         "110303",
         "0.11838324863562455",
         "2150",
         "0.019491763596638352",
         "0.024240593065193244",
         "1.4334138336503395",
         "0.7428571428571429",
         "0.2980536520185244",
         "0.4509353736870534",
         "0.004460892238509182",
         "-0.018046908699777084",
         "0.002984945850145627"
        ],
        [
         "3",
         "963795",
         "0.10049065300704042",
         "15235",
         "0.015807303420333162",
         "0.015782437929899546",
         "1.2984202044813036",
         "0.686490467789178",
         "0.29976513133502075",
         "0.3914914546871834",
         "109791",
         "0.11783374206462069",
         "1284",
         "0.011694947673306555",
         "0.01600777110971127",
         "0.8600401752063943",
         "0.8441988950276244",
         "0.41588739408314507",
         "0.43421603182277163",
         "0.004112355747026607",
         "-0.017343089057580266",
         "0.0027611922663094046"
        ],
        [
         "4",
         "942837",
         "0.09830545480024173",
         "10349",
         "0.010976446618026233",
         "0.011001327079014366",
         "0.9016110897145891",
         "0.7751237560165122",
         "0.39807058613526247",
         "0.38170008545256595",
         "121965",
         "0.13089954869626347",
         "921",
         "0.007551346697823146",
         "0.01085063126345516",
         "0.5553219833435854",
         "0.9168902920284135",
         "0.5467869427794085",
         "0.3752054458515509",
         "0.0034250999202030874",
         "-0.032594093896021734",
         "0.009333341789086439"
        ],
        [
         "5",
         "960719",
         "0.10016993205637181",
         "8111",
         "0.008442635151381413",
         "0.008426709036074093",
         "0.6934824851604356",
         "0.844589849437317",
         "0.49824051819163434",
         "0.3506178435644822",
         "62511",
         "0.06709024464848215",
         "323",
         "0.0051670905920557985",
         "0.008417404032354489",
         "0.3799850689577766",
         "0.9423835832675612",
         "0.6138771874278907",
         "0.3330350534957798",
         "0.0032755445593256145",
         "0.03307968740788966",
         "0.013259311628975609"
        ],
        [
         "6",
         "971988",
         "0.10134490097479984",
         "6059",
         "0.006233616052873081",
         "0.00625180950090182",
         "0.5120324962965007",
         "0.8964817320703654",
         "0.5995854191664342",
         "0.3005553514950514",
         "93616",
         "0.10047384209198869",
         "318",
         "0.003396855238420783",
         "0.006324090654523836",
         "0.24980291113830877",
         "0.9674822415153906",
         "0.7143510295198794",
         "0.25662077754346235",
         "0.002836760814452298",
         "0.0008710588828111515",
         "7.519106200768801e-06"
        ],
        [
         "7",
         "883250",
         "0.09209258116971811",
         "4056",
         "0.004592131333144636",
         "0.004597913531470286",
         "0.37720007935806366",
         "0.9312190609958719",
         "0.6916780003361522",
         "0.24249323603885742",
         "82816",
         "0.08888268785987583",
         "188",
         "0.0022700927357032458",
         "0.004786966190947632",
         "0.16694140142287456",
         "0.9823204419889503",
         "0.8032337173797552",
         "0.18155554249761385",
         "0.0023220385974413904",
         "0.003209893309842282",
         "0.00011387738944586455"
        ],
        [
         "8",
         "1036780",
         "0.10810047699421493",
         "3890",
         "0.0037520013889156814",
         "0.003728429840321058",
         "0.30819136452733165",
         "0.9645346945067744",
         "0.7997784773303672",
         "0.1667867218697091",
         "80674",
         "0.0865837756038401",
         "142",
         "0.0017601705630066688",
         "0.0037749919506011756",
         "0.12944199851844107",
         "0.9935280189423836",
         "0.8898174929835952",
         "0.10514023774933623",
         "0.0019918308259090126",
         "0.02151670139037483",
         "0.004775603590600133"
        ],
        [
         "9",
         "944659",
         "0.0984954267027509",
         "2594",
         "0.0027459644167895504",
         "0.002755510598719365",
         "0.22555495929558902",
         "0.9867508264675151",
         "0.8982739040331181",
         "0.08956733837942676",
         "51788",
         "0.055581731053024164",
         "56",
         "0.001081331582606009",
         "0.002630038350215675",
         "0.07952054423324671",
         "0.997947908445146",
         "0.9453992240366195",
         "0.0532730995340126",
         "0.0016646328341835413",
         "0.04291369564972673",
         "0.024553308740815113"
        ],
        [
         "10",
         "975644",
         "0.10172609596688191",
         "1547",
         "0.001585619344760999",
         "0.0015558299311226997",
         "0.130243605699744",
         "1.0",
         "1.0",
         "0.0",
         "50874",
         "0.05460077596338054",
         "26",
         "0.0005110665565907929",
         "0.001651509965592829",
         "0.03758356028182228",
         "1.0",
         "1.0",
         "0.0",
         "0.001074552788170206",
         "0.04712532000350137",
         "0.029323059530632817"
        ]
       ],
       "shape": {
        "columns": 21,
        "rows": 10
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count_train</th>\n",
       "      <th>share_train</th>\n",
       "      <th>defaults_train</th>\n",
       "      <th>default_rate_train</th>\n",
       "      <th>avg_p_train</th>\n",
       "      <th>lift_train</th>\n",
       "      <th>capture_train</th>\n",
       "      <th>cum_share_train</th>\n",
       "      <th>KS_train</th>\n",
       "      <th>count_val</th>\n",
       "      <th>...</th>\n",
       "      <th>defaults_val</th>\n",
       "      <th>default_rate_val</th>\n",
       "      <th>avg_p_val</th>\n",
       "      <th>lift_val</th>\n",
       "      <th>capture_val</th>\n",
       "      <th>cum_share_val</th>\n",
       "      <th>KS_val</th>\n",
       "      <th>default_rate_diff</th>\n",
       "      <th>share_diff</th>\n",
       "      <th>psi_component</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>948905</td>\n",
       "      <td>0.098938</td>\n",
       "      <td>41871</td>\n",
       "      <td>0.044126</td>\n",
       "      <td>0.044229</td>\n",
       "      <td>3.624500</td>\n",
       "      <td>0.358601</td>\n",
       "      <td>0.098938</td>\n",
       "      <td>0.262863</td>\n",
       "      <td>167407</td>\n",
       "      <td>...</td>\n",
       "      <td>7262</td>\n",
       "      <td>0.043379</td>\n",
       "      <td>0.048534</td>\n",
       "      <td>3.190091</td>\n",
       "      <td>0.573165</td>\n",
       "      <td>0.179670</td>\n",
       "      <td>0.398919</td>\n",
       "      <td>0.000746</td>\n",
       "      <td>-0.080732</td>\n",
       "      <td>0.048167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>962315</td>\n",
       "      <td>0.100336</td>\n",
       "      <td>23050</td>\n",
       "      <td>0.023953</td>\n",
       "      <td>0.023890</td>\n",
       "      <td>1.967484</td>\n",
       "      <td>0.556011</td>\n",
       "      <td>0.199274</td>\n",
       "      <td>0.361133</td>\n",
       "      <td>110303</td>\n",
       "      <td>...</td>\n",
       "      <td>2150</td>\n",
       "      <td>0.019492</td>\n",
       "      <td>0.024241</td>\n",
       "      <td>1.433414</td>\n",
       "      <td>0.742857</td>\n",
       "      <td>0.298054</td>\n",
       "      <td>0.450935</td>\n",
       "      <td>0.004461</td>\n",
       "      <td>-0.018047</td>\n",
       "      <td>0.002985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>963795</td>\n",
       "      <td>0.100491</td>\n",
       "      <td>15235</td>\n",
       "      <td>0.015807</td>\n",
       "      <td>0.015782</td>\n",
       "      <td>1.298420</td>\n",
       "      <td>0.686490</td>\n",
       "      <td>0.299765</td>\n",
       "      <td>0.391491</td>\n",
       "      <td>109791</td>\n",
       "      <td>...</td>\n",
       "      <td>1284</td>\n",
       "      <td>0.011695</td>\n",
       "      <td>0.016008</td>\n",
       "      <td>0.860040</td>\n",
       "      <td>0.844199</td>\n",
       "      <td>0.415887</td>\n",
       "      <td>0.434216</td>\n",
       "      <td>0.004112</td>\n",
       "      <td>-0.017343</td>\n",
       "      <td>0.002761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>942837</td>\n",
       "      <td>0.098305</td>\n",
       "      <td>10349</td>\n",
       "      <td>0.010976</td>\n",
       "      <td>0.011001</td>\n",
       "      <td>0.901611</td>\n",
       "      <td>0.775124</td>\n",
       "      <td>0.398071</td>\n",
       "      <td>0.381700</td>\n",
       "      <td>121965</td>\n",
       "      <td>...</td>\n",
       "      <td>921</td>\n",
       "      <td>0.007551</td>\n",
       "      <td>0.010851</td>\n",
       "      <td>0.555322</td>\n",
       "      <td>0.916890</td>\n",
       "      <td>0.546787</td>\n",
       "      <td>0.375205</td>\n",
       "      <td>0.003425</td>\n",
       "      <td>-0.032594</td>\n",
       "      <td>0.009333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>960719</td>\n",
       "      <td>0.100170</td>\n",
       "      <td>8111</td>\n",
       "      <td>0.008443</td>\n",
       "      <td>0.008427</td>\n",
       "      <td>0.693482</td>\n",
       "      <td>0.844590</td>\n",
       "      <td>0.498241</td>\n",
       "      <td>0.350618</td>\n",
       "      <td>62511</td>\n",
       "      <td>...</td>\n",
       "      <td>323</td>\n",
       "      <td>0.005167</td>\n",
       "      <td>0.008417</td>\n",
       "      <td>0.379985</td>\n",
       "      <td>0.942384</td>\n",
       "      <td>0.613877</td>\n",
       "      <td>0.333035</td>\n",
       "      <td>0.003276</td>\n",
       "      <td>0.033080</td>\n",
       "      <td>0.013259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>971988</td>\n",
       "      <td>0.101345</td>\n",
       "      <td>6059</td>\n",
       "      <td>0.006234</td>\n",
       "      <td>0.006252</td>\n",
       "      <td>0.512032</td>\n",
       "      <td>0.896482</td>\n",
       "      <td>0.599585</td>\n",
       "      <td>0.300555</td>\n",
       "      <td>93616</td>\n",
       "      <td>...</td>\n",
       "      <td>318</td>\n",
       "      <td>0.003397</td>\n",
       "      <td>0.006324</td>\n",
       "      <td>0.249803</td>\n",
       "      <td>0.967482</td>\n",
       "      <td>0.714351</td>\n",
       "      <td>0.256621</td>\n",
       "      <td>0.002837</td>\n",
       "      <td>0.000871</td>\n",
       "      <td>0.000008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>883250</td>\n",
       "      <td>0.092093</td>\n",
       "      <td>4056</td>\n",
       "      <td>0.004592</td>\n",
       "      <td>0.004598</td>\n",
       "      <td>0.377200</td>\n",
       "      <td>0.931219</td>\n",
       "      <td>0.691678</td>\n",
       "      <td>0.242493</td>\n",
       "      <td>82816</td>\n",
       "      <td>...</td>\n",
       "      <td>188</td>\n",
       "      <td>0.002270</td>\n",
       "      <td>0.004787</td>\n",
       "      <td>0.166941</td>\n",
       "      <td>0.982320</td>\n",
       "      <td>0.803234</td>\n",
       "      <td>0.181556</td>\n",
       "      <td>0.002322</td>\n",
       "      <td>0.003210</td>\n",
       "      <td>0.000114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1036780</td>\n",
       "      <td>0.108100</td>\n",
       "      <td>3890</td>\n",
       "      <td>0.003752</td>\n",
       "      <td>0.003728</td>\n",
       "      <td>0.308191</td>\n",
       "      <td>0.964535</td>\n",
       "      <td>0.799778</td>\n",
       "      <td>0.166787</td>\n",
       "      <td>80674</td>\n",
       "      <td>...</td>\n",
       "      <td>142</td>\n",
       "      <td>0.001760</td>\n",
       "      <td>0.003775</td>\n",
       "      <td>0.129442</td>\n",
       "      <td>0.993528</td>\n",
       "      <td>0.889817</td>\n",
       "      <td>0.105140</td>\n",
       "      <td>0.001992</td>\n",
       "      <td>0.021517</td>\n",
       "      <td>0.004776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>944659</td>\n",
       "      <td>0.098495</td>\n",
       "      <td>2594</td>\n",
       "      <td>0.002746</td>\n",
       "      <td>0.002756</td>\n",
       "      <td>0.225555</td>\n",
       "      <td>0.986751</td>\n",
       "      <td>0.898274</td>\n",
       "      <td>0.089567</td>\n",
       "      <td>51788</td>\n",
       "      <td>...</td>\n",
       "      <td>56</td>\n",
       "      <td>0.001081</td>\n",
       "      <td>0.002630</td>\n",
       "      <td>0.079521</td>\n",
       "      <td>0.997948</td>\n",
       "      <td>0.945399</td>\n",
       "      <td>0.053273</td>\n",
       "      <td>0.001665</td>\n",
       "      <td>0.042914</td>\n",
       "      <td>0.024553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>975644</td>\n",
       "      <td>0.101726</td>\n",
       "      <td>1547</td>\n",
       "      <td>0.001586</td>\n",
       "      <td>0.001556</td>\n",
       "      <td>0.130244</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>50874</td>\n",
       "      <td>...</td>\n",
       "      <td>26</td>\n",
       "      <td>0.000511</td>\n",
       "      <td>0.001652</td>\n",
       "      <td>0.037584</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001075</td>\n",
       "      <td>0.047125</td>\n",
       "      <td>0.029323</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       count_train  share_train  defaults_train  default_rate_train  \\\n",
       "class                                                                 \n",
       "1           948905     0.098938           41871            0.044126   \n",
       "2           962315     0.100336           23050            0.023953   \n",
       "3           963795     0.100491           15235            0.015807   \n",
       "4           942837     0.098305           10349            0.010976   \n",
       "5           960719     0.100170            8111            0.008443   \n",
       "6           971988     0.101345            6059            0.006234   \n",
       "7           883250     0.092093            4056            0.004592   \n",
       "8          1036780     0.108100            3890            0.003752   \n",
       "9           944659     0.098495            2594            0.002746   \n",
       "10          975644     0.101726            1547            0.001586   \n",
       "\n",
       "       avg_p_train  lift_train  capture_train  cum_share_train  KS_train  \\\n",
       "class                                                                      \n",
       "1         0.044229    3.624500       0.358601         0.098938  0.262863   \n",
       "2         0.023890    1.967484       0.556011         0.199274  0.361133   \n",
       "3         0.015782    1.298420       0.686490         0.299765  0.391491   \n",
       "4         0.011001    0.901611       0.775124         0.398071  0.381700   \n",
       "5         0.008427    0.693482       0.844590         0.498241  0.350618   \n",
       "6         0.006252    0.512032       0.896482         0.599585  0.300555   \n",
       "7         0.004598    0.377200       0.931219         0.691678  0.242493   \n",
       "8         0.003728    0.308191       0.964535         0.799778  0.166787   \n",
       "9         0.002756    0.225555       0.986751         0.898274  0.089567   \n",
       "10        0.001556    0.130244       1.000000         1.000000  0.000000   \n",
       "\n",
       "       count_val  ...  defaults_val  default_rate_val  avg_p_val  lift_val  \\\n",
       "class             ...                                                        \n",
       "1         167407  ...          7262          0.043379   0.048534  3.190091   \n",
       "2         110303  ...          2150          0.019492   0.024241  1.433414   \n",
       "3         109791  ...          1284          0.011695   0.016008  0.860040   \n",
       "4         121965  ...           921          0.007551   0.010851  0.555322   \n",
       "5          62511  ...           323          0.005167   0.008417  0.379985   \n",
       "6          93616  ...           318          0.003397   0.006324  0.249803   \n",
       "7          82816  ...           188          0.002270   0.004787  0.166941   \n",
       "8          80674  ...           142          0.001760   0.003775  0.129442   \n",
       "9          51788  ...            56          0.001081   0.002630  0.079521   \n",
       "10         50874  ...            26          0.000511   0.001652  0.037584   \n",
       "\n",
       "       capture_val  cum_share_val    KS_val  default_rate_diff  share_diff  \\\n",
       "class                                                                        \n",
       "1         0.573165       0.179670  0.398919           0.000746   -0.080732   \n",
       "2         0.742857       0.298054  0.450935           0.004461   -0.018047   \n",
       "3         0.844199       0.415887  0.434216           0.004112   -0.017343   \n",
       "4         0.916890       0.546787  0.375205           0.003425   -0.032594   \n",
       "5         0.942384       0.613877  0.333035           0.003276    0.033080   \n",
       "6         0.967482       0.714351  0.256621           0.002837    0.000871   \n",
       "7         0.982320       0.803234  0.181556           0.002322    0.003210   \n",
       "8         0.993528       0.889817  0.105140           0.001992    0.021517   \n",
       "9         0.997948       0.945399  0.053273           0.001665    0.042914   \n",
       "10        1.000000       1.000000  0.000000           0.001075    0.047125   \n",
       "\n",
       "       psi_component  \n",
       "class                 \n",
       "1           0.048167  \n",
       "2           0.002985  \n",
       "3           0.002761  \n",
       "4           0.009333  \n",
       "5           0.013259  \n",
       "6           0.000008  \n",
       "7           0.000114  \n",
       "8           0.004776  \n",
       "9           0.024553  \n",
       "10          0.029323  \n",
       "\n",
       "[10 rows x 21 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ==========================================================\n",
    "# Tableaux IN/OUT + Classes (déciles) avec le **modèle final**\n",
    "# (utilise p_tr_curr / p_va_curr produits après drop-proxy + ablation)\n",
    "# Option : utiliser la proba ajustée au prior-shift pour la VAL si dispo.\n",
    "# ==========================================================\n",
    "\n",
    "USE_PRIOR_SHIFT_IN_VAL = True  # si True et p_val_adj existe, on l’utilise pour la VAL\n",
    "\n",
    "def _safe_auc(y, p):\n",
    "    y = pd.Series(y).astype(int).to_numpy()\n",
    "    p = pd.Series(p).astype(float).to_numpy()\n",
    "    if np.unique(y).size < 2:\n",
    "        return np.nan\n",
    "    return roc_auc_score(y, p)\n",
    "\n",
    "def global_metrics_df(y, p, name=\"SET\"):\n",
    "    \"\"\"Résumé global (AUC, Gini, Brier, LogLoss, KS, calibration, etc.).\"\"\"\n",
    "    y = pd.Series(y).astype(int).to_numpy()\n",
    "    p = pd.Series(p).astype(float).to_numpy()\n",
    "    n = len(y); n_def = int(y.sum()); dr = float(y.mean())\n",
    "    auc = _safe_auc(y, p)\n",
    "    gini = float(2*auc - 1) if np.isfinite(auc) else np.nan\n",
    "    brier = brier_score_loss(y, p) if n else np.nan\n",
    "    ll = log_loss(y, p) if n else np.nan\n",
    "    # KS + seuil\n",
    "    if np.unique(y).size >= 2:\n",
    "        fpr, tpr, thr = roc_curve(y, p)\n",
    "        ks_arr = tpr - fpr\n",
    "        i = int(np.nanargmax(ks_arr))\n",
    "        ks, thr_ks = float(ks_arr[i]), float(thr[i])\n",
    "    else:\n",
    "        ks, thr_ks = np.nan, np.nan\n",
    "    # Calibration slope/intercept (logit(p) -> y)\n",
    "    def _calib(y_, p_, eps=1e-9):\n",
    "        if np.unique(y_).size < 2:\n",
    "            return np.nan, np.nan\n",
    "        p_clip = np.clip(p_, eps, 1-eps)\n",
    "        logit_p = np.log(p_clip/(1-p_clip)).reshape(-1, 1)\n",
    "        try:\n",
    "            lr = LogisticRegression(penalty=\"none\", solver=\"lbfgs\", max_iter=2000)\n",
    "            lr.fit(logit_p, y_)\n",
    "        except Exception:\n",
    "            lr = LogisticRegression(penalty=None, solver=\"lbfgs\", max_iter=2000)\n",
    "            lr.fit(logit_p, y_)\n",
    "        return float(lr.intercept_[0]), float(lr.coef_[0][0])\n",
    "    a, b = _calib(y, p)\n",
    "\n",
    "    df = pd.DataFrame([{\n",
    "        \"set\": name,\n",
    "        \"n\": n, \"defaults\": n_def, \"default_rate\": dr,\n",
    "        \"AUC\": auc, \"Gini\": gini,\n",
    "        \"Brier\": brier, \"LogLoss\": ll,\n",
    "        \"KS\": ks, \"KS_threshold\": thr_ks,\n",
    "        \"Calib_intercept\": a, \"Calib_slope\": b\n",
    "    }])\n",
    "    return df\n",
    "\n",
    "def decile_edges_from_train(p_train, q=10):\n",
    "    \"\"\"\n",
    "    Seuils de classes par quantiles du TRAIN.\n",
    "    On renvoie des bornes strictement croissantes [-inf, ..., +inf].\n",
    "    \"\"\"\n",
    "    p = pd.Series(p_train).astype(float)\n",
    "    pf = p[np.isfinite(p)]\n",
    "    if pf.empty:\n",
    "        return np.array([-np.inf, np.inf], dtype=\"float64\")\n",
    "    qs = np.linspace(0, 1, q+1)\n",
    "    inner = np.quantile(pf, qs)[1:-1]  # on exclut 0% et 100% (gérés par inf)\n",
    "    inner = np.unique(inner)\n",
    "    edges = np.r_[-np.inf, inner, np.inf].astype(\"float64\")\n",
    "    # enforce strict increase\n",
    "    for i in range(1, len(edges)):\n",
    "        if not (edges[i] > edges[i-1]):\n",
    "            edges[i] = np.nextafter(edges[i-1], np.inf)\n",
    "    return edges\n",
    "\n",
    "def class_table_from_edges(y, p, edges, name=\"SET\"):\n",
    "    \"\"\"\n",
    "    Table classes (1=plus risquée … K=moins risquée) avec stats par classe.\n",
    "    Classes basées sur des edges issus du TRAIN. Exclut les p NaN (codes = -1).\n",
    "    \"\"\"\n",
    "    y = pd.Series(y).astype(int)\n",
    "    p = pd.Series(p).astype(float)\n",
    "    bins = pd.cut(p, bins=edges, include_lowest=True, duplicates=\"drop\")\n",
    "    codes = bins.cat.codes.to_numpy()               # -1 pour NaN / hors bornes\n",
    "    K = int(bins.cat.categories.size)\n",
    "    mask = codes >= 0                               # garder seulement 0..K-1\n",
    "    # Classe 1 = plus risquée (p élevé) ⇒ inverser l’ordre\n",
    "    risk_class = (K - codes[mask]).astype(int)      # 1..K\n",
    "\n",
    "    df = pd.DataFrame({\"y\": y[mask].to_numpy(), \"p\": p[mask].to_numpy(),\n",
    "                       \"class\": risk_class})\n",
    "    tab = (df.groupby(\"class\", dropna=True)\n",
    "             .agg(count=(\"y\",\"size\"), defaults=(\"y\",\"sum\"), avg_p=(\"p\",\"mean\"))\n",
    "             .sort_index())                         # 1..K\n",
    "    if tab.empty:\n",
    "        tab.index.name = \"class\"\n",
    "        tab[\"set\"] = name\n",
    "        return tab\n",
    "\n",
    "    tab[\"default_rate\"] = tab[\"defaults\"] / tab[\"count\"].clip(lower=1)\n",
    "    tab[\"share\"] = tab[\"count\"] / max(int(tab[\"count\"].sum()), 1)\n",
    "\n",
    "    # Cumuls top→bas risque (classes 1..K)\n",
    "    tab[\"cum_defaults\"] = tab[\"defaults\"].cumsum()\n",
    "    tab[\"cum_count\"]    = tab[\"count\"].cumsum()\n",
    "    tot_d = float(tab[\"defaults\"].sum())\n",
    "    tot_c = float(tab[\"count\"].sum())\n",
    "    tot_g = float((tab[\"count\"] - tab[\"defaults\"]).sum())\n",
    "    tab[\"capture\"]   = tab[\"cum_defaults\"] / (tot_d if tot_d>0 else 1.0)\n",
    "    tab[\"cum_share\"] = tab[\"cum_count\"]    / (tot_c if tot_c>0 else 1.0)\n",
    "    tab[\"TPR\"] = tab[\"capture\"]\n",
    "    tab[\"FPR\"] = (tab[\"count\"] - tab[\"defaults\"]).cumsum() / (tot_g if tot_g>0 else 1.0)\n",
    "    tab[\"KS\"]  = tab[\"TPR\"] - tab[\"FPR\"]\n",
    "\n",
    "    # Lift vs moyenne\n",
    "    global_dr = (tot_d / tot_c) if tot_c>0 else np.nan\n",
    "    tab[\"lift\"] = tab[\"default_rate\"] / global_dr if np.isfinite(global_dr) else np.nan\n",
    "    tab.index.name = \"class\"\n",
    "    tab[\"set\"] = name\n",
    "    return tab[[\"set\",\"count\",\"share\",\"defaults\",\"default_rate\",\"avg_p\",\"lift\",\"capture\",\"cum_share\",\"KS\"]]\n",
    "\n",
    "def compare_classes(train_tab, val_tab, eps=1e-9):\n",
    "    \"\"\"\n",
    "    Jointure par classe + PSI composante et total.\n",
    "    Corrige le conflit de colonne 'set' en la retirant avant la jointure.\n",
    "    \"\"\"\n",
    "    tt = train_tab.drop(columns=[c for c in [\"set\"] if c in train_tab.columns]).copy()\n",
    "    vv = val_tab.drop(columns=[c for c in [\"set\"] if c in val_tab.columns]).copy()\n",
    "    if tt.index.name != \"class\":\n",
    "        tt.index.name = \"class\"\n",
    "    if vv.index.name != \"class\":\n",
    "        vv.index.name = \"class\"\n",
    "    tt.index = tt.index.astype(int); tt = tt.sort_index()\n",
    "    vv.index = vv.index.astype(int); vv = vv.sort_index()\n",
    "\n",
    "    tt = tt.rename(columns={\n",
    "        \"count\":\"count_train\",\"share\":\"share_train\",\"defaults\":\"defaults_train\",\n",
    "        \"default_rate\":\"default_rate_train\",\"avg_p\":\"avg_p_train\",\"lift\":\"lift_train\",\n",
    "        \"capture\":\"capture_train\",\"cum_share\":\"cum_share_train\",\"KS\":\"KS_train\"\n",
    "    })\n",
    "    vv = vv.rename(columns={\n",
    "        \"count\":\"count_val\",\"share\":\"share_val\",\"defaults\":\"defaults_val\",\n",
    "        \"default_rate\":\"default_rate_val\",\"avg_p\":\"avg_p_val\",\"lift\":\"lift_val\",\n",
    "        \"capture\":\"capture_val\",\"cum_share\":\"cum_share_val\",\"KS\":\"KS_val\"\n",
    "    })\n",
    "\n",
    "    comp = tt.join(vv, how=\"outer\")\n",
    "\n",
    "    comp[\"default_rate_diff\"] = comp[\"default_rate_train\"] - comp[\"default_rate_val\"]\n",
    "    comp[\"share_diff\"]        = comp[\"share_train\"] - comp[\"share_val\"]\n",
    "\n",
    "    pa = comp[\"share_train\"].fillna(0.0).to_numpy()\n",
    "    pb = comp[\"share_val\"].fillna(0.0).to_numpy()\n",
    "    comp[\"psi_component\"] = (pa - pb) * np.log((pa + eps) / (pb + eps))\n",
    "    psi_total = float(np.nansum(comp[\"psi_component\"].to_numpy()))\n",
    "\n",
    "    comp = comp.sort_index()\n",
    "    return comp, psi_total\n",
    "\n",
    "def _check_monotonicity(tab):\n",
    "    \"\"\"Vérifie que le taux de défaut baisse bien du plus risqué vers le moins risqué.\"\"\"\n",
    "    if tab.empty:\n",
    "        return False\n",
    "    dif = tab[\"default_rate\"].diff()\n",
    "    mono = bool((dif.dropna() <= 0).all())\n",
    "    txt = \"OK ✅\" if mono else \"⚠️ non monotone\"\n",
    "    print(f\"Monotonicité des taux de défaut (haut → bas risque) : {txt}\")\n",
    "    return mono\n",
    "\n",
    "# ----------------- Utilisation du **modèle final** -----------------\n",
    "# On récupère les probabilités/labels du dernier fit (après ablation)\n",
    "# Fallback si les variables finales n'existent pas encore.\n",
    "\n",
    "# TRAIN (final)\n",
    "if 'p_tr_curr' in globals() and 'y_train_full' in globals():\n",
    "    p_train_final = p_tr_curr\n",
    "    y_train_final = y_train_full\n",
    "else:\n",
    "    # fallback sur anciennes variables si besoin\n",
    "    p_train_final = p_train\n",
    "    y_train_final = y_train\n",
    "\n",
    "# VAL (final)\n",
    "p_val_base_final = None\n",
    "if 'p_va_curr' in globals():\n",
    "    p_val_base_final = p_va_curr\n",
    "elif 'p_val' in globals():\n",
    "    p_val_base_final = p_val\n",
    "\n",
    "# Option : utiliser la version prior-shift ajustée si dispo\n",
    "if USE_PRIOR_SHIFT_IN_VAL and 'p_val_adj' in globals():\n",
    "    p_val_final = p_val_adj\n",
    "else:\n",
    "    p_val_final = p_val_base_final\n",
    "\n",
    "# ------------- Génération des tableaux ------------------\n",
    "\n",
    "# 1) Tableaux de métriques globales (TRAIN avec proba finales)\n",
    "metrics_train = global_metrics_df(y_train_final, p_train_final, name=\"TRAIN (final)\")\n",
    "display(metrics_train)\n",
    "\n",
    "# 2) Seuils de classes à partir du TRAIN (final), puis tables classes Train & Val\n",
    "edges = decile_edges_from_train(p_train_final, q=10)  # ← change q si tu veux 5/7/12 classes\n",
    "\n",
    "classes_train = class_table_from_edges(y_train_final, p_train_final, edges, name=\"TRAIN (final)\")\n",
    "display(classes_train)\n",
    "_ = _check_monotonicity(classes_train)\n",
    "\n",
    "# 3) Validation si dispo\n",
    "if 'y_val' in globals() and y_val is not None and p_val_final is not None:\n",
    "    # Affiche aussi les métriques globales VAL (en précisant si prior-shift utilisé)\n",
    "    suffix = \"VAL (final, prior-shift)\" if (USE_PRIOR_SHIFT_IN_VAL and 'p_val_adj' in globals()) else \"VAL (final)\"\n",
    "    metrics_val = global_metrics_df(y_val, p_val_final, name=suffix)\n",
    "    display(metrics_val)\n",
    "\n",
    "    classes_val = class_table_from_edges(y_val, p_val_final, edges, name=suffix)\n",
    "    display(classes_val)\n",
    "    _ = _check_monotonicity(classes_val)\n",
    "\n",
    "    comp_classes, psi_total = compare_classes(classes_train, classes_val)\n",
    "    print(f\"PSI (distribution des classes TRAIN→VAL) = {psi_total:.4f}  (≈ <0.10 faible, 0.10–0.25 modéré, >0.25 fort)\")\n",
    "    display(comp_classes)\n",
    "\n",
    "    # (Optionnel) Exports CSV\n",
    "    classes_train.to_csv(\"train_classes_deciles_final.csv\")\n",
    "    classes_val.to_csv(\"val_classes_deciles_final.csv\")\n",
    "    comp_classes.to_csv(\"compare_classes_train_vs_val_final.csv\")\n",
    "    metrics_train.to_csv(\"metrics_train_final.csv\", index=False)\n",
    "    metrics_val.to_csv(\"metrics_val_final.csv\", index=False)\n",
    "else:\n",
    "    print(\"Validation non disponible : seuls les tableaux TRAIN (modèle final) ont été affichés.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3afc8b0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PeriodArray>\n",
      "['2020Q1', '2020Q2', '2020Q3', '2020Q4', '2021Q1', '2021Q2', '2021Q3',\n",
      " '2021Q4', '2022Q1', '2022Q2', '2022Q3', '2022Q4']\n",
      "Length: 12, dtype: period[Q-DEC]\n",
      "<PeriodArray>\n",
      "['2023Q1', '2023Q2', '2023Q3', '2023Q4']\n",
      "Length: 4, dtype: period[Q-DEC]\n"
     ]
    }
   ],
   "source": [
    "print(df_train_imp[\"vintage\"].unique())\n",
    "print(df_val_imp[\"vintage\"].unique())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pd-calibration-NMoSp0fs-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
